{
  "version": "https://jsonfeed.org/version/1",
  "icon": "https://www.trackawesomelist.com/icon.png",
  "favicon": "https://www.trackawesomelist.com/favicon.ico",
  "language": "en",
  "title": "Awesome List Updates on Dec 11, 2022",
  "_site_title": "Track Awesome List",
  "description": "5 awesome lists updated today.",
  "_seo_title": "Awesome List Updates on Dec 11, 2022 - Track Awesome List",
  "feed_url": "https://www.trackawesomelist.com/feed.json",
  "home_page_url": "https://www.trackawesomelist.com",
  "items": [
    {
      "id": "https://www.trackawesomelist.com/Kamigami55/awesome-chatgpt/",
      "title": "Awesome Chatgpt",
      "_slug": "Kamigami55/awesome-chatgpt/",
      "_filepath": "/content/Kamigami55/awesome-chatgpt/README.md",
      "url": "https://www.trackawesomelist.com/Kamigami55/awesome-chatgpt/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Use ChatGPT Anywhere / Chatbots\n\n*   [gpt-ai-assistant (⭐7.7k)](https://github.com/memochou1993/gpt-ai-assistant) (Chinese content): Run your own GPT LINE bot on Vercel in 10 minutes.",
      "content_html": "<h3><p>Use ChatGPT Anywhere / Chatbots</p>\n</h3><ul>\n<li><a href=\"https://github.com/memochou1993/gpt-ai-assistant\" rel=\"noopener noreferrer\">gpt-ai-assistant (⭐7.7k)</a> (Chinese content): Run your own GPT LINE bot on Vercel in 10 minutes.</li>\n</ul>\n",
      "date_published": "2022-12-11T17:50:56.000Z",
      "date_modified": "2022-12-11T17:50:56.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/vitejs/awesome-vite/",
      "title": "Awesome Vite",
      "_slug": "vitejs/awesome-vite/",
      "_filepath": "/content/vitejs/awesome-vite/README.md",
      "url": "https://www.trackawesomelist.com/vitejs/awesome-vite/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Vue / Ecosystem\n\n*   ![v3](https://img.shields.io/badge/-v3-35495e) [unplugin-vue-i18n (⭐260)](https://github.com/intlify/bundle-tools/tree/main/packages/unplugin-vue-i18n) - Integration for Vue I18n.",
      "content_html": "<h3><p>Vue / Ecosystem</p>\n</h3><ul>\n<li><img src=\"https://img.shields.io/badge/-v3-35495e\" alt=\"v3\" /> <a href=\"https://github.com/intlify/bundle-tools/tree/main/packages/unplugin-vue-i18n\" rel=\"noopener noreferrer\">unplugin-vue-i18n (⭐260)</a> - Integration for Vue I18n.</li>\n</ul>\n",
      "date_published": "2022-12-11T16:47:05.000Z",
      "date_modified": "2022-12-11T16:47:05.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/unixorn/awesome-zsh-plugins/",
      "title": "Awesome Zsh Plugins",
      "_slug": "unixorn/awesome-zsh-plugins/",
      "_filepath": "/content/unixorn/awesome-zsh-plugins/README.md",
      "url": "https://www.trackawesomelist.com/unixorn/awesome-zsh-plugins/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Themes / [superconsole](https://github.com/alexchmykhalo/superconsole) - Windows-only\n\n*   [gus (⭐0)](https://github.com/gusye1234/Gus-zsh-theme/) - Hackable transient theme. Includes decorators for conda, `git` information and current directory.",
      "content_html": "<h3><p>Themes / <a href=\"https://github.com/alexchmykhalo/superconsole\" rel=\"noopener noreferrer\">superconsole</a> - Windows-only</p>\n</h3><ul>\n<li><a href=\"https://github.com/gusye1234/Gus-zsh-theme/\" rel=\"noopener noreferrer\">gus (⭐0)</a> - Hackable transient theme. Includes decorators for conda, <code>git</code> information and current directory.</li>\n</ul>\n",
      "date_published": "2022-12-11T15:20:15.000Z",
      "date_modified": "2022-12-11T15:20:15.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/jetli/awesome-yew/",
      "title": "Awesome Yew",
      "_slug": "jetli/awesome-yew/",
      "_filepath": "/content/jetli/awesome-yew/README.md",
      "url": "https://www.trackawesomelist.com/jetli/awesome-yew/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Crates / Frameworks\n\n*   [stackable (⭐22)](https://github.com/futursolo/stackable) - A framework experience for Yew.",
      "content_html": "<h3><p>Crates / Frameworks</p>\n</h3><ul>\n<li><a href=\"https://github.com/futursolo/stackable\" rel=\"noopener noreferrer\">stackable (⭐22)</a> - A framework experience for Yew.</li>\n</ul>\n",
      "date_published": "2022-12-11T10:02:04.000Z",
      "date_modified": "2022-12-11T10:02:04.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/YuzheSHI/awesome-agi-cocosci/",
      "title": "Awesome Agi Cocosci",
      "_slug": "YuzheSHI/awesome-agi-cocosci/",
      "_filepath": "/content/YuzheSHI/awesome-agi-cocosci/README.md",
      "url": "https://www.trackawesomelist.com/YuzheSHI/awesome-agi-cocosci/",
      "summary": "16 awesome projects updated",
      "content_text": "\n\n### Bayesian Modeling / Bayesian Induction\n\n*   [Testing a Bayesian Measure of Representativeness Using a Large Image Database](https://proceedings.neurips.cc/paper/2011/hash/2c89109d42178de8a367c0228f169bf8-Abstract.html) - ***NeurIPS'11***, 2011. \\[[All Versions](https://scholar.google.com/scholar?cluster=8576570792794301292\\&hl=en\\&as_sdt=0,5)].\n\n### Bayesian Modeling / Generative Model\n\n*   [Learning Latent Space Energy-Based Prior Model](https://proceedings.neurips.cc/paper/2020/hash/fa3060edb66e6ff4507886f9912e1ab9-Abstract.html) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?oi=bibs\\&hl=en\\&cluster=9945264852135249894)]. \\[[Project](https://bpucla.github.io/latent-space-ebm-prior-project/)]. \\[[Code (⭐36)](https://github.com/bpucla/latent-space-EBM-prior)]. A milestone paper on Latent Energy-Based Model.\n\n### Bayesian Modeling / Nonparametric Model\n\n*   [Hierarchical topic models and the nested Chinese restaurant process](https://proceedings.neurips.cc/paper/2003/file/7b41bfa5085806dfa24b8c9de0ce567f-Paper.pdf) - ***NeurIPS'03***, 2003. \\[[All Versions](https://scholar.google.com/scholar?cluster=15040818675282958700\\&hl=en\\&as_sdt=0,5)]. The original paper for nested Chinese restaurant process.\n\n### Communications / Language Compositionality\n\n*   [Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols](https://proceedings.neurips.cc/paper/2017/hash/70222949cc0db89ab32c9969754d4758-Abstract.html) - ***NeurIPS'18***, 2018. \\[[All Versions](https://scholar.google.com/scholar?cluster=17308624474306270808\\&hl=en\\&as_sdt=0,5)].\n\n### Problem Solving / Human-Level Problem Solving\n\n*   [Physion: Evaluating Physical Prediction from Vision in Humans and Machines](https://openreview.net/forum?id=CXyZrKPz4CU) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?cluster=8733318111076645893\\&hl=en\\&as_sdt=0,5)].\n\n### Problem Solving / Intrinsic Motivation\n\n*   [Intrinsically Motivated Reinforcement Learning](https://proceedings.neurips.cc/paper/2004/hash/4be5a36cbaca8ab9d2066debfe4e65c1-Abstract.html) - ***NeurIPS'04***, 2004. \\[[All Versions](https://scholar.google.com/scholar?cluster=9736217847061704054\\&hl=en\\&as_sdt=0,5)]. A comprehensive review on intrinsic reward functions in classic reinforcement learning.\n*   [Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning](https://proceedings.neurips.cc/paper/2015/hash/e00406144c1e7e35240afed70f34166a-Abstract.html) - ***NeurIPS'15***, 2015. \\[[All Versions](https://scholar.google.com/scholar?cluster=9262504233068870193\\&hl=en\\&as_sdt=0,5)]. The original paper on empowerment as intrinsic motivation.\n\n### Problem Solving / Reinforcement Learning\n\n*   [A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation](https://proceedings.neurips.cc/paper/2019/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=7721047641895252765\\&hl=en\\&as_sdt=0,5)].\n*   [Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability](https://arxiv.org/abs/2107.06277) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?cluster=9640851185758072663\\&hl=en\\&as_sdt=0,5)]. A formal treatment on the generalization problem in reinforcement learning.\n*   [On the Expressivity of Markov Reward](https://papers.NeurIPS.cc/paper/2021/file/4079016d940210b4ae9ae7d41c4a2065-Paper.pdf) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?cluster=4524686816939437211\\&hl=en\\&as_sdt=0,5)]. A formal treatment of tasks and rewards in reinforcement learning modeling.\n\n### System 1 & System 2 / Neural-Symbolic AI\n\n*   [DeepProbLog: Neural Probabilistic Logic Programming](https://arxiv.org/abs/1805.10872) - ***NeurIPS'18***, 2018. \\[[All Versions](https://scholar.google.com/scholar?cluster=6079567413300944995\\&hl=en\\&as_sdt=0,5)]. The original paper on neuro-symbolic probabilistic programming.\n*   [Bridging Machine Learning and Logical Reasoning by Abductive Learning.](http://papers.NeurIPS.cc/paper/8548-bridging-machine-learning-and-logical-reasoning-by-abductive-learning) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=1518342375288126288\\&hl=en\\&as_sdt=0,5)]. \\[[Slides](https://daiwz.net/org/slides/ABL-meetup.html#/slide-title)]. \\[[Code (⭐99)](https://github.com/AbductiveLearning/ABL-HED)]. The original paper on Abductive Learning, a derivative-free approach for neuro-symbolic learning.\n*   [Learning by Abstraction: The Neural State Machine](https://proceedings.neurips.cc/paper/2019/file/c20a7ce2a627ba838cfbff082db35197-Paper.pdf) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=7361406080192630148\\&hl=en\\&as_sdt=0,5)].\n*   [Classification-by-Components: Probabilistic Modeling of Reasoning over a Set of Components](http://papers.NeurIPS.cc/paper/8546-classification-by-components-probabilistic-modeling-of-reasoning-over-a-set-of-components.pdf) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=12691103404451941071\\&hl=en\\&as_sdt=0,5)].\n*   [Understanding Deep Architectures with Reasoning Layer](https://proceedings.neurips.cc/paper/2020/file/0d82627e10660af39ea7eb69c3568955-Paper.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=937882599430270789\\&hl=en\\&as_sdt=0,5)].\n*   [Compositional Generalization via Neural-Symbolic Stack Machines](https://arxiv.org/pdf/2008.06662.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=15612498612943317331\\&hl=en\\&as_sdt=0,5)].\n*   [Learning Compositional Rules via Neural Program Synthesis](https://proceedings.neurips.cc/paper/2020/hash/7a685d9edd95508471a9d3d6fcace432-Abstract.html) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=3160670555314650508\\&hl=en\\&as_sdt=0,5)].\n*   [Discovering Symbolic Models from Deep Learning with Inductive Biases](https://arxiv.org/abs/2006.11287) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=9452091824686227240\\&hl=en\\&as_sdt=0,5)].\n*   [Visual Concept-Metaconcept Learning](https://papers.NeurIPS.cc/paper/2019/file/98d8a23fd60826a2a474c5b4f5811707-Paper.pdf) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=1888051343232298875\\&hl=en\\&as_sdt=0,5)].\n\n### Explainability / Explainable Deep Learning\n\n*   [Compositional Explanations of Neurons](https://proceedings.neurips.cc/paper/2020/hash/c74956ffb38ba48ed6ce977af6727275-Abstract.html) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=15725346730266402738\\&hl=en\\&as_sdt=0,5)]. \\[[Project (⭐25)](https://github.com/jayelm/compexp)]. A concept-composition version of network dissection.\n*   [This Looks Like That: Deep Learning for Interpretable Image Recognition](http://papers.NeurIPS.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=9461838581952136719\\&hl=en\\&as_sdt=0,5)].\n*   [Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation](https://proceedings.neurips.cc/paper/2018/hash/5fc34ed307aac159a30d81181c99847e-Abstract.html) - ***NeurIPS'18***, 2018. \\[[All Versions](https://scholar.google.com/scholar?cluster=401428033641216502\\&hl=en\\&as_sdt=0,5)]. Maching the learned pattern of neurons in different neural networks.\n\n### Meta-Level Considerations / Meta Learning\n\n*   [Bayesian Model-Agnostic Meta-Learning](https://proceedings.neurips.cc/paper/2018/hash/e1021d43911ca2c1845910d84f40aeae-Abstract.html) - ***NeurIPS'18***, 2018. \\[[All Versions](https://scholar.google.com/scholar?cluster=7370333111335795917\\&hl=en\\&as_sdt=0,5)]. A Bayesian account on MAML.\n*   [On Effective Scheduling of Model-based Reinforcement Learning](https://proceedings.neurips.cc/paper/2021/hash/1e4d36177d71bbb3558e43af9577d70e-Abstract.html) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?cluster=11128521607771619105\\&hl=en\\&as_sdt=0,5)].\n\n### Theory of Mind / AI Assisted Research\n\n*   [Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others](https://static1.squarespace.com/static/595a9f155016e1f7ead6edf1/t/61eeb3e7bbc41a23cd288f8a/1643033708945/Gandhi_etal_2021.pdf) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?oi=bibs\\&hl=en\\&cluster=16514364601966350574)].\n\n### Analogy / AI Assisted Research\n\n*   [VISALOGY: Answering Visual Analogy Questions](https://proceedings.neurips.cc/paper/2015/file/45f31d16b1058d586fc3be7207b58053-Paper.pdf) - ***NeurIPS'15***, 2015. \\[[All Versions](https://scholar.google.com/scholar?cluster=7665427758655324654\\&hl=en\\&as_sdt=0,5)].\n\n### Commonsense / Intuitive Physics\n\n*   [PHYRE: A New Benchmark for Physical Reasoning](https://proceedings.neurips.cc/paper/2019/hash/4191ef5f6c1576762869ac49281130c9-Abstract.html) - ***NeurIPS'19***, 2019. \\[[All Versions](https://scholar.google.com/scholar?cluster=9555658528231205655\\&hl=en\\&as_sdt=0,5)]. A benchmark for AI physical reasoning.\n\n### Knowledge Representation / Commonsense Knowledgebase\n\n*   [Unsupervised Structure Learning of Stochastic And-Or Grammars](http://www.stat.ucla.edu/~sczhu/papers/Conf_2013/Learning_AoG_NeurIPS_2013.pdf) - ***NeurIPS'13***, 2013. \\[[All Versions](https://scholar.google.com/scholar?oi=bibs\\&hl=en\\&cluster=4354984630817844670)].\n\n### Learning in the Open World / Commonsense Knowledgebase\n\n*   [Energy-Based Models for Continual Learning](https://arxiv.org/pdf/2011.12216.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=7094884707139778576\\&hl=en\\&as_sdt=0,5)]. \\[[Project](https://energy-based-model.github.io/Energy-Based-Models-for-Continual-Learning/)].\n*   [A causal view of compositional zero-shot recognition](https://proceedings.neurips.cc/paper/2020/file/1010cedf85f6a7e24b087e63235dc12e-Paper.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=2543173389101020482\\&hl=en\\&as_sdt=0,5)].\n\n### Learning with Cognitive Plausibility / Commonsense Knowledgebase\n\n*   [Self-supervised Learning Through the eyes of a Child](https://cims.nyu.edu/~brenden/papers/OrhanEtAl2020NeurIPS.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=5608715260418451299\\&hl=en\\&as_sdt=0,5)]. Concept learning through near-natural co-occurrence frequency estimation.\n*   [BONGARD-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning](https://proceedings.neurips.cc/paper/2020/hash/bf15e9bbff22c7719020f9df4badc20a-Abstract.html) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=9164011458889391917\\&hl=en\\&as_sdt=0,5)].\n*   [Attention over Learned Object Embeddings Enables Complex Visual Reasoning](https://proceedings.neurips.cc/paper/2021/hash/4c26774d852f62440fc746ea4cdd57f6-Abstract.html) - ***NeurIPS'21***, 2021. \\[[All Versions](https://scholar.google.com/scholar?cluster=127829313460149801\\&hl=en\\&as_sdt=0,5)].\n*   [Distributed Representations of Words and Phrases and their Compositionality](https://papers.NeurIPS.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf) - ***NeurIPS'13***, 2013. \\[[All Versions](https://scholar.google.com/scholar?cluster=2410615501856807729\\&hl=en\\&as_sdt=0,5)].\n*   [Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals](https://proceedings.neurips.cc/paper/2020/file/64dcf3c521a00dbb4d2a10a27a95a9d8-Paper.pdf) - ***NeurIPS'20***, 2020. \\[[All Versions](https://scholar.google.com/scholar?cluster=2255457416066730255\\&hl=en\\&as_sdt=0,5)].",
      "content_html": "<h3><p>Bayesian Modeling / Bayesian Induction</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2011/hash/2c89109d42178de8a367c0228f169bf8-Abstract.html\" rel=\"noopener noreferrer\">Testing a Bayesian Measure of Representativeness Using a Large Image Database</a> - <em><strong>NeurIPS'11</strong></em>, 2011. [<a href=\"https://scholar.google.com/scholar?cluster=8576570792794301292&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Bayesian Modeling / Generative Model</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/hash/fa3060edb66e6ff4507886f9912e1ab9-Abstract.html\" rel=\"noopener noreferrer\">Learning Latent Space Energy-Based Prior Model</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=9945264852135249894\" rel=\"noopener noreferrer\">All Versions</a>]. [<a href=\"https://bpucla.github.io/latent-space-ebm-prior-project/\" rel=\"noopener noreferrer\">Project</a>]. [<a href=\"https://github.com/bpucla/latent-space-EBM-prior\" rel=\"noopener noreferrer\">Code (⭐36)</a>]. A milestone paper on Latent Energy-Based Model.</li>\n</ul>\n<h3><p>Bayesian Modeling / Nonparametric Model</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2003/file/7b41bfa5085806dfa24b8c9de0ce567f-Paper.pdf\" rel=\"noopener noreferrer\">Hierarchical topic models and the nested Chinese restaurant process</a> - <em><strong>NeurIPS'03</strong></em>, 2003. [<a href=\"https://scholar.google.com/scholar?cluster=15040818675282958700&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. The original paper for nested Chinese restaurant process.</li>\n</ul>\n<h3><p>Communications / Language Compositionality</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2017/hash/70222949cc0db89ab32c9969754d4758-Abstract.html\" rel=\"noopener noreferrer\">Emergence of Language with Multi-agent Games: Learning to Communicate with Sequences of Symbols</a> - <em><strong>NeurIPS'18</strong></em>, 2018. [<a href=\"https://scholar.google.com/scholar?cluster=17308624474306270808&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Problem Solving / Human-Level Problem Solving</p>\n</h3><ul>\n<li><a href=\"https://openreview.net/forum?id=CXyZrKPz4CU\" rel=\"noopener noreferrer\">Physion: Evaluating Physical Prediction from Vision in Humans and Machines</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?cluster=8733318111076645893&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Problem Solving / Intrinsic Motivation</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2004/hash/4be5a36cbaca8ab9d2066debfe4e65c1-Abstract.html\" rel=\"noopener noreferrer\">Intrinsically Motivated Reinforcement Learning</a> - <em><strong>NeurIPS'04</strong></em>, 2004. [<a href=\"https://scholar.google.com/scholar?cluster=9736217847061704054&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. A comprehensive review on intrinsic reward functions in classic reinforcement learning.</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2015/hash/e00406144c1e7e35240afed70f34166a-Abstract.html\" rel=\"noopener noreferrer\">Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning</a> - <em><strong>NeurIPS'15</strong></em>, 2015. [<a href=\"https://scholar.google.com/scholar?cluster=9262504233068870193&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. The original paper on empowerment as intrinsic motivation.</li>\n</ul>\n<h3><p>Problem Solving / Reinforcement Learning</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2019/hash/4a46fbfca3f1465a27b210f4bdfe6ab3-Abstract.html\" rel=\"noopener noreferrer\">A Generalized Algorithm for Multi-Objective Reinforcement Learning and Policy Adaptation</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=7721047641895252765&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2107.06277\" rel=\"noopener noreferrer\">Why Generalization in RL is Difficult: Epistemic POMDPs and Implicit Partial Observability</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?cluster=9640851185758072663&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. A formal treatment on the generalization problem in reinforcement learning.</li>\n</ul>\n<ul>\n<li><a href=\"https://papers.NeurIPS.cc/paper/2021/file/4079016d940210b4ae9ae7d41c4a2065-Paper.pdf\" rel=\"noopener noreferrer\">On the Expressivity of Markov Reward</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?cluster=4524686816939437211&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. A formal treatment of tasks and rewards in reinforcement learning modeling.</li>\n</ul>\n<h3><p>System 1 &amp; System 2 / Neural-Symbolic AI</p>\n</h3><ul>\n<li><a href=\"https://arxiv.org/abs/1805.10872\" rel=\"noopener noreferrer\">DeepProbLog: Neural Probabilistic Logic Programming</a> - <em><strong>NeurIPS'18</strong></em>, 2018. [<a href=\"https://scholar.google.com/scholar?cluster=6079567413300944995&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. The original paper on neuro-symbolic probabilistic programming.</li>\n</ul>\n<ul>\n<li><a href=\"http://papers.NeurIPS.cc/paper/8548-bridging-machine-learning-and-logical-reasoning-by-abductive-learning\" rel=\"noopener noreferrer\">Bridging Machine Learning and Logical Reasoning by Abductive Learning.</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=1518342375288126288&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. [<a href=\"https://daiwz.net/org/slides/ABL-meetup.html#/slide-title\" rel=\"noopener noreferrer\">Slides</a>]. [<a href=\"https://github.com/AbductiveLearning/ABL-HED\" rel=\"noopener noreferrer\">Code (⭐99)</a>]. The original paper on Abductive Learning, a derivative-free approach for neuro-symbolic learning.</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2019/file/c20a7ce2a627ba838cfbff082db35197-Paper.pdf\" rel=\"noopener noreferrer\">Learning by Abstraction: The Neural State Machine</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=7361406080192630148&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"http://papers.NeurIPS.cc/paper/8546-classification-by-components-probabilistic-modeling-of-reasoning-over-a-set-of-components.pdf\" rel=\"noopener noreferrer\">Classification-by-Components: Probabilistic Modeling of Reasoning over a Set of Components</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=12691103404451941071&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/file/0d82627e10660af39ea7eb69c3568955-Paper.pdf\" rel=\"noopener noreferrer\">Understanding Deep Architectures with Reasoning Layer</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=937882599430270789&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/2008.06662.pdf\" rel=\"noopener noreferrer\">Compositional Generalization via Neural-Symbolic Stack Machines</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=15612498612943317331&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/hash/7a685d9edd95508471a9d3d6fcace432-Abstract.html\" rel=\"noopener noreferrer\">Learning Compositional Rules via Neural Program Synthesis</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=3160670555314650508&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2006.11287\" rel=\"noopener noreferrer\">Discovering Symbolic Models from Deep Learning with Inductive Biases</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=9452091824686227240&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://papers.NeurIPS.cc/paper/2019/file/98d8a23fd60826a2a474c5b4f5811707-Paper.pdf\" rel=\"noopener noreferrer\">Visual Concept-Metaconcept Learning</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=1888051343232298875&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Explainability / Explainable Deep Learning</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/hash/c74956ffb38ba48ed6ce977af6727275-Abstract.html\" rel=\"noopener noreferrer\">Compositional Explanations of Neurons</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=15725346730266402738&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. [<a href=\"https://github.com/jayelm/compexp\" rel=\"noopener noreferrer\">Project (⭐25)</a>]. A concept-composition version of network dissection.</li>\n</ul>\n<ul>\n<li><a href=\"http://papers.NeurIPS.cc/paper/9095-this-looks-like-that-deep-learning-for-interpretable-image-recognition.pdf\" rel=\"noopener noreferrer\">This Looks Like That: Deep Learning for Interpretable Image Recognition</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=9461838581952136719&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2018/hash/5fc34ed307aac159a30d81181c99847e-Abstract.html\" rel=\"noopener noreferrer\">Towards Understanding Learning Representations: To What Extent Do Different Neural Networks Learn the Same Representation</a> - <em><strong>NeurIPS'18</strong></em>, 2018. [<a href=\"https://scholar.google.com/scholar?cluster=401428033641216502&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. Maching the learned pattern of neurons in different neural networks.</li>\n</ul>\n<h3><p>Meta-Level Considerations / Meta Learning</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2018/hash/e1021d43911ca2c1845910d84f40aeae-Abstract.html\" rel=\"noopener noreferrer\">Bayesian Model-Agnostic Meta-Learning</a> - <em><strong>NeurIPS'18</strong></em>, 2018. [<a href=\"https://scholar.google.com/scholar?cluster=7370333111335795917&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. A Bayesian account on MAML.</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2021/hash/1e4d36177d71bbb3558e43af9577d70e-Abstract.html\" rel=\"noopener noreferrer\">On Effective Scheduling of Model-based Reinforcement Learning</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?cluster=11128521607771619105&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Theory of Mind / AI Assisted Research</p>\n</h3><ul>\n<li><a href=\"https://static1.squarespace.com/static/595a9f155016e1f7ead6edf1/t/61eeb3e7bbc41a23cd288f8a/1643033708945/Gandhi_etal_2021.pdf\" rel=\"noopener noreferrer\">Baby Intuitions Benchmark (BIB): Discerning the goals, preferences, and actions of others</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=16514364601966350574\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Analogy / AI Assisted Research</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2015/file/45f31d16b1058d586fc3be7207b58053-Paper.pdf\" rel=\"noopener noreferrer\">VISALOGY: Answering Visual Analogy Questions</a> - <em><strong>NeurIPS'15</strong></em>, 2015. [<a href=\"https://scholar.google.com/scholar?cluster=7665427758655324654&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Commonsense / Intuitive Physics</p>\n</h3><ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2019/hash/4191ef5f6c1576762869ac49281130c9-Abstract.html\" rel=\"noopener noreferrer\">PHYRE: A New Benchmark for Physical Reasoning</a> - <em><strong>NeurIPS'19</strong></em>, 2019. [<a href=\"https://scholar.google.com/scholar?cluster=9555658528231205655&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. A benchmark for AI physical reasoning.</li>\n</ul>\n<h3><p>Knowledge Representation / Commonsense Knowledgebase</p>\n</h3><ul>\n<li><a href=\"http://www.stat.ucla.edu/~sczhu/papers/Conf_2013/Learning_AoG_NeurIPS_2013.pdf\" rel=\"noopener noreferrer\">Unsupervised Structure Learning of Stochastic And-Or Grammars</a> - <em><strong>NeurIPS'13</strong></em>, 2013. [<a href=\"https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=4354984630817844670\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Learning in the Open World / Commonsense Knowledgebase</p>\n</h3><ul>\n<li><a href=\"https://arxiv.org/pdf/2011.12216.pdf\" rel=\"noopener noreferrer\">Energy-Based Models for Continual Learning</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=7094884707139778576&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. [<a href=\"https://energy-based-model.github.io/Energy-Based-Models-for-Continual-Learning/\" rel=\"noopener noreferrer\">Project</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/file/1010cedf85f6a7e24b087e63235dc12e-Paper.pdf\" rel=\"noopener noreferrer\">A causal view of compositional zero-shot recognition</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=2543173389101020482&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<h3><p>Learning with Cognitive Plausibility / Commonsense Knowledgebase</p>\n</h3><ul>\n<li><a href=\"https://cims.nyu.edu/~brenden/papers/OrhanEtAl2020NeurIPS.pdf\" rel=\"noopener noreferrer\">Self-supervised Learning Through the eyes of a Child</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=5608715260418451299&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>]. Concept learning through near-natural co-occurrence frequency estimation.</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/hash/bf15e9bbff22c7719020f9df4badc20a-Abstract.html\" rel=\"noopener noreferrer\">BONGARD-LOGO: A New Benchmark for Human-Level Concept Learning and Reasoning</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=9164011458889391917&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2021/hash/4c26774d852f62440fc746ea4cdd57f6-Abstract.html\" rel=\"noopener noreferrer\">Attention over Learned Object Embeddings Enables Complex Visual Reasoning</a> - <em><strong>NeurIPS'21</strong></em>, 2021. [<a href=\"https://scholar.google.com/scholar?cluster=127829313460149801&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://papers.NeurIPS.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf\" rel=\"noopener noreferrer\">Distributed Representations of Words and Phrases and their Compositionality</a> - <em><strong>NeurIPS'13</strong></em>, 2013. [<a href=\"https://scholar.google.com/scholar?cluster=2410615501856807729&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n<ul>\n<li><a href=\"https://proceedings.neurips.cc/paper/2020/file/64dcf3c521a00dbb4d2a10a27a95a9d8-Paper.pdf\" rel=\"noopener noreferrer\">Refactoring Policy for Compositional Generalizability using Self-Supervised Object Proposals</a> - <em><strong>NeurIPS'20</strong></em>, 2020. [<a href=\"https://scholar.google.com/scholar?cluster=2255457416066730255&amp;hl=en&amp;as_sdt=0,5\" rel=\"noopener noreferrer\">All Versions</a>].</li>\n</ul>\n",
      "date_published": "2022-12-11T04:42:53.000Z",
      "date_modified": "2022-12-11T04:42:53.000Z"
    }
  ]
}
