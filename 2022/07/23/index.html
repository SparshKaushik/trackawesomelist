<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Awesome List Updates on Jul 23, 2022 - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Awesome List Updates on Jul 23, 2022" />
    <meta property="og:description" content="6 awesome lists updated today." />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Awesome List Updates on Jul 23, 2022</h1>
<p>6 awesome lists updated today.</p>
<p><a href="/">üè† Home</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/search/">üîç Search</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/rss.xml">üî• Feed</a><span> ¬∑ </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">üìÆ Subscribe</a><span> ¬∑ </span><a href="https://github.com/sponsors/theowenyoung">‚ù§Ô∏è  Sponsor</a></p>
<h2><a href="https://www.trackawesomelist.com/dariubs/GoBooks/">1. GoBooks</a></h2><h3><p>2021 - <a href="https://practicalgobook.net" rel="noopener noreferrer">Practical Go: Building Scalable Network and Non-Network Applications</a> / Why does this book look so different?</p>
</h3><ul>
<li>Writing command line applications</li>
</ul>
<ul>
<li>Writing a HTTP services and clients</li>
</ul>
<ul>
<li>Writing RPC services and clients using gRPC</li>
</ul>
<ul>
<li>Writing middleware for network clients and servers</li>
</ul>
<ul>
<li>Storing data in cloud object stores and SQL databases</li>
</ul>
<ul>
<li>Testing your applications using idiomatic techniques</li>
</ul>
<ul>
<li>Adding observability to your applications</li>
</ul>
<ul>
<li>Managing configuration data from your applications</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/parro-it/awesome-micro-npm-packages/">2. Awesome Micro Npm Packages</a></h2><h3><p>Modules / Array</p>
</h3><ul>
<li><a href="https://github.com/ehmicky/fast-cartesian" rel="noopener noreferrer">fast-cartesian (‚≠ê71)</a> - Fast cartesian product.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/TheComputerM/awesome-svelte/">3. Awesome Svelte</a></h2><h3><p>UI Libraries</p>
</h3><ul>
<li><a href="https://github.com/Tommertom/svelte-ionic-app" rel="noopener noreferrer">ionic-svelte (‚≠ê36)</a> - Svelte integration with Ionic's UI for mobile app development, including many starters.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/desiderantes/awesome-vala/">4. Awesome Vala</a></h2><h3><p>Apps / Productivity</p>
</h3><ul>
<li><a href="https://gitlab.gnome.org/GNOME/gnome-calculator" rel="noopener noreferrer">GNOME Calculator</a> - The calculator app for the GNOME desktop.</li>
</ul>
<ul>
<li><a href="https://github.com/pdfpc/pdfpc" rel="noopener noreferrer">pdfpc (‚≠ê1.7k)</a> - A GTK presenter application with multi-monitor support for PDF files.</li>
</ul>
<h3><p>Libraries / Command-line</p>
</h3><ul>
<li><a href="https://github.com/naaando/console-command" rel="noopener noreferrer">console-command (‚≠ê1)</a> - Library to route command-line arguments to a Command pattern object, current implementation covers extension by inheritance or using closures.</li>
</ul>
<h3><p>Libraries / Data Structures &amp; Data Types</p>
</h3><ul>
<li><a href="https://wiki.gnome.org/Projects/Libgee" rel="noopener noreferrer">Libgee</a> - A utility library providing GObject-based interfaces and classes for commonly used data structures (lists, maps, queues, trees, etc.).</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/sindresorhus/awesome/">5. Awesome List</a></h2><h3><p>Theory</p>
</h3><ul>
<li><a href="https://github.com/YuzheSHI/awesome-agi-cocosci#readme" rel="noopener noreferrer">AGI &amp; CoCoSci (‚≠ê336)</a> - The reciprocation of Artificial General Intelligence (AGI) and Computational Cognitive Sciences (CoCoSci).</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/YuzheSHI/awesome-agi-cocosci/">6. Awesome Agi Cocosci</a></h2><h3><p>Cognitive Development / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://psycnet.apa.org/record/2012-12791-001" rel="noopener noreferrer">Reconstructing constructivism: Causal models, Bayesian learning mechanisms, and the theory theory</a> - <em><strong>Psychological Bulletin</strong></em>, 2012. [<a href="https://scholar.google.com/scholar?cluster=11218217347365817167&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Alison Gopnik's review on the constructivism idea of developmental research.</li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/1810.07528" rel="noopener noreferrer">Machine Common Sense Concept Paper</a> - <em><strong>DARPA</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=1603121108181262769&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. DARPA's perspective on integrating core knowledge from development psychology into machine intelligence systems.</li>
</ul>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Cognitive_development" rel="noopener noreferrer">Cognitive Development</a> - <em><strong>Wikipedia</strong></em>.</li>
</ul>
<ul>
<li><a href="https://doi.apa.org/doiLanding?doi=10.1037/rev0000153" rel="noopener noreferrer">Towards a rational constructivist theory of cognitive development</a> - <em><strong>Psychological Review</strong></em>, 2019. [<a href="https://scholar.google.com/scholar?cluster=3294824172745724080&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Fei Xu's review extending Gopnik's view of constructivism, with the rationality as constraint.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661312001301" rel="noopener noreferrer">The origins of inquiry: inductive inference and exploration in early childhood</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2012. [<a href="https://scholar.google.com/scholar?cluster=5189329081728071335&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Laura Schulz's review on children's exploratory play.</li>
</ul>
<ul>
<li><a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-devpsych-070120-014806" rel="noopener noreferrer">Play, Curiosity, and Cognition</a> - <em><strong>Annual Review of Developmental Psychology</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=10278208468154249192&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5" rel="noopener noreferrer">All Versions</a>]. Laura Schulz's review on children's exploratory play, which proposes a new perspective on exploratory play to explain the emergence of irrational behaviors in play.</li>
</ul>
<h3><p>Problem Solving / Human-Level Problem Solving</p>
</h3><ul>
<li><a href="https://cpilab.org/pubs/Dasgupta2018Learning.pdf" rel="noopener noreferrer">Learning to act by integrating mental simulations and physical experiments</a> - <em><strong>CogSci'18</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=7342920174595829739&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. [<a href="https://github.com/ishita-dg/SimulationVSAction" rel="noopener noreferrer">Code (‚≠ê1)</a>].</li>
</ul>
<h3><p>Problem Solving / Planning</p>
</h3><ul>
<li><a href="https://arxiv.org/pdf/2109.11082.pdf" rel="noopener noreferrer">Discovering State and Action Abstractions for Generalized Task and Motion Planning</a> - <em><strong>AAAI'22</strong></em>, 2022. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=1054368060554971920" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Problem Solving / Intrinsic Motivation</p>
</h3><ul>
<li><a href="https://psyarxiv.com/ybs7g/" rel="noopener noreferrer">Intrinsic Exploration as Empowerment in a Richly Structured Online Game</a> - 2022. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=12321757821600526668" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<ul>
<li><a href="https://gershmanlab.com/pubs/Tomov21.pdf" rel="noopener noreferrer">Multi-task reinforcement learning in humans</a> - <em><strong>Nature Human Behavior</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=14589018692074515644&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Problem Solving / Inverse Reinforcement Learning</p>
</h3><ul>
<li><a href="https://www.ijcai.org/Proceedings/07/Papers/416.pdf" rel="noopener noreferrer">Bayesian Inverse Reinforcement Learning</a> - <em><strong>IJCAI'07</strong></em>, 2007. [<a href="https://scholar.google.com/scholar?cluster=4154724070362583557&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A Bayesian account on classic inverse reinforcement learning.</li>
</ul>
<h3><p>System 1 &amp; System 2 / Dual-Coding Theory</p>
</h3><ul>
<li><a href="https://zh.pb1lib.org/book/1004349/825277" rel="noopener noreferrer">Mental Representations: A Dual Coding Approach</a> - <em><strong>Oxford University Press</strong></em>, 1990. [<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0,5&amp;q=mental+representations:+a+dual+coding+approach" rel="noopener noreferrer">All Versions</a>]. The original book on dual coding theory, in the neuroscience account of mental representation.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661321001765" rel="noopener noreferrer">Dual coding of knowledge in the human brain</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=11751507203561842501&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Yanchao Bi's review on neuroscience experiments on dual coding theory.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0896627320302798" rel="noopener noreferrer">Two Forms of Knowledge Representations in the Human Brain</a> - <em><strong>Neuron</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=16941965185680116049" rel="noopener noreferrer">All Versions</a>]. Illustrating language-derived and sensory-derived knowledge.</li>
</ul>
<h3><p>System 1 &amp; System 2 / Neural-Symbolic AI</p>
</h3><ul>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-642-59789-3_58" rel="noopener noreferrer">Regression Analysis for Interval-Valued Data</a> - <em><strong>Data Analysis, Classification, and Related Methods</strong></em>, 2000. [<a href="https://scholar.google.com/scholar?cluster=9407097855380377791&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper on symbolic regression.</li>
</ul>
<ul>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-7908-1709-6_20" rel="noopener noreferrer">Symbolic data analysis: what is it?</a> - <em><strong>Proceedings in Computational Statistics</strong></em>, 2006. [<a href="https://scholar.google.com/scholar?cluster=3730437602749399283&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<ul>
<li><a href="https://www.jair.org/index.php/jair/article/view/11172" rel="noopener noreferrer">Learning Explanatory Rules from Noisy Data</a> - <em><strong>Journal of Artificial Intelligence Research</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=2553893814364678772&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper for differential Inductive Logic Programming.</li>
</ul>
<ul>
<li><a href="https://arxiv.org/pdf/2103.01937.pdf" rel="noopener noreferrer">Neural Production Systems</a> - <em><strong>ICML'21</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=15299280949648915581&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Yoshua Bengio's perspective on slot attention model as a general production system.</li>
</ul>
<h3><p>Explainability / Strong Machine Learning</p>
</h3><ul>
<li><a href="https://link.springer.com/article/10.1007/s10994-018-5707-3" rel="noopener noreferrer">Ultra-Strong Machine Learning: comprehensibility of programs learned with ILP</a> - <em><strong>Machine Learning</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=17551060457946144913&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Stephen Muggleton's account of ultra-strong machine learning, which not only learns human understandable knowledge, but also improves human performance on the corresponding tasks.</li>
</ul>
<h3><p>Explainability / Explainable Deep Learning</p>
</h3><ul>
<li><a href="https://ieeexplore.ieee.org/document/8099837" rel="noopener noreferrer">Network dissection: Quantifying interpretability of deep visual representations</a> - <em><strong>CVPR'17</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=18069685615852396783&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. [<a href="http://netdissect.csail.mit.edu/" rel="noopener noreferrer">Project</a>]. [<a href="http://places2.csail.mit.edu/index.html" rel="noopener noreferrer">Dataset: Places365</a>]. The original paper on visualizing the class activation maps to explain convolutional neural networks.</li>
</ul>
<ul>
<li><a href="https://distill.pub/2020/circuits/zoom-in/" rel="noopener noreferrer">Zoom In: An Introduction to Circuits</a> - <em><strong>Distill</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=9053581372570691569&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A perspective on treating neural networks as circuits.</li>
</ul>
<h3><p>Embodied Intelligence / Explainable Deep Learning</p>
</h3><ul>
<li><a href="https://plato.stanford.edu/entries/embodied-cognition/" rel="noopener noreferrer">Embodied Cognition</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Embodied Cognition, which emphasizes the significance of an agent's physical body in cognitive abilities.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/content-externalism/" rel="noopener noreferrer">Externalism About the Mind</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on mind externalism, a long-term debate about the boundary of embodied intelligence.</li>
</ul>
<ul>
<li><a href="https://www.researchgate.net/profile/David-Woods-19/publication/242545872_Cognitive_Engineering_Human_Problem_Solving_with_Tools/links/542becf70cf29bbc126ac097/Cognitive-Engineering-Human-Problem-Solving-with-Tools.pdf" rel="noopener noreferrer">Cognitive engineering: Human problem solving with tools</a> - <em><strong>Human Factors</strong></em>, 1988. [<a href="https://scholar.google.com/scholar?cluster=14194840995416222723&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original idea of investigating huamn tool use in problem solving.</li>
</ul>
<ul>
<li><a href="https://psycnet.apa.org/record/1993-97340-000" rel="noopener noreferrer">Tools, language and cognition in human evolution</a> - <em><strong>Cambridge University Press</strong></em>, 1993. [<a href="https://scholar.google.com/scholar?cluster=6046350461147957220&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A classic perspective correlating human tool use with the evolution of civilization.</li>
</ul>
<ul>
<li><a href="https://icds.uoregon.edu/wp-content/uploads/2014/06/Clark-and-Chalmers-The-Extended-Mind.pdf" rel="noopener noreferrer">The Extended Mind</a> - <em><strong>Analysis</strong></em>, 1998. [<a href="https://scholar.google.com/scholar?cluster=9546561188261943866&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper on the debate of mind externalism.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661303003231" rel="noopener noreferrer">The neural bases of complex tool use in humans</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2004. [<a href="https://scholar.google.com/scholar?cluster=3612212926196611828&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A neuroscience account of human tool use.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0960982207017708" rel="noopener noreferrer">Spontaneous Metatool Use by New Caledonian Crows</a> - <em><strong>Current Biology</strong></em>, 2007. [<a href="https://scholar.google.com/scholar?cluster=9263531730425342443&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A piece of evidence that intelligent animals can take advantage of matatools to make tools for problem solving.</li>
</ul>
<ul>
<li><a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Frev0000027" rel="noopener noreferrer">Tool use and affordance: Manipulation-based versus reasoning-based approaches</a> - <em><strong>Psychological Review</strong></em>, 2016. [<a href="https://scholar.google.com/scholar?cluster=3284942486402374505&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A classic review on human tool use and affordance.</li>
</ul>
<ul>
<li><a href="https://yzhu.io/publication/tool2015cvpr/paper.pdf" rel="noopener noreferrer">Understanding Tools: Task-Oriented Object Modeling, Learning and Recognition</a> - <em><strong>CVPR'15</strong></em>, 2015. [<a href="https://scholar.google.com/scholar?cluster=4609926671953500969&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. [<a href="https://yzhu.io/publication/tool2015cvpr/" rel="noopener noreferrer">Project</a>]. The original paper introducing affordance and physically-grounded tool use into computer vision.</li>
</ul>
<h3><p>Evolutionary Intelligence / Explainable Deep Learning</p>
</h3><ul>
<li><a href="http://websites.umich.edu/~zhanglab/clubPaper/06_08_2012.pdf" rel="noopener noreferrer">Evolutionary trade-offs, Pareto optimality, and the geometry of phenotype space</a> - <em><strong>Science</strong></em>, 2012. [<a href="https://scholar.google.com/scholar?cluster=16162252507845975080&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A classic paper correlating biological trade-offs with the evolution of pareto optimality.</li>
</ul>
<ul>
<li><a href="https://link.springer.com/article/10.1007/BF01442131" rel="noopener noreferrer">Pareto optimality in multiobjective problems</a> - <em><strong>Applied Mathematics and Optimization</strong></em>, 1977. [<a href="https://scholar.google.com/scholar?cluster=11305142600366783354&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper on the pareto optimality in multiobjective problems.</li>
</ul>
<ul>
<li><a href="http://www.soft-computing.de/SMC0805.pdf" rel="noopener noreferrer">Pareto-Based Multiobjective Machine Learning: An Overview and Case Studies</a> - <em><strong>IEEE Transactions on Systems, Man, and Cybernetics</strong></em>, 2008. [<a href="https://scholar.google.com/scholar?cluster=11308312498510305429&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on the application of pareto optimality to multiobjective machine learning.</li>
</ul>
<h3><p>Causality / AI Assisted Research</p>
</h3><ul>
<li><a href="http://www.jakebowers.org/ITVExperiments/angristimbensrubin96.pdf" rel="noopener noreferrer">Identification of Causal Effects Using Instrumental Variables</a> - <em><strong>Journal of the American Statistical Association</strong></em>, 1996. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=17166265099721941605" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Causality" rel="noopener noreferrer">Causality</a> - <em><strong>Wikipedia</strong></em>. Wikipedia on causality, which is influence by which one event, process, state, or object (a cause) contributes to the production of another event, process, state, or object (an effect) where the cause is partly responsible for the effect, and the effect is partly dependent on the cause.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/causal-models/" rel="noopener noreferrer">Causal Models</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Causal models, which are mathematical models representing causal relationships within an individual system or population.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/content-causal/" rel="noopener noreferrer">Causal Theories of Mental Content</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on causal theories of mental content, which attempts to explain how thoughts can be about things.</li>
</ul>
<ul>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3241036" rel="noopener noreferrer">The Seven Tools of Causal Inference, with Reflections on Machine Learning</a> - <em><strong>Communications of the ACM</strong></em>, 2019. [<a href="https://scholar.google.com/scholar?cluster=13296019510897277617&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Judea Pearl's review on causal inference in probabilistic graph models.</li>
</ul>
<ul>
<li><a href="https://cardiacmr.hms.harvard.edu/files/cardiacmr/files/toward_causal_representation_learning.pdf" rel="noopener noreferrer">Toward Causal Representation Learning</a> - <em><strong>Proceedings of the IEEE</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=15629454810797806102&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Yoshua Bengio's review on the perspective of treating causal inference as a representation learning problem.</li>
</ul>
<ul>
<li><a href="https://cocosci.princeton.edu/tom/papers/tbci.pdf" rel="noopener noreferrer">Theory-Based Causal Induction</a> - <em><strong>Psychological Review</strong></em>, 2009. [<a href="https://scholar.google.com/scholar?cluster=13980129728092173387&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Thomas Griffiths' review on causal Bayesian theory induction.</li>
</ul>
<ul>
<li><a href="https://ojs.aaai.org//index.php/AAAI/article/view/5483" rel="noopener noreferrer">Theory-Based Causal Transfer: Integrating Instance-Level Induction and Abstract-Level Structure Learning</a> - <em><strong>AAAI'20</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=9411622427165139667&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A computatinoal account on causal transfer.</li>
</ul>
<ul>
<li><a href="https://www.psych.uni-goettingen.de/de/cognition/publikationen-dateien-waldmann/2006_science.pdf" rel="noopener noreferrer">Causal Reasoning in Rats</a> - <em><strong>Science</strong></em>, 2006. [<a href="https://scholar.google.com/scholar?cluster=17987039255457850949&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A piece of evidence for the capability of causal reasoning in intelligent animals.</li>
</ul>
<ul>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.183.4674&amp;rep=rep1&amp;type=pdf" rel="noopener noreferrer">Do New Caledonian crows solve physical problems through causal reasoning?</a> - <em><strong>Proceedings of the Royal Society B: Biological Sciences</strong></em>, 2009. [<a href="https://scholar.google.com/scholar?cluster=18374985546068164189&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A piece of evidence for the capability of causal reasoning in intelligent animals.</li>
</ul>
<h3><p>Methodologies for Experiments / Quantitative Analysis</p>
</h3><ul>
<li><a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-psych-122414-033702" rel="noopener noreferrer">Experiments with More Than One Random Factor: Designs, Analytic Models, and Statistical Power</a> - <em><strong>Annual Review of Psychology</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=6652444619934494760&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review of the quantitative analysis techniques for behavioral studies.</li>
</ul>
<h3><p>Methodologies for Experiments / Scaling Up Behavioral Studies</p>
</h3><ul>
<li><a href="https://cocosci.princeton.edu/jpeterson/papers/peterson2021-science.pdf" rel="noopener noreferrer">Using large-scale experiments and machine learning to discover theories of human decision-making</a> - <em><strong>Science</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=7456250222852859810&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A piece of evidence for the merits brought by large-scale behavioral studies in social science.</li>
</ul>
<ul>
<li><a href="https://web.archive.org/web/20170809024454id_/http://www.kevinjing.com/visual_search_at_pinterest.pdf" rel="noopener noreferrer">Visual Search at Pinterest</a> - <em><strong>KDD'15</strong></em>, 2015. [<a href="https://scholar.google.com/scholar?cluster=2051024301293529405&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Large scale user study in the development of the recommendations system by Pinterest.</li>
</ul>
<h3><p>Methodologies for Experiments / Question Answering</p>
</h3><ul>
<li><a href="https://cogsci.mindmodeling.org/2016/papers/0122/paper0122.pdf" rel="noopener noreferrer">Searching large hypothesis spaces by asking questions</a> - <em><strong>CogSci'16</strong></em>, 2016. [<a href="https://scholar.google.com/scholar?cluster=3398849603439166012&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A behavioral study for the 20 questions game.</li>
</ul>
<ul>
<li><a href="https://gureckislab.org/papers/RotheLakeGureckis-2016cogsci.pdf" rel="noopener noreferrer">Asking and evaluating natural language questions</a> - <em><strong>CogSci'16</strong></em>, 2016. [<a href="https://scholar.google.com/scholar?cluster=34641833161282231&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A behavioral study for the battleship game.</li>
</ul>
<h3><p>Methodologies for Experiments / Human-Machine Comparison</p>
</h3><ul>
<li><a href="https://psycnet.apa.org/record/1973-00249-001" rel="noopener noreferrer">Elimination by aspects: A theory of choice</a> - <em><strong>Psychological Review</strong></em>, 1972. [<a href="https://scholar.google.com/scholar?cluster=1633792484482810297&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Herbert Simon's early experiments on computer aided behavioral studies.</li>
</ul>
<h3><p>Methodologies for Experiments / Virtual Reality</p>
</h3><ul>
<li><a href="https://www.nature.com/articles/nn948" rel="noopener noreferrer">Virtual reality in behavioral neuroscience and beyond</a> - <em><strong>Nature Neuroscience</strong></em>, 2002. [<a href="https://scholar.google.com/scholar?cluster=12168354203281280346&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A classic review on the early applications of Virtual Reality to behavioral studies.</li>
</ul>
<ul>
<li><a href="https://psycnet.apa.org/record/2022-60836-006" rel="noopener noreferrer">The psychology of virtual reality</a> - <em><strong>The psychology of technology: Social science research in the age of Big Data (pp. 155‚Äì193), American Psychological Association</strong></em>, 2022. [<a href="https://scholar.google.com/scholar?cluster=11535480055596209683&amp;hl=en&amp;as_sdt=0,5&amp;as_ylo=2021" rel="noopener noreferrer">All Versions</a>]. Jeremy Bailenson's review on the applications of Virtual Reality to behavioral studies.</li>
</ul>
<h3><p>Meta-Level Considerations / Meta Learning</p>
</h3><ul>
<li><a href="https://arxiv.org/pdf/2201.03916.pdf" rel="noopener noreferrer">Automated Reinforcement Learning (AutoRL): A Survey and Open Problems</a> - 2022. [<a href="https://scholar.google.com/scholar?cluster=9025378857688824887&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on AutoRL.</li>
</ul>
<h3><p>David Marr / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://usa1lib.org/book/1223444/8e5ca8" rel="noopener noreferrer">Vision: A Computational Investigation into the Human Representation and Processing of Visual Information</a> - <em><strong>MIT Press</strong></em>, 1982. [<a href="https://scholar.google.com/scholar?cluster=14386368570811483142&amp;hl=en&amp;as_sdt=0,44" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Meta-Level Considerations / Marr's Levels of Analysis</p>
</h3><ul>
<li><a href="https://cocosci.princeton.edu/tom/papers/LabPublications/BridgingLevelsAnalysis.pdf" rel="noopener noreferrer">Bridging Levels of Analysis for Probabilistic Models of Cognition</a> - <em><strong>Current Directions in Psychological Science</strong></em>, 2012. [<a href="https://scholar.google.com/scholar?cluster=5063382112136991296&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A Marr's paradigm account on probabilistic models.</li>
</ul>
<ul>
<li><a href="https://people.csail.mit.edu/pkrafft/papers/krafft-griffiths-levels-css.pdf" rel="noopener noreferrer">Levels of Analysis in Computational Social Science</a> - <em><strong>CogSci'18</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=10178929388985626844&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A Marr's paradigm account on computational social science.</li>
</ul>
<ul>
<li><a href="https://baicsworkshop.github.io/pdf/BAICS_6.pdf" rel="noopener noreferrer">Levels of Analysis for Machine Learning</a> - <em><strong>ICLR'20 Bridging AI and Cognitive Science Workshop</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=13819038971626384115&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A Marr's paradigm account on machine learning.</li>
</ul>
<h3><p>Meta-Level Considerations / Gestalt</p>
</h3><ul>
<li><a href="https://psycnet.apa.org/record/2007-10344-001" rel="noopener noreferrer">Gestalt theory</a> - <em><strong>A source book of Gestalt psychology</strong></em>, 1938. [<a href="https://scholar.google.com/scholar?cluster=18133275659218646817&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original book on Gestalt psychology.</li>
</ul>
<ul>
<li><a href="https://link.springer.com/article/10.1007/BF00422382" rel="noopener noreferrer">Gestalt Psychology</a> - <em><strong>Psychologische Forschung</strong></em>, 1967. [<a href="https://scholar.google.com/scholar?cluster=16023098380090751616&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Wolfgang K√∂hler's review on Gestalt psychology.</li>
</ul>
<ul>
<li><a href="https://hk1lib.org/book/1244721/20ddc5" rel="noopener noreferrer">Deep Learning: How the Mind Overrides Experience</a> - <em><strong>Cambridge University Press</strong></em>, 2011. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=231021877034210140" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Meta-Level Considerations / Rationality</p>
</h3><ul>
<li><a href="https://plato.stanford.edu/entries/bounded-rationality/" rel="noopener noreferrer">Bounded Rationality</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Bounded Rationality, an elementary hypothesis of human intelligence in psychology and ecology.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/rationality-instrumental/" rel="noopener noreferrer">Instrumental Rationality</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Instrumental Rationality, a dabate on whether an agent's decision is made intentionally or out of rational coherence.</li>
</ul>
<ul>
<li><a href="https://gershmanlab.com/pubs/GershmanHorvitzTenenbaum15.pdf" rel="noopener noreferrer">Computational rationality: A converging paradigm for intelligence in brains, minds, and machines</a> - <em><strong>Science</strong></em>, 2015. [<a href="https://scholar.google.com/scholar?cluster=7744057022238735461&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on the rationality of Bayesian computational models.</li>
</ul>
<ul>
<li><a href="https://cocosci.princeton.edu/papers/lieder_resource.pdf" rel="noopener noreferrer">Resource-rational analysis: Understanding human cognition as the optimal use of limited computational resources</a> - <em><strong>Behavioral and Brain Sciences</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=1642626865293965288&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A resource-rational account on interpreting human intelligence.</li>
</ul>
<h3><p>Meta-Level Considerations / Cognitive Architecture</p>
</h3><ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661321001285" rel="noopener noreferrer">The secret life of predictive brains: what's spontaneous activity for?</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=719229834892860829&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A neuroscience account on brain as a generative model.</li>
</ul>
<ul>
<li><a href="http://act-r.psy.cmu.edu/wordpress/wp-content/uploads/2013/09/Anderson91.pdf" rel="noopener noreferrer">Is human cognition adaptive?</a> - <em><strong>Behavioral and Brain Sciences</strong></em>, 1991. [<a href="https://scholar.google.com/scholar?cluster=3639936076538071052&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper introducing the adaptation perspective of human intelligence, the theoretical basis of the ACT cognitive architecture.</li>
</ul>
<ul>
<li><a href="https://doi.org/10.1126/SCIENCE.AAN8871" rel="noopener noreferrer">What is consciousness, and could machines have it?</a> - <em><strong>Science</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=6932714857132107942&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A perspective on the two levels of consciousness in machine intelligence.</li>
</ul>
<h3><p>Theory of Mind / AI Assisted Research</p>
</h3><ul>
<li><a href="https://en.wikipedia.org/wiki/Theory_of_mind" rel="noopener noreferrer">Theory of Mind</a> - <em><strong>Wikipedia</strong></em>. Wikipedia on Theory of Mind (ToM), a cognitive capability that estimating others' goal, belief, and desire.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661316301565?via%3Dihub" rel="noopener noreferrer">Bayesian Brains without Probabilities</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2016. [<a href="https://scholar.google.com/scholar?cluster=13076510377612067772&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A perspective on human probabilistic modeling without explicit probabilistic computation.</li>
</ul>
<ul>
<li><a href="https://www.nature.com/articles/s41598-018-23618-6" rel="noopener noreferrer">Using human brain activity to guide machine learning</a> - <em><strong>Scientific Report</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=12987955253653036948&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<ul>
<li><a href="https://dspace.mit.edu/bitstream/handle/1721.1/112291/ivc_full_preprint.pdf?sequence=1&amp;isAllowed=y" rel="noopener noreferrer">Ten-month-old infants infer the value of goals from the costs of actions</a> - <em><strong>Science</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=11862940312128630925&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A piece of evidence for children's capability on ToM.</li>
</ul>
<ul>
<li><a href="https://arxiv.org/pdf/2011.05558.pdf" rel="noopener noreferrer">Intentonomy: a Dataset and Study towards Human Intent Understanding</a> - <em><strong>CVPR'21</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=5268870345003195142&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A large-scale database on human intentionally-posted images on social media.</li>
</ul>
<ul>
<li><a href="https://www.tshu.io/HeiderSimmel/CogSci20/Flatland_CogSci20.pdf" rel="noopener noreferrer">Adventures in Flatland: Perceiving Social Interactions Under Physical Dynamics</a> - <em><strong>CogSci'20</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=1928005249823745390&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Analogy / AI Assisted Research</p>
</h3><ul>
<li><a href="https://plato.stanford.edu/entries/metaphor/" rel="noopener noreferrer">Metaphor</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Metaphor, a poetically or rhetorically ambitious use of words, a figurative as opposed to literal use.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/reasoning-analogy/" rel="noopener noreferrer">Analogy and Analogical Reasoning</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Analogy, a comparison between two objects, or systems of objects, that highlights respects in which they are thought to be similar.</li>
</ul>
<ul>
<li><a href="https://1lib.net/book/1165963/e9aa3d" rel="noopener noreferrer">A Cognitive Theory of Metaphor</a> - <em><strong>MIT Press</strong></em>, 1985. [<a href="https://scholar.google.com/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=a+cognitive+theory+of+metaphor&amp;btnG=" rel="noopener noreferrer">All Versions</a>]. A cognitive account on Metaphor.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/0004370289900775" rel="noopener noreferrer">The structure-mapping engine: Algorithm and examples</a> - <em><strong>Artificial Intelligence</strong></em>, 1989. [<a href="https://scholar.google.com/scholar?cluster=16104901325436513899&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A computational implementation of analogy.</li>
</ul>
<ul>
<li><a href="https://cogsci.ucsd.edu/~coulson/203/gentner-markman-97.pdf" rel="noopener noreferrer">Structure mapping in analogy and similarity</a> - <em><strong>American Psychologist</strong></em>, 1997. [<a href="https://scholar.google.com/scholar?cluster=3497411606978611830&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A perspective unifying analogy and similarity judgement.</li>
</ul>
<ul>
<li><a href="https://psycnet.apa.org/record/2022-26663-001" rel="noopener noreferrer">A theory of relation learning and cross-domain generalization</a> - <em><strong>Psychological Review</strong></em>, 2022. [<a href="https://scholar.google.com/scholar?cluster=8559821723107269122&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on the perspective of treating analogy as cross-domain generalization.</li>
</ul>
<ul>
<li><a href="https://proceedings.mlr.press/v97/allen19a.html" rel="noopener noreferrer">Analogies Explained: Towards Understanding Word Embeddings</a> - <em><strong>ICML'19</strong></em>, 2019. [<a href="https://scholar.google.com/scholar?cluster=15445529659618849253&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Explaining the analogy capability in word embeddings.</li>
</ul>
<ul>
<li><a href="http://proceedings.mlr.press/v28/juhwang13.pdf" rel="noopener noreferrer">Analogy-preserving Semantic Embedding for Visual Object Categorization</a> - <em><strong>ICML'13</strong></em>, 2013. [<a href="https://scholar.google.com/scholar?cluster=9332855910734484101&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The first application of analogy to machine learning.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0004370218301863" rel="noopener noreferrer">Analogy between concepts</a> - <em><strong>Artificial Intelligence</strong></em>, 2019. [<a href="https://scholar.google.com/scholar?cluster=1397905953174123757&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A mathematical account on analogy.</li>
</ul>
<ul>
<li><a href="https://escholarship.org/content/qt3j2576vv/qt3j2576vv.pdf" rel="noopener noreferrer">Preschoolers and adults make inferences from novel metaphors</a> - <em><strong>CogSci'22</strong></em>, 2022. [<a href="https://scholar.google.com/scholar?cluster=16038983545360341739&amp;hl=en&amp;as_sdt=0,44" rel="noopener noreferrer">All Versions</a>]. A piece of evidence that understanding metaphors is capable for different cognitive development phases.</li>
</ul>
<h3><p>Commonsense / Intuitive Physics</p>
</h3><ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661317301262" rel="noopener noreferrer">Intuitive Physics: Current Research and Controversies</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?start=0&amp;hl=en&amp;as_sdt=0,5&amp;cluster=12085981794958916203" rel="noopener noreferrer">All Versions</a>]. Hongjing Lu's review on intuitive physics.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1364661317301134" rel="noopener noreferrer">Mind Games: Game Engines as an Architecture for Intuitive Physics</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=14527964477161848029&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5" rel="noopener noreferrer">All Versions</a>]. Tomer Ullman's review on simulation-based intuitive physics.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0010028521000190" rel="noopener noreferrer">Limits on Simulation Approaches in Intuitive Physics</a> - <em><strong>Cognitive Psychology</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cluster=6329029167380621767" rel="noopener noreferrer">All Versions</a>]. Ernest Davis's perspective against intuitive physics, that physcial reasoning is logical reasoning instead of intuition.</li>
</ul>
<h3><p>Commonsense / AI Commonsense Reasoning</p>
</h3><ul>
<li><a href="https://link.springer.com/chapter/10.1007%2F3-540-53487-3_59" rel="noopener noreferrer">Towards a theory of commonsense visual reasoning</a> - <em><strong>FSTTCS</strong></em>, 1990. [<a href="https://scholar.google.com/scholar?cluster=13178231862265713961&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper on visual commonsense.</li>
</ul>
<ul>
<li><a href="http://cs.wellesley.edu/~cs125/reading/commonsenseAI.pdf" rel="noopener noreferrer">Commonsense reasoning and commonsense knowledge in artificial intelligence</a> - <em><strong>Communications of the ACM</strong></em>, 2015. [<a href="https://scholar.google.com/scholar?cluster=13786590180441485203&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Gary Marcus's review on commonsense knowledge in AI.</li>
</ul>
<ul>
<li><a href="https://openreview.net/pdf?id=Byg1v1HKDB" rel="noopener noreferrer">Abductive Commonsense Reasoning</a> - <em><strong>ICLR'20</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=16544200144479839958&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Abductive commonsense reasoning on large language models.</li>
</ul>
<ul>
<li><a href="https://aclanthology.org/2020.emnlp-main.703.pdf" rel="noopener noreferrer">Experience Grounds Language</a> - <em><strong>EMNLP'20</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=3734668471751920487&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A perspective on the furture of computational linguistics research---commonsense-driven and embodied language.</li>
</ul>
<h3><p>Commonsense / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://faculty.cc.gatech.edu/~isbell/classes/reading/papers/lenat95cyc.pdf" rel="noopener noreferrer">CYC: A Large-Scale Investment in Knowledge Infrastructure</a> - <em><strong>Communications of the ACM</strong></em>, 1995. [<a href="https://scholar.google.com/scholar?cluster=6505009388871605141&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The first attempt to build large-scale commonse knoweldgebase from human knowledge.</li>
</ul>
<ul>
<li><a href="https://www.aaai.org/Library/Symposia/Spring/2002/ss02-09-011.php" rel="noopener noreferrer">The Public Acquisition of Commonsense Knowledge</a> - <em><strong>Proceedings of AAAI Spring Symposium on Acquiring (and Using) Linguistic (and World) Knowledge for Information Access</strong></em>, 2002. [<a href="https://scholar.google.com/scholar?cluster=12533779219524472080&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The first attempt for acquring commonsense knowlege from humans' activities on the internet.</li>
</ul>
<h3><p>Inductive Logic &amp; Program Synthesis / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://plato.stanford.edu/entries/logic-inductive/" rel="noopener noreferrer">Inductive Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Inductive Logic, which is a logic of evidential support.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/modeltheory-fo/" rel="noopener noreferrer">First-order Model Theory</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on First-order Model Theory, which is a branch of mathematics that deals with the relationships between descriptions in first-order languages and the structures that satisfy these descriptions.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-paraconsistent/" rel="noopener noreferrer">Paraconsistent Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Paraconsistent Logic, where any logic is paraconsistent as long as it is not explosive.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logical-consequence/" rel="noopener noreferrer">Logical Consequence</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Logical Consequence, which is about the relation between premises and conclusions in valid arguments.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logical-pluralism/" rel="noopener noreferrer">Logic Pluralism</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Logic Pluralism, which is the view that there is more than one correct logic.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-firstorder-emergence/" rel="noopener noreferrer">The Emergence of First-Order Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on the emergence of first-order logic, mainly about first-order logic is natural retrospect.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-higher-order/" rel="noopener noreferrer">Second-order and Higher-order Logic</a> - <em><strong>Plato Stanford</strong></em>.</li>
</ul>
<ul>
<li><a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/10/program_synthesis_now.pdf" rel="noopener noreferrer">Program Synthesis</a> - <em><strong>Foundations and Trends in Programming Languages</strong></em>, 2017. [<a href="https://scholar.google.com/scholar?cluster=5442933587668978421&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Sumit Gulwani's comprehensive review on program synthesis.</li>
</ul>
<ul>
<li><a href="https://www.ijcai.org/Proceedings/83-1/Papers/109.pdf" rel="noopener noreferrer">The Discovery of the Equator or Concept Driven Learning</a> - <em><strong>IJCAI'83</strong></em>, 1983. [<a href="https://scholar.google.com/scholar?cluster=15712225225140903169&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The original paper on second-order metarules.</li>
</ul>
<ul>
<li><a href="http://www.doc.ic.ac.uk/~shm/Papers/metagol_gram.pdf" rel="noopener noreferrer">Meta-interpretive learning: application to grammatical inference</a> - <em><strong>Machine Learning</strong></em>, 2014. [<a href="https://scholar.google.com/scholar?cluster=17075313112718885592&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. Stephen Muggleton's original paper on Meta-Interpretive Learning (MIL).</li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2008.07912" rel="noopener noreferrer">Inductive logic programming at 30: a new introduction</a> - <em><strong>Journal of Artificial Intelligence Research</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=317114056670544302&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A 30-year comprehensive review on Inductive Logic Programming.</li>
</ul>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0004370204000591" rel="noopener noreferrer">Qualitative choice logic</a> - <em><strong>Artificial Intelligence</strong></em>, 2004. [<a href="https://scholar.google.com/scholar?cluster=1586187056162326386&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Knowledge Representation / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://1lib.net/book/511192/9eab86" rel="noopener noreferrer">Handbook of Knowledge Representation</a> - <em><strong>Elsevier</strong></em>, 2008. [<a href="https://scholar.google.com/scholar?cluster=14732064619564679879&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A pragmatical handbook for all kinds of knowledge representation modes.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-ontology/" rel="noopener noreferrer">Logic and Ontology</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on logic and ontology, mainly about the intersections of logic and ontology in many significant philosophy problems.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/language-thought/" rel="noopener noreferrer">The Language of Thought Hypothesis</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on the laugnage of though hypothesis, which proposes that thinking occurs in a mental language.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/scientific-representation/" rel="noopener noreferrer">Scientific Representation</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on scientific representation, focusing on how scientific models represent their target systems.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/self-knowledge/" rel="noopener noreferrer">Self-Knowledge</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on self-knowledge, which standardly refers to knowledge of one's own mental states‚Äîthat is, of what one is feeling or thinking, or what one believes or desires.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/supervenience/" rel="noopener noreferrer">Supervenience</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on supervenience, where a set of properties A supervenes upon another set B just in case no two things can differ with respect to A-properties without also differing with respect to their B-properties.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-dialogical/" rel="noopener noreferrer">Dialogical Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on dialogical logic, which is a dialogue-based approach to logic and argumentation rooted in a research tradition that goes back to dialectics in Greek Antiquity, when problems were approached through dialogues in which opposing parties discussed a thesis through questions and answers.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-temporal/" rel="noopener noreferrer">Temporal Logic</a> - <em><strong>Plato Stanford</strong></em>.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-modal/" rel="noopener noreferrer">Modal Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Modal Logic, which is the study of the deductive behavior of the expressions 'it is necessary that' and 'it is possible that'.</li>
</ul>
<ul>
<li><a href="https://plato.stanford.edu/entries/logic-epistemic/" rel="noopener noreferrer">Epistemic Logic</a> - <em><strong>Plato Stanford</strong></em>. A computational philosophy account on Epistemic Logic, which is a subfield of epistemology concerned with logical approaches to knowledge, belief and related notions.</li>
</ul>
<ul>
<li><a href="https://perception.jhu.edu/files/PDFs/21_Relations/HafriFirestone_2021_SeeingRelations_TiCS.pdf" rel="noopener noreferrer">The Perception of Relations</a> - <em><strong>Trends in Cognitive Sciences</strong></em>, 2021. [<a href="https://scholar.google.com/scholar?cluster=12190078466818849725&amp;hl=en&amp;as_sdt=2005&amp;sciodt=0,5" rel="noopener noreferrer">All Versions</a>]. Chaz Firestone's review on the perception of relation, in constrast to the conventional reasoning view.</li>
</ul>
<ul>
<li><a href="http://www.charleskemp.com/papers/KempGT08.pdf" rel="noopener noreferrer">Theory Acquisition and the Language of Thought</a> - <em><strong>CogSci'08</strong></em>, 2008. [<a href="https://scholar.google.com/scholar?cluster=1839916602381147749&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<h3><p>Learning in the Open World / Commonsense Knowledgebase</p>
</h3><ul>
<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8413121" rel="noopener noreferrer">Zero-Shot Learning‚ÄîA Comprehensive Evaluation of the Good, the Bad and the Ugly</a> - <em><strong>IEEE Transactions on Pattern Analysis and Machine Intelligence</strong></em>, 2018. [<a href="https://scholar.google.com/scholar?cluster=11909080239486864961&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on zero-shot learning.</li>
</ul>
<ul>
<li><a href="https://www.4paradigm.com/upload/file/20210427/20210427225045_12063.pdf" rel="noopener noreferrer">Generalizing from a few examples: A survey on few-shot learning</a> - <em><strong>ACM Computing Survey</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=7932202448069313464&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>].</li>
</ul>
<ul>
<li><a href="https://ieeexplore.ieee.org/document/7298799" rel="noopener noreferrer">Towards Open World Recognition</a> - <em><strong>CVPR'15</strong></em>, 2015. [<a href="https://scholar.google.com/scholar?cluster=856704237994181529&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. The first paper introducing the problem of open-world recognition.</li>
</ul>
<ul>
<li><a href="https://arxiv.org/pdf/2007.02519.pdf" rel="noopener noreferrer">In the Wild: From ML Models to Pragmatic ML Systems</a> - <em><strong>ICLR'20</strong></em>, 2020. [<a href="https://scholar.google.com/scholar?cluster=15243890330014986346&amp;hl=en&amp;as_sdt=0,5" rel="noopener noreferrer">All Versions</a>]. A comprehensive review on incremental machine learning.</li>
</ul>
<hr><ul><li> Prev: <a href="/2022/07/24/">Jul 24, 2022</a></li><li> Next: <a href="/2022/07/22/">Jul 22, 2022</a></li></ul>
    </main>
  </body>
</html>
