{
  "version": "https://jsonfeed.org/version/1",
  "icon": "https://www.trackawesomelist.com/icon.png",
  "favicon": "https://www.trackawesomelist.com/favicon.ico",
  "language": "en",
  "title": "Track Awesome Qa Updates Daily",
  "_seo_title": "Track Awesome Qa (seriousran/awesome-qa) Updates Daily - Track Awesome List",
  "_site_title": "Track Awesome List",
  "description": "üòé A curated list of the Question Answering (QA)",
  "home_page_url": "https://www.trackawesomelist.com/seriousran/awesome-qa/",
  "feed_url": "https://www.trackawesomelist.com/seriousran/awesome-qa/feed.json",
  "items": [
    {
      "id": "https://www.trackawesomelist.com/2021/01/13/",
      "title": "Awesome Qa Updates on Jan 13, 2021",
      "_short_title": "Jan 13, 2021",
      "_slug": "2021/01/13/",
      "summary": "1 awesome projects updated on Jan 13, 2021",
      "_filepath": "/content/2021/01/13/README.md",
      "url": "https://www.trackawesomelist.com/2021/01/13/",
      "date_published": "2021-01-13T14:58:52.000Z",
      "date_modified": "2021-01-13T14:58:52.000Z",
      "content_text": "\n\n### Recent QA Models\n\n*   DilBert: Delaying Interaction Layers in Transformer-based Encoders for Efficient Open Domain Question Answering (2020)\n    *   paper: <https://arxiv.org/pdf/2010.08422.pdf>\n    *   github: [https://github.com/wissam-sib/dilbert (‚≠ê16)](https://github.com/wissam-sib/dilbert)",
      "content_html": "<h3><p>Recent QA Models</p>\n</h3>\n<ul>\n<li>DilBert: Delaying Interaction Layers in Transformer-based Encoders for Efficient Open Domain Question Answering (2020)<ul>\n<li>paper: <a href=\"https://arxiv.org/pdf/2010.08422.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/2010.08422.pdf</a></li>\n<li>github: <a href=\"https://github.com/wissam-sib/dilbert\" rel=\"noopener noreferrer\">https://github.com/wissam-sib/dilbert (‚≠ê16)</a></li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2020/05/05/",
      "title": "Awesome Qa Updates on May 05, 2020",
      "_short_title": "May 05, 2020",
      "_slug": "2020/05/05/",
      "summary": "24 awesome projects updated on May 05, 2020",
      "_filepath": "/content/2020/05/05/README.md",
      "url": "https://www.trackawesomelist.com/2020/05/05/",
      "date_published": "2020-05-05T11:09:44.000Z",
      "date_modified": "2020-05-05T11:09:44.000Z",
      "content_text": "\n\n### Recent QA Models\n\n*   UnifiedQA: Crossing Format Boundaries With a Single QA System (2020)\n    *   Demo: <https://unifiedqa.apps.allenai.org/>\n*   ProQA: Resource-efficient method for pretraining a dense corpus index for open-domain QA and IR. (2020)\n    *   paper: <https://arxiv.org/pdf/2005.00038.pdf>\n    *   github: [https://github.com/xwhan/ProQA (‚≠ê43)](https://github.com/xwhan/ProQA)\n*   TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages (2020)\n    *   paper: <https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf>\n*   Retrospective Reader for Machine Reading Comprehension\n    *   paper: <https://arxiv.org/pdf/2001.09694v2.pdf>\n*   TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection (AAAI 2020)\n    *   paper: <https://arxiv.org/pdf/1911.04118.pdf>\n\n### Recent Language Models\n\n*   [ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators](https://openreview.net/pdf?id=r1xMH1BtvB), Kevin Clark, et al., ICLR, 2020.\n*   [TinyBERT: Distilling BERT for Natural Language Understanding](https://openreview.net/pdf?id=rJx0Q6EFPB), Xiaoqi Jiao, et al., ICLR, 2020.\n*   [MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers](https://arxiv.org/abs/2002.10957), Wenhui Wang, et al., arXiv, 2020.\n*   [T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683), Colin Raffel, et al., arXiv preprint, 2019.\n*   [ERNIE: Enhanced Language Representation with Informative Entities](https://arxiv.org/abs/1905.07129), Zhengyan Zhang, et al., ACL, 2019.\n*   [XLNet: Generalized Autoregressive Pretraining for Language Understanding](https://arxiv.org/abs/1906.08237), Zhilin Yang, et al., arXiv preprint, 2019.\n*   [ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942), Zhenzhong Lan, et al., arXiv preprint, 2019.\n*   [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692), Yinhan Liu, et al., arXiv preprint, 2019.\n*   [DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter](https://arxiv.org/pdf/1910.01108.pdf), Victor sanh, et al., arXiv, 2019.\n*   [SpanBERT: Improving Pre-training by Representing and Predicting Spans](https://arxiv.org/pdf/1907.10529v3.pdf), Mandar Joshi, et al., TACL, 2019.\n*   [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805), Jacob Devlin, et al., NAACL 2019, 2018.\n\n### Arxiv\n\n*   [Investigating the Successes and Failures of BERT for Passage Re-Ranking](https://arxiv.org/abs/1905.01758), Harshith Padigela, et al., arXiv preprint, May 2019.\n*   [BERT with History Answer Embedding for Conversational Question Answering](https://arxiv.org/abs/1905.05412), Chen Qu, et al., arXiv preprint, May 2019.\n*   [Understanding the Behaviors of BERT in Ranking](https://arxiv.org/abs/1904.07531), Yifan Qiao, et al., arXiv preprint, Apr 2019.\n*   [BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis](https://arxiv.org/abs/1904.02232), Hu Xu, et al., arXiv preprint, Apr 2019.\n*   [End-to-End Open-Domain Question Answering with BERTserini](https://arxiv.org/abs/1902.01718), Wei Yang, et al., arXiv preprint, Feb 2019.\n*   [A BERT Baseline for the Natural Questions](https://arxiv.org/abs/1901.08634), Chris Alberti, et al., arXiv preprint, Jan 2019.\n*   [Passage Re-ranking with BERT](https://arxiv.org/abs/1901.04085), Rodrigo Nogueira, et al., arXiv preprint, Jan 2019.\n*   [SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering](https://arxiv.org/abs/1812.03593), Chenguang Zhu, et al., arXiv, Dec 2018.",
      "content_html": "<h3><p>Recent QA Models</p>\n</h3>\n<ul>\n<li>UnifiedQA: Crossing Format Boundaries With a Single QA System (2020)<ul>\n<li>Demo: <a href=\"https://unifiedqa.apps.allenai.org/\" rel=\"noopener noreferrer\">https://unifiedqa.apps.allenai.org/</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>ProQA: Resource-efficient method for pretraining a dense corpus index for open-domain QA and IR. (2020)<ul>\n<li>paper: <a href=\"https://arxiv.org/pdf/2005.00038.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/2005.00038.pdf</a></li>\n<li>github: <a href=\"https://github.com/xwhan/ProQA\" rel=\"noopener noreferrer\">https://github.com/xwhan/ProQA (‚≠ê43)</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>TYDI QA: A Benchmark for Information-Seeking Question Answering in Typologically Diverse Languages (2020)<ul>\n<li>paper: <a href=\"https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/ftp/arxiv/papers/2003/2003.05002.pdf</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>Retrospective Reader for Machine Reading Comprehension<ul>\n<li>paper: <a href=\"https://arxiv.org/pdf/2001.09694v2.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/2001.09694v2.pdf</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection (AAAI 2020)<ul>\n<li>paper: <a href=\"https://arxiv.org/pdf/1911.04118.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/1911.04118.pdf</a></li>\n</ul>\n</li>\n</ul>\n<h3><p>Recent Language Models</p>\n</h3>\n<ul>\n<li><a href=\"https://openreview.net/pdf?id=r1xMH1BtvB\" rel=\"noopener noreferrer\">ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</a>, Kevin Clark, et al., ICLR, 2020.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://openreview.net/pdf?id=rJx0Q6EFPB\" rel=\"noopener noreferrer\">TinyBERT: Distilling BERT for Natural Language Understanding</a>, Xiaoqi Jiao, et al., ICLR, 2020.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/2002.10957\" rel=\"noopener noreferrer\">MINILM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers</a>, Wenhui Wang, et al., arXiv, 2020.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1910.10683\" rel=\"noopener noreferrer\">T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a>, Colin Raffel, et al., arXiv preprint, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1905.07129\" rel=\"noopener noreferrer\">ERNIE: Enhanced Language Representation with Informative Entities</a>, Zhengyan Zhang, et al., ACL, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1906.08237\" rel=\"noopener noreferrer\">XLNet: Generalized Autoregressive Pretraining for Language Understanding</a>, Zhilin Yang, et al., arXiv preprint, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1909.11942\" rel=\"noopener noreferrer\">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</a>, Zhenzhong Lan, et al., arXiv preprint, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1907.11692\" rel=\"noopener noreferrer\">RoBERTa: A Robustly Optimized BERT Pretraining Approach</a>, Yinhan Liu, et al., arXiv preprint, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1910.01108.pdf\" rel=\"noopener noreferrer\">DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter</a>, Victor sanh, et al., arXiv, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1907.10529v3.pdf\" rel=\"noopener noreferrer\">SpanBERT: Improving Pre-training by Representing and Predicting Spans</a>, Mandar Joshi, et al., TACL, 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1810.04805\" rel=\"noopener noreferrer\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>, Jacob Devlin, et al., NAACL 2019, 2018.</li>\n</ul>\n<h3><p>Arxiv</p>\n</h3>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1905.01758\" rel=\"noopener noreferrer\">Investigating the Successes and Failures of BERT for Passage Re-Ranking</a>, Harshith Padigela, et al., arXiv preprint, May 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1905.05412\" rel=\"noopener noreferrer\">BERT with History Answer Embedding for Conversational Question Answering</a>, Chen Qu, et al., arXiv preprint, May 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.07531\" rel=\"noopener noreferrer\">Understanding the Behaviors of BERT in Ranking</a>, Yifan Qiao, et al., arXiv preprint, Apr 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1904.02232\" rel=\"noopener noreferrer\">BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis</a>, Hu Xu, et al., arXiv preprint, Apr 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1902.01718\" rel=\"noopener noreferrer\">End-to-End Open-Domain Question Answering with BERTserini</a>, Wei Yang, et al., arXiv preprint, Feb 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1901.08634\" rel=\"noopener noreferrer\">A BERT Baseline for the Natural Questions</a>, Chris Alberti, et al., arXiv preprint, Jan 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1901.04085\" rel=\"noopener noreferrer\">Passage Re-ranking with BERT</a>, Rodrigo Nogueira, et al., arXiv preprint, Jan 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1812.03593\" rel=\"noopener noreferrer\">SDNet: Contextualized Attention-based Deep Network for Conversational Question Answering</a>, Chenguang Zhu, et al., arXiv, Dec 2018.</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2019/12/12/",
      "title": "Awesome Qa Updates on Dec 12, 2019",
      "_short_title": "Dec 12, 2019",
      "_slug": "2019/12/12/",
      "summary": "19 awesome projects updated on Dec 12, 2019",
      "_filepath": "/content/2019/12/12/README.md",
      "url": "https://www.trackawesomelist.com/2019/12/12/",
      "date_published": "2019-12-12T02:00:58.000Z",
      "date_modified": "2019-12-12T02:00:58.000Z",
      "content_text": "\n\n### AAAI 2020\n\n*   [TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection](https://arxiv.org/pdf/1911.04118.pdf), Siddhant Garg, et al., AAAI 2020, Nov 2019.\n\n### ACL 2019\n\n*   [Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications](https://arxiv.org/pdf/1906.02829v1.pdf), Wei Zhao, et al., ACL 2019, Jun 2019.\n*   [Cognitive Graph for Multi-Hop Reading Comprehension at Scale](https://arxiv.org/pdf/1905.05460v2.pdf), Ming Ding, et al., ACL 2019, Jun 2019.\n*   [Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index](https://arxiv.org/abs/1906.05807), Minjoon Seo, et al., ACL 2019, Jun 2019.\n*   [Unsupervised Question Answering by Cloze Translation](https://arxiv.org/abs/1906.04980), Patrick Lewis, et al., ACL 2019, Jun 2019.\n*   [Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader](https://arxiv.org/abs/1905.07098), Wenhan Xiong, et al., ACL 2019, May 2019.\n*   [Matching Article Pairs with Graphical Decomposition and Convolutions](https://arxiv.org/pdf/1802.07459v2.pdf), Bang Liu, et al., ACL 2019, May 2019.\n*   [Episodic Memory Reader: Learning what to Remember for Question Answering from Streaming Data](https://arxiv.org/abs/1903.06164), Moonsu Han, et al., ACL 2019, Mar 2019.\n*   [Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension](https://arxiv.org/abs/1811.00232), Daesik Kim, et al., ACL 2019, Nov 2018.\n\n### EMNLP-IJCNLP 2019\n\n*   [Language Models as Knowledge Bases?](https://arxiv.org/pdf/1909.01066v2.pdf), Fabio Petron, et al., EMNLP-IJCNLP 2019, Sep 2019.\n*   [LXMERT: Learning Cross-Modality Encoder Representations from Transformers](https://arxiv.org/pdf/1908.07490v3.pdf), Hao Tan, et al., EMNLP-IJCNLP 2019, Dec 2019.\n*   [Answering Complex Open-domain Questions Through Iterative Query Generation](https://arxiv.org/pdf/1910.07000v1.pdf), Peng Qi, et al., EMNLP-IJCNLP 2019, Oct 2019.\n*   [KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning](https://arxiv.org/pdf/1909.02151v1.pdf), Bill Yuchen Lin, et al., EMNLP-IJCNLP 2019, Sep 2019.\n*   [Mixture Content Selection for Diverse Sequence Generation](https://arxiv.org/pdf/1909.01953v1.pdf), Jaemin Cho, et al., EMNLP-IJCNLP 2019, Sep 2019.\n*   [A Discrete Hard EM Approach for Weakly Supervised Question Answering](https://arxiv.org/pdf/1909.04849v1.pdf), Sewon Min, et al., EMNLP-IJCNLP, 2019, Sep 2019.\n\n### Dataset\n\n*   [ELI5: Long Form Question Answering](https://arxiv.org/abs/1907.09190), Angela Fan, et al., ACL 2019, Jul 2019\n*   [CODAH: An Adversarially-Authored Question Answering Dataset for\n    Common Sense](https://www.aclweb.org/anthology/W19-2008.pdf), Michael Chen, et al., RepEval 2019, Jun 2019.\n\n### Datasets / Subtypes of QA\n\n*   [CODAH Dataset (‚≠ê22)](https://github.com/Websail-NU/CODAH)\n*   [ELI5 (‚≠ê325)](https://github.com/facebookresearch/ELI5)\n    *   Paper: <https://arxiv.org/abs/1907.09190>",
      "content_html": "<h3><p>AAAI 2020</p>\n</h3>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1911.04118.pdf\" rel=\"noopener noreferrer\">TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection</a>, Siddhant Garg, et al., AAAI 2020, Nov 2019.</li>\n</ul>\n<h3><p>ACL 2019</p>\n</h3>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1906.02829v1.pdf\" rel=\"noopener noreferrer\">Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications</a>, Wei Zhao, et al., ACL 2019, Jun 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1905.05460v2.pdf\" rel=\"noopener noreferrer\">Cognitive Graph for Multi-Hop Reading Comprehension at Scale</a>, Ming Ding, et al., ACL 2019, Jun 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1906.05807\" rel=\"noopener noreferrer\">Real-Time Open-Domain Question Answering with Dense-Sparse Phrase Index</a>, Minjoon Seo, et al., ACL 2019, Jun 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1906.04980\" rel=\"noopener noreferrer\">Unsupervised Question Answering by Cloze Translation</a>, Patrick Lewis, et al., ACL 2019, Jun 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1905.07098\" rel=\"noopener noreferrer\">Improving Question Answering over Incomplete KBs with Knowledge-Aware Reader</a>, Wenhan Xiong, et al., ACL 2019, May 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1802.07459v2.pdf\" rel=\"noopener noreferrer\">Matching Article Pairs with Graphical Decomposition and Convolutions</a>, Bang Liu, et al., ACL 2019, May 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1903.06164\" rel=\"noopener noreferrer\">Episodic Memory Reader: Learning what to Remember for Question Answering from Streaming Data</a>, Moonsu Han, et al., ACL 2019, Mar 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/abs/1811.00232\" rel=\"noopener noreferrer\">Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension</a>, Daesik Kim, et al., ACL 2019, Nov 2018.</li>\n</ul>\n<h3><p>EMNLP-IJCNLP 2019</p>\n</h3>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1909.01066v2.pdf\" rel=\"noopener noreferrer\">Language Models as Knowledge Bases?</a>, Fabio Petron, et al., EMNLP-IJCNLP 2019, Sep 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1908.07490v3.pdf\" rel=\"noopener noreferrer\">LXMERT: Learning Cross-Modality Encoder Representations from Transformers</a>, Hao Tan, et al., EMNLP-IJCNLP 2019, Dec 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1910.07000v1.pdf\" rel=\"noopener noreferrer\">Answering Complex Open-domain Questions Through Iterative Query Generation</a>, Peng Qi, et al., EMNLP-IJCNLP 2019, Oct 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1909.02151v1.pdf\" rel=\"noopener noreferrer\">KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning</a>, Bill Yuchen Lin, et al., EMNLP-IJCNLP 2019, Sep 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1909.01953v1.pdf\" rel=\"noopener noreferrer\">Mixture Content Selection for Diverse Sequence Generation</a>, Jaemin Cho, et al., EMNLP-IJCNLP 2019, Sep 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1909.04849v1.pdf\" rel=\"noopener noreferrer\">A Discrete Hard EM Approach for Weakly Supervised Question Answering</a>, Sewon Min, et al., EMNLP-IJCNLP, 2019, Sep 2019.</li>\n</ul>\n<h3><p>Dataset</p>\n</h3>\n<ul>\n<li><a href=\"https://arxiv.org/abs/1907.09190\" rel=\"noopener noreferrer\">ELI5: Long Form Question Answering</a>, Angela Fan, et al., ACL 2019, Jul 2019</li>\n</ul>\n\n<ul>\n<li><a href=\"https://www.aclweb.org/anthology/W19-2008.pdf\" rel=\"noopener noreferrer\">CODAH: An Adversarially-Authored Question Answering Dataset for\nCommon Sense</a>, Michael Chen, et al., RepEval 2019, Jun 2019.</li>\n</ul>\n<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://github.com/Websail-NU/CODAH\" rel=\"noopener noreferrer\">CODAH Dataset (‚≠ê22)</a></li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/facebookresearch/ELI5\" rel=\"noopener noreferrer\">ELI5 (‚≠ê325)</a><ul>\n<li>Paper: <a href=\"https://arxiv.org/abs/1907.09190\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1907.09190</a></li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2019/09/09/",
      "title": "Awesome Qa Updates on Sep 09, 2019",
      "_short_title": "Sep 09, 2019",
      "_slug": "2019/09/09/",
      "summary": "3 awesome projects updated on Sep 09, 2019",
      "_filepath": "/content/2019/09/09/README.md",
      "url": "https://www.trackawesomelist.com/2019/09/09/",
      "date_published": "2019-09-09T05:20:52.000Z",
      "date_modified": "2019-09-09T05:20:52.000Z",
      "content_text": "\n\n### ACL 2019\n\n*   [Overview of the MEDIQA 2019 Shared Task on Textual Inference,\n    Question Entailment and Question Answering](https://www.aclweb.org/anthology/W19-5039), Asma Ben Abacha, et al., ACL-W 2019, Aug 2019.\n*   [SemEval-2019 Task 10: Math Question Answering](https://www.aclweb.org/anthology/S19-2153), Mark Hopkins, et al., ACL-W 2019, Jun 2019.\n*   [Natural Questions: a Benchmark for Question Answering Research](https://ai.google/research/pubs/pub47761), Tom Kwiatkowski, et al., TACL 2019, Jan 2019.",
      "content_html": "<h3><p>ACL 2019</p>\n</h3>\n<ul>\n<li><a href=\"https://www.aclweb.org/anthology/W19-5039\" rel=\"noopener noreferrer\">Overview of the MEDIQA 2019 Shared Task on Textual Inference,\nQuestion Entailment and Question Answering</a>, Asma Ben Abacha, et al., ACL-W 2019, Aug 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://www.aclweb.org/anthology/S19-2153\" rel=\"noopener noreferrer\">SemEval-2019 Task 10: Math Question Answering</a>, Mark Hopkins, et al., ACL-W 2019, Jun 2019.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://ai.google/research/pubs/pub47761\" rel=\"noopener noreferrer\">Natural Questions: a Benchmark for Question Answering Research</a>, Tom Kwiatkowski, et al., TACL 2019, Jan 2019.</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2019/02/14/",
      "title": "Awesome Qa Updates on Feb 14, 2019",
      "_short_title": "Feb 14, 2019",
      "_slug": "2019/02/14/",
      "summary": "2 awesome projects updated on Feb 14, 2019",
      "_filepath": "/content/2019/02/14/README.md",
      "url": "https://www.trackawesomelist.com/2019/02/14/",
      "date_published": "2019-02-14T00:59:05.000Z",
      "date_modified": "2019-02-14T00:59:05.000Z",
      "content_text": "\n\n### Publications / Subtypes of QA\n\n*   Papers\n    *   [\"Learning to Skim Text\"](https://arxiv.org/pdf/1704.06877.pdf), Adams Wei Yu, Hongrae Lee, Quoc V. Le, 2017.\n        : Show only what you want in Text\n    *   [\"Deep Joint Entity Disambiguation with Local Neural Attention\"](https://arxiv.org/pdf/1704.04920.pdf), Octavian-Eugen Ganea and Thomas Hofmann, 2017.\n    *   [\"BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION\"](https://arxiv.org/pdf/1611.01603.pdf), Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hananneh Hajishirzi, ICLR, 2017.\n    *   [\"Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks\"](http://nlp.cs.berkeley.edu/pubs/FrancisLandau-Durrett-Klein_2016_EntityConvnets_paper.pdf), Matthew Francis-Landau, Greg Durrett and Dan Klei, NAACL-HLT 2016.\n        *   [https://GitHub.com/matthewfl/nlp-entity-convnet (‚≠ê57)](https://GitHub.com/matthewfl/nlp-entity-convnet)\n    *   [\"Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\"](https://ieeexplore.ieee.org/document/6823700/), Wei Shen, Jianyong Wang, Jiawei Han, IEEE Transactions on Knowledge and Data Engineering(TKDE), 2014.\n    *   [\"Introduction to ‚ÄúThis is Watson\"](https://ieeexplore.ieee.org/document/6177724/), IBM Journal of Research and Development, D. A. Ferrucci, 2012.\n    *   [\"A survey on question answering technology from an information retrieval perspective\"](https://www.sciencedirect.com/science/article/pii/S0020025511003860), Information Sciences, 2011.\n    *   [\"Question Answering in Restricted Domains: An Overview\"](https://www.mitpressjournals.org/doi/abs/10.1162/coli.2007.33.1.41), Diego Moll√° and Jos√© Luis Vicedo, Computational Linguistics, 2007\n    *   [\"Natural language question answering: the view from here\"](https://github.com/seriousran/awesome-qa/blob/master/README.md/), L Hirschman, R Gaizauskas, natural language engineering, 2001.\n    *   Entity Disambiguation / Entity Linking\n\n### Datasets / Subtypes of QA\n\n*   [WikiQA](https://www.microsoft.com/en-us/download/details.aspx?id=52419\\&from=https%3A%2F%2Fresearch.microsoft.com%2Fen-US%2Fdownloads%2F4495da01-db8c-4041-a7f6-7984a4f6a905%2Fdefault.aspx)\n    *   A publicly available set of question and sentence pairs for open-domain question answering.",
      "content_html": "<h3><p>Publications / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Papers<ul>\n<li><a href=\"https://arxiv.org/pdf/1704.06877.pdf\" rel=\"noopener noreferrer\">\"Learning to Skim Text\"</a>, Adams Wei Yu, Hongrae Lee, Quoc V. Le, 2017.\n: Show only what you want in Text</li>\n<li><a href=\"https://arxiv.org/pdf/1704.04920.pdf\" rel=\"noopener noreferrer\">\"Deep Joint Entity Disambiguation with Local Neural Attention\"</a>, Octavian-Eugen Ganea and Thomas Hofmann, 2017.</li>\n<li><a href=\"https://arxiv.org/pdf/1611.01603.pdf\" rel=\"noopener noreferrer\">\"BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION\"</a>, Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, Hananneh Hajishirzi, ICLR, 2017.</li>\n<li><a href=\"http://nlp.cs.berkeley.edu/pubs/FrancisLandau-Durrett-Klein_2016_EntityConvnets_paper.pdf\" rel=\"noopener noreferrer\">\"Capturing Semantic Similarity for Entity Linking with Convolutional Neural Networks\"</a>, Matthew Francis-Landau, Greg Durrett and Dan Klei, NAACL-HLT 2016.<ul>\n<li><a href=\"https://GitHub.com/matthewfl/nlp-entity-convnet\" rel=\"noopener noreferrer\">https://GitHub.com/matthewfl/nlp-entity-convnet (‚≠ê57)</a></li>\n</ul>\n</li>\n<li><a href=\"https://ieeexplore.ieee.org/document/6823700/\" rel=\"noopener noreferrer\">\"Entity Linking with a Knowledge Base: Issues, Techniques, and Solutions\"</a>, Wei Shen, Jianyong Wang, Jiawei Han, IEEE Transactions on Knowledge and Data Engineering(TKDE), 2014.</li>\n<li><a href=\"https://ieeexplore.ieee.org/document/6177724/\" rel=\"noopener noreferrer\">\"Introduction to ‚ÄúThis is Watson\"</a>, IBM Journal of Research and Development, D. A. Ferrucci, 2012.</li>\n<li><a href=\"https://www.sciencedirect.com/science/article/pii/S0020025511003860\" rel=\"noopener noreferrer\">\"A survey on question answering technology from an information retrieval perspective\"</a>, Information Sciences, 2011.</li>\n<li><a href=\"https://www.mitpressjournals.org/doi/abs/10.1162/coli.2007.33.1.41\" rel=\"noopener noreferrer\">\"Question Answering in Restricted Domains: An Overview\"</a>, Diego Moll√° and Jos√© Luis Vicedo, Computational Linguistics, 2007</li>\n<li><a href=\"https://github.com/seriousran/awesome-qa/blob/master/README.md/\" rel=\"noopener noreferrer\">\"Natural language question answering: the view from here\"</a>, L Hirschman, R Gaizauskas, natural language engineering, 2001.</li>\n<li>Entity Disambiguation / Entity Linking</li>\n</ul>\n</li>\n</ul>\n<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://www.microsoft.com/en-us/download/details.aspx?id=52419&amp;from=https%3A%2F%2Fresearch.microsoft.com%2Fen-US%2Fdownloads%2F4495da01-db8c-4041-a7f6-7984a4f6a905%2Fdefault.aspx\" rel=\"noopener noreferrer\">WikiQA</a><ul>\n<li>A publicly available set of question and sentence pairs for open-domain question answering.</li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2019/01/24/",
      "title": "Awesome Qa Updates on Jan 24, 2019",
      "_short_title": "Jan 24, 2019",
      "_slug": "2019/01/24/",
      "summary": "2 awesome projects updated on Jan 24, 2019",
      "_filepath": "/content/2019/01/24/README.md",
      "url": "https://www.trackawesomelist.com/2019/01/24/",
      "date_published": "2019-01-24T01:29:21.000Z",
      "date_modified": "2019-01-24T01:29:21.000Z",
      "content_text": "\n\n### Datasets / Subtypes of QA\n\n*   [AI2 Science Questions v2.1(2017)](http://data.allenai.org/ai2-science-questions/)\n    *   It consists of questions used in student assessments in the United States across elementary and middle school grade levels. Each question is 4-way multiple choice format and may or may not include a diagram element.\n    *   Paper: <http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf>\n*   [MS MARCO](http://www.msmarco.org/dataset.aspx)\n    *   This is for real-world question answering.\n    *   Paper: <https://arxiv.org/abs/1611.09268>",
      "content_html": "<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"http://data.allenai.org/ai2-science-questions/\" rel=\"noopener noreferrer\">AI2 Science Questions v2.1(2017)</a><ul>\n<li>It consists of questions used in student assessments in the United States across elementary and middle school grade levels. Each question is 4-way multiple choice format and may or may not include a diagram element.</li>\n<li>Paper: <a href=\"http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf\" rel=\"noopener noreferrer\">http://ai2-website.s3.amazonaws.com/publications/AI2ReasoningChallenge2018.pdf</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"http://www.msmarco.org/dataset.aspx\" rel=\"noopener noreferrer\">MS MARCO</a><ul>\n<li>This is for real-world question answering.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1611.09268\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1611.09268</a></li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2019/01/22/",
      "title": "Awesome Qa Updates on Jan 22, 2019",
      "_short_title": "Jan 22, 2019",
      "_slug": "2019/01/22/",
      "summary": "7 awesome projects updated on Jan 22, 2019",
      "_filepath": "/content/2019/01/22/README.md",
      "url": "https://www.trackawesomelist.com/2019/01/22/",
      "date_published": "2019-01-22T07:03:51.000Z",
      "date_modified": "2019-01-22T07:03:51.000Z",
      "content_text": "\n\n### Datasets / Subtypes of QA\n\n*   [DeepMind Q\\&A Dataset; CNN/Daily Mail (‚≠ê1.3k)](https://github.com/deepmind/rc-data)\n    *   Hermann et al. (2015) created two awesome datasets using news articles for Q\\&A research. Each dataset contains many documents (90k and 197k each), and each document companies on average 4 questions approximately. Each question is a sentence with one missing word/phrase which can be found from the accompanying document/context.\n    *   Paper: <https://arxiv.org/abs/1506.03340>\n*   [NarrativeQA (‚≠ê479)](https://github.com/deepmind/narrativeqa)\n    *   It includes the list of documents with Wikipedia summaries, links to full stories, and questions and answers.\n    *   Paper: <https://arxiv.org/pdf/1712.07040v1.pdf>\n*   [NewsQA (‚≠ê254)](https://github.com/Maluuba/newsqa)\n    *   A machine comprehension dataset\n    *   Paper: <https://arxiv.org/pdf/1611.09830.pdf>\n*   [SQuAD1.0](https://rajpurkar.github.io/SQuAD-explorer/)\n    *   Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.\n    *   Paper: <https://arxiv.org/abs/1606.05250>\n*   [SQuAD2.0](https://rajpurkar.github.io/SQuAD-explorer/)\n    *   SQuAD2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 new, unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering.\n    *   Paper: <https://arxiv.org/abs/1806.03822>\n*   [Story cloze test](http://cs.rochester.edu/nlp/rocstories/)\n    *   'Story Cloze Test' is a new commonsense reasoning framework for evaluating story understanding, story generation, and script learning. This test requires a system to choose the correct ending to a four-sentence story.\n    *   Paper: <https://arxiv.org/abs/1604.01696>\n*   [TriviaQA](http://nlp.cs.washington.edu/triviaqa/)\n    *   TriviaQA is a reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions.\n    *   Paper: <https://arxiv.org/abs/1705.03551>",
      "content_html": "<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://github.com/deepmind/rc-data\" rel=\"noopener noreferrer\">DeepMind Q&amp;A Dataset; CNN/Daily Mail (‚≠ê1.3k)</a><ul>\n<li>Hermann et al. (2015) created two awesome datasets using news articles for Q&amp;A research. Each dataset contains many documents (90k and 197k each), and each document companies on average 4 questions approximately. Each question is a sentence with one missing word/phrase which can be found from the accompanying document/context.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1506.03340\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1506.03340</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/deepmind/narrativeqa\" rel=\"noopener noreferrer\">NarrativeQA (‚≠ê479)</a><ul>\n<li>It includes the list of documents with Wikipedia summaries, links to full stories, and questions and answers.</li>\n<li>Paper: <a href=\"https://arxiv.org/pdf/1712.07040v1.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/1712.07040v1.pdf</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/Maluuba/newsqa\" rel=\"noopener noreferrer\">NewsQA (‚≠ê254)</a><ul>\n<li>A machine comprehension dataset</li>\n<li>Paper: <a href=\"https://arxiv.org/pdf/1611.09830.pdf\" rel=\"noopener noreferrer\">https://arxiv.org/pdf/1611.09830.pdf</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"https://rajpurkar.github.io/SQuAD-explorer/\" rel=\"noopener noreferrer\">SQuAD1.0</a><ul>\n<li>Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1606.05250\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1606.05250</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"https://rajpurkar.github.io/SQuAD-explorer/\" rel=\"noopener noreferrer\">SQuAD2.0</a><ul>\n<li>SQuAD2.0 combines the 100,000 questions in SQuAD1.1 with over 50,000 new, unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1806.03822\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1806.03822</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"http://cs.rochester.edu/nlp/rocstories/\" rel=\"noopener noreferrer\">Story cloze test</a><ul>\n<li>'Story Cloze Test' is a new commonsense reasoning framework for evaluating story understanding, story generation, and script learning. This test requires a system to choose the correct ending to a four-sentence story.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1604.01696\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1604.01696</a></li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"http://nlp.cs.washington.edu/triviaqa/\" rel=\"noopener noreferrer\">TriviaQA</a><ul>\n<li>TriviaQA is a reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions.</li>\n<li>Paper: <a href=\"https://arxiv.org/abs/1705.03551\" rel=\"noopener noreferrer\">https://arxiv.org/abs/1705.03551</a></li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/11/14/",
      "title": "Awesome Qa Updates on Nov 14, 2018",
      "_short_title": "Nov 14, 2018",
      "_slug": "2018/11/14/",
      "summary": "1 awesome projects updated on Nov 14, 2018",
      "_filepath": "/content/2018/11/14/README.md",
      "url": "https://www.trackawesomelist.com/2018/11/14/",
      "date_published": "2018-11-14T05:33:48.000Z",
      "date_modified": "2018-11-14T05:33:48.000Z",
      "content_text": "\n\n### Facebook AI Research's publication within 5 years / Subtypes of QA\n\n*   2018\n    *   [Embodied Question Answering](https://research.fb.com/publications/embodied-question-answering/), Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, and Dhruv Batra, CVPR, 2018\n    *   [Do explanations make VQA models more predictable to a human?](https://research.fb.com/publications/do-explanations-make-vqa-models-more-predictable-to-a-human/), Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit Chattopadhyay, and Devi Parikh, EMNLP, 2018\n    *   [Neural Compositional Denotational Semantics for Question Answering](https://research.fb.com/publications/neural-compositional-denotational-semantics-for-question-answering/), Nitish Gupta, Mike Lewis, EMNLP, 2018",
      "content_html": "<h3><p>Facebook AI Research's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2018<ul>\n<li><a href=\"https://research.fb.com/publications/embodied-question-answering/\" rel=\"noopener noreferrer\">Embodied Question Answering</a>, Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, and Dhruv Batra, CVPR, 2018</li>\n<li><a href=\"https://research.fb.com/publications/do-explanations-make-vqa-models-more-predictable-to-a-human/\" rel=\"noopener noreferrer\">Do explanations make VQA models more predictable to a human?</a>, Arjun Chandrasekaran, Viraj Prabhu, Deshraj Yadav, Prithvijit Chattopadhyay, and Devi Parikh, EMNLP, 2018</li>\n<li><a href=\"https://research.fb.com/publications/neural-compositional-denotational-semantics-for-question-answering/\" rel=\"noopener noreferrer\">Neural Compositional Denotational Semantics for Question Answering</a>, Nitish Gupta, Mike Lewis, EMNLP, 2018</li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/10/16/",
      "title": "Awesome Qa Updates on Oct 16, 2018",
      "_short_title": "Oct 16, 2018",
      "_slug": "2018/10/16/",
      "summary": "7 awesome projects updated on Oct 16, 2018",
      "_filepath": "/content/2018/10/16/README.md",
      "url": "https://www.trackawesomelist.com/2018/10/16/",
      "date_published": "2018-10-16T00:19:04.000Z",
      "date_modified": "2018-10-16T00:53:54.000Z",
      "content_text": "\n\n### Systems / Subtypes of QA\n\n*   [IBM Watson](https://www.ibm.com/watson/) - Has state-of-the-arts performance.\n*   [Facebook DrQA](https://research.fb.com/downloads/drqa/) - Applied to the SQuAD1.0 dataset. The SQuAD2.0 dataset has released. but DrQA is not tested yet.\n*   [MIT media lab's Knowledge graph](http://conceptnet.io/) - Is a freely-available semantic network, designed to help computers understand the meanings of words that people use.\n\n### Lectures / Subtypes of QA\n\n*   [Question Answering - Natural Language Processing](https://youtu.be/Kzi6tE4JaGo) - By Dragomir Radev, Ph.D. | University of Michigan | 2016.\n\n### Slides / Subtypes of QA\n\n*   [Question Answering with Knowledge Bases, Web and Beyond (‚≠ê35)](https://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf) - By Scott Wen-tau Yih & Hao Ma | Microsoft Research | 2016.\n*   [Question Answering](https://hpi.de/fileadmin/user_upload/fachgebiete/plattner/teaching/NaturalLanguageProcessing/NLP2017/NLP8_QuestionAnswering.pdf) - By Dr. Mariana Neves | Hasso Plattner Institut | 2017.\n\n### Datasets / Subtypes of QA\n\n*   [MultiRC](https://cogcomp.org/multirc/)\n    *   A dataset of short paragraphs and multi-sentence questions\n    *   Paper: <http://cogcomp.org/page/publication_view/833>",
      "content_html": "<h3><p>Systems / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://www.ibm.com/watson/\" rel=\"noopener noreferrer\">IBM Watson</a> - Has state-of-the-arts performance.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://research.fb.com/downloads/drqa/\" rel=\"noopener noreferrer\">Facebook DrQA</a> - Applied to the SQuAD1.0 dataset. The SQuAD2.0 dataset has released. but DrQA is not tested yet.</li>\n</ul>\n\n<ul>\n<li><a href=\"http://conceptnet.io/\" rel=\"noopener noreferrer\">MIT media lab's Knowledge graph</a> - Is a freely-available semantic network, designed to help computers understand the meanings of words that people use.</li>\n</ul>\n<h3><p>Lectures / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://youtu.be/Kzi6tE4JaGo\" rel=\"noopener noreferrer\">Question Answering - Natural Language Processing</a> - By Dragomir Radev, Ph.D. | University of Michigan | 2016.</li>\n</ul>\n<h3><p>Slides / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf\" rel=\"noopener noreferrer\">Question Answering with Knowledge Bases, Web and Beyond (‚≠ê35)</a> - By Scott Wen-tau Yih &amp; Hao Ma | Microsoft Research | 2016.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://hpi.de/fileadmin/user_upload/fachgebiete/plattner/teaching/NaturalLanguageProcessing/NLP2017/NLP8_QuestionAnswering.pdf\" rel=\"noopener noreferrer\">Question Answering</a> - By Dr. Mariana Neves | Hasso Plattner Institut | 2017.</li>\n</ul>\n<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://cogcomp.org/multirc/\" rel=\"noopener noreferrer\">MultiRC</a><ul>\n<li>A dataset of short paragraphs and multi-sentence questions</li>\n<li>Paper: <a href=\"http://cogcomp.org/page/publication_view/833\" rel=\"noopener noreferrer\">http://cogcomp.org/page/publication_view/833</a></li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/09/28/",
      "title": "Awesome Qa Updates on Sep 28, 2018",
      "_short_title": "Sep 28, 2018",
      "_slug": "2018/09/28/",
      "summary": "5 awesome projects updated on Sep 28, 2018",
      "_filepath": "/content/2018/09/28/README.md",
      "url": "https://www.trackawesomelist.com/2018/09/28/",
      "date_published": "2018-09-28T07:39:53.000Z",
      "date_modified": "2018-09-28T07:39:53.000Z",
      "content_text": "\n\n### Analysis and Parsing for Pre-processing in QA systems / Subtypes of QA\n\n*   [Morphological analysis](https://www.cs.bham.ac.uk/~pjh/sem1a5/pt2/pt2_intro_morphology.html)\n*   [Named Entity Recognition(NER)](https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/named-entity-recognition.md)\n*   Homonyms / Polysemy Analysis\n*   Syntactic Parsing (Dependency Parsing)\n*   Semantic Recognition",
      "content_html": "<h3><p>Analysis and Parsing for Pre-processing in QA systems / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://www.cs.bham.ac.uk/~pjh/sem1a5/pt2/pt2_intro_morphology.html\" rel=\"noopener noreferrer\">Morphological analysis</a></li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/named-entity-recognition.md\" rel=\"noopener noreferrer\">Named Entity Recognition(NER)</a></li>\n</ul>\n\n<ul>\n<li>Homonyms / Polysemy Analysis</li>\n</ul>\n\n<ul>\n<li>Syntactic Parsing (Dependency Parsing)</li>\n</ul>\n\n<ul>\n<li>Semantic Recognition</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/08/13/",
      "title": "Awesome Qa Updates on Aug 13, 2018",
      "_short_title": "Aug 13, 2018",
      "_slug": "2018/08/13/",
      "summary": "7 awesome projects updated on Aug 13, 2018",
      "_filepath": "/content/2018/08/13/README.md",
      "url": "https://www.trackawesomelist.com/2018/08/13/",
      "date_published": "2018-08-13T05:00:09.000Z",
      "date_modified": "2018-08-13T06:50:43.000Z",
      "content_text": "\n\n### Types of QA / Subtypes of QA\n\n*   Knowledge-based QA\n*   Table/List-based QA\n*   Text-based QA\n*   Community-based QA\n*   Visual QA\n\n### Google AI's publication within 5 years / Subtypes of QA\n\n*   2017\n    *   [\"Analyzing Language Learned by an Active Question Answering Agent\"](https://arxiv.org/pdf/1801.07537.pdf), Christian Buck and Jannis Bulian and Massimiliano Ciaramita and Wojciech Gajewski and Andrea Gesmundo and Neil Houlsby and Wei Wang, NIPS, 2017.\n    *   [\"Learning Recurrent Span Representations for Extractive Question Answering\"](https://arxiv.org/pdf/1611.01436.pdf), Kenton Lee and Shimi Salant and Tom Kwiatkowski and Ankur Parikh and Dipanjan Das and Jonathan Berant, ICLR, 2017.\n    *   Identify the same question\n        *   [\"Neural Paraphrase Identification of Questions with Noisy Pretraining\"](https://arxiv.org/pdf/1704.04565.pdf), Gaurav Singh Tomar and Thyago Duque and Oscar T√§ckstr√∂m and Jakob Uszkoreit and Dipanjan Das, SCLeM, 2017.\n\n### Facebook AI Research's publication within 5 years / Subtypes of QA\n\n*   2017\n    *   DrQA <a name=\"drqa\"></a>\n        *   [Reading Wikipedia to Answer Open-Domain Questions](https://cs.stanford.edu/people/danqi/papers/acl2017.pdf), Danqi Chen, Adam Fisch, Jason Weston & Antoine Bordes, ACL, 2017.",
      "content_html": "<h3><p>Types of QA / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Knowledge-based QA</li>\n</ul>\n\n<ul>\n<li>Table/List-based QA</li>\n</ul>\n\n<ul>\n<li>Text-based QA</li>\n</ul>\n\n<ul>\n<li>Community-based QA</li>\n</ul>\n\n<ul>\n<li>Visual QA</li>\n</ul>\n<h3><p>Google AI's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2017<ul>\n<li><a href=\"https://arxiv.org/pdf/1801.07537.pdf\" rel=\"noopener noreferrer\">\"Analyzing Language Learned by an Active Question Answering Agent\"</a>, Christian Buck and Jannis Bulian and Massimiliano Ciaramita and Wojciech Gajewski and Andrea Gesmundo and Neil Houlsby and Wei Wang, NIPS, 2017.</li>\n<li><a href=\"https://arxiv.org/pdf/1611.01436.pdf\" rel=\"noopener noreferrer\">\"Learning Recurrent Span Representations for Extractive Question Answering\"</a>, Kenton Lee and Shimi Salant and Tom Kwiatkowski and Ankur Parikh and Dipanjan Das and Jonathan Berant, ICLR, 2017.</li>\n<li>Identify the same question<ul>\n<li><a href=\"https://arxiv.org/pdf/1704.04565.pdf\" rel=\"noopener noreferrer\">\"Neural Paraphrase Identification of Questions with Noisy Pretraining\"</a>, Gaurav Singh Tomar and Thyago Duque and Oscar T√§ckstr√∂m and Jakob Uszkoreit and Dipanjan Das, SCLeM, 2017.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3><p>Facebook AI Research's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2017<ul>\n<li>DrQA <a></a><ul>\n<li><a href=\"https://cs.stanford.edu/people/danqi/papers/acl2017.pdf\" rel=\"noopener noreferrer\">Reading Wikipedia to Answer Open-Domain Questions</a>, Danqi Chen, Adam Fisch, Jason Weston &amp; Antoine Bordes, ACL, 2017.</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/08/03/",
      "title": "Awesome Qa Updates on Aug 03, 2018",
      "_short_title": "Aug 03, 2018",
      "_slug": "2018/08/03/",
      "summary": "1 awesome projects updated on Aug 03, 2018",
      "_filepath": "/content/2018/08/03/README.md",
      "url": "https://www.trackawesomelist.com/2018/08/03/",
      "date_published": "2018-08-03T07:53:47.000Z",
      "date_modified": "2018-08-03T07:53:47.000Z",
      "content_text": "\n\n### Most QA systems have roughly 3 parts / Subtypes of QA\n\n*   Fact extraction <br/>\n    1.  Entity Extraction <br/>\n        1.  [Named-Entity Recognition(NER)](https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/named-entity-recognition.md)\n    2.  [Relation Extraction](https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/relation-extraction.md) <br/>",
      "content_html": "<h3><p>Most QA systems have roughly 3 parts / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Fact extraction <br /><ol>\n<li>Entity Extraction <br /><ol>\n<li><a href=\"https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/named-entity-recognition.md\" rel=\"noopener noreferrer\">Named-Entity Recognition(NER)</a></li>\n</ol>\n</li>\n<li><a href=\"https://github.com/seriousran/awesome-qa/blob/master/README.md/mds/relation-extraction.md\" rel=\"noopener noreferrer\">Relation Extraction</a> <br /></li>\n</ol>\n</li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/08/01/",
      "title": "Awesome Qa Updates on Aug 01, 2018",
      "_short_title": "Aug 01, 2018",
      "_slug": "2018/08/01/",
      "summary": "3 awesome projects updated on Aug 01, 2018",
      "_filepath": "/content/2018/08/01/README.md",
      "url": "https://www.trackawesomelist.com/2018/08/01/",
      "date_published": "2018-08-01T05:56:31.000Z",
      "date_modified": "2018-08-01T06:04:53.000Z",
      "content_text": "\n\n### Most QA systems have roughly 3 parts / Subtypes of QA\n\n*   Understanding the question\n*   Generating an answer\n\n### Links / Subtypes of QA\n\n*   [Why question answering is hard](http://nicklothian.com/blog/2014/09/25/why-question-answering-is-hard/)",
      "content_html": "<h3><p>Most QA systems have roughly 3 parts / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Understanding the question</li>\n</ul>\n\n<ul>\n<li>Generating an answer</li>\n</ul>\n<h3><p>Links / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"http://nicklothian.com/blog/2014/09/25/why-question-answering-is-hard/\" rel=\"noopener noreferrer\">Why question answering is hard</a></li>\n</ul>\n"
    },
    {
      "id": "https://www.trackawesomelist.com/2018/07/30/",
      "title": "Awesome Qa Updates on Jul 30, 2018",
      "_short_title": "Jul 30, 2018",
      "_slug": "2018/07/30/",
      "summary": "29 awesome projects updated on Jul 30, 2018",
      "_filepath": "/content/2018/07/30/README.md",
      "url": "https://www.trackawesomelist.com/2018/07/30/",
      "date_published": "2018-07-30T02:47:27.000Z",
      "date_modified": "2018-07-30T08:24:13.000Z",
      "content_text": "\n\n### Types of QA\n\n*   Single-turn QA: answer without considering any context\n*   Conversational QA: use previsous conversation turns\n\n### Events / Subtypes of QA\n\n*   Wolfram Alpha launced the answer engine in 2009.\n*   IBM Watson system defeated top *[Jeopardy!](https://www.jeopardy.com)* champions in 2011.\n*   Apple's Siri integrated Wolfram Alpha's answer engine in 2011.\n*   Google embraced QA by launching its Knowledge Graph, leveraging the free base knowledge base in 2012.\n*   Amazon Echo | Alexa (2015), Google Home | Google Assistant (2016), INVOKE | MS Cortana (2017), HomePod (2017)\n\n### Dataset Collections / Subtypes of QA\n\n*   [NLIWOD's Question answering datasets (‚≠ê93)](https://github.com/dice-group/NLIWOD/tree/master/qa.datasets)\n*   [karthinkncode's Datasets for Natural Language Processing (‚≠ê923)](https://github.com/karthikncode/nlp-datasets)\n\n### Datasets / Subtypes of QA\n\n*   [Children's Book Test](https://uclmr.github.io/ai4exams/data.html)\n*   It is one of the bAbI project of Facebook AI Research which is organized towards the goal of automatic text understanding and reasoning. The CBT is designed to measure directly how well language models can exploit wider linguistic context.\n*   [GraphQuestions (‚≠ê93)](https://github.com/ysu1989/GraphQuestions)\n    *   On generating Characteristic-rich Question sets for QA evaluation.\n*   [LC-QuAD](http://sda.cs.uni-bonn.de/projects/qa-dataset/)\n    *   It is a gold standard KBQA (Question Answering over Knowledge Base) dataset containing 5000 Question and SPARQL queries. LC-QuAD uses DBpedia v04.16 as the target KB.\n*   [Qestion-Answer Dataset by CMU](http://www.cs.cmu.edu/~ark/QA-data/)\n    *   This is a corpus of Wikipedia articles, manually-generated factoid questions from them, and manually-generated answers to these questions, for use in academic research. These data were collected by Noah Smith, Michael Heilman, Rebecca Hwa, Shay Cohen, Kevin Gimpel, and many students at Carnegie Mellon University and the University of Pittsburgh between 2008 and 2010.\n\n### The DeepQA Research Team in IBM Watson's publication within 5 years / Subtypes of QA\n\n*   2015\n    *   \"Automated Problem List Generation from Electronic Medical Records in IBM Watson\", Murthy Devarakonda, Ching-Huei Tsou, IAAI, 2015.\n    *   \"Decision Making in IBM Watson Question Answering\", J. William Murdock, Ontology summit, 2015.\n    *   [\"Unsupervised Entity-Relation Analysis in IBM Watson\"](http://www.cogsys.org/papers/ACS2015/article12.pdf), Aditya Kalyanpur, J William Murdock, ACS, 2015.\n    *   \"Commonsense Reasoning: An Event Calculus Based Approach\", E T Mueller, Morgan Kaufmann/Elsevier, 2015.\n*   2014\n    *   \"Problem-oriented patient record summary: An early report on a Watson application\", M. Devarakonda, Dongyang Zhang, Ching-Huei Tsou, M. Bornea, Healthcom, 2014.\n    *   [\"WatsonPaths: Scenario-based Question Answering and Inference over Unstructured Information\"](http://domino.watson.ibm.com/library/Cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/088f74984a07645485257d5f006ace96!OpenDocument\\&Highlight=0,RC25489), Adam Lally, Sugato Bachi, Michael A. Barborak, David W. Buchanan, Jennifer Chu-Carroll, David A. Ferrucci\\*, Michael R. Glass, Aditya Kalyanpur, Erik T. Mueller, J. William Murdock, Siddharth Patwardhan, John M. Prager, Christopher A. Welty, IBM Research Report RC25489, 2014.\n    *   [\"Medical Relation Extraction with Manifold Models\"](http://acl2014.org/acl2014/P14-1/pdf/P14-1078.pdf), Chang Wang and James Fan, ACL, 2014.\n\n### MS Research's publication within 5 years / Subtypes of QA\n\n*   2018\n    *   \"Characterizing and Supporting Question Answering in Human-to-Human Communication\", Xiao Yang, Ahmed Hassan Awadallah, Madian Khabsa, Wei Wang, Miaosen Wang, ACM SIGIR, 2018.\n    *   [\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\"](https://arxiv.org/abs/1710.07300), Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Akos Kadar, Adam Trischler, Yoshua Bengio, ICLR, 2018\n*   2017\n    *   \"Multi-level Attention Networks for Visual Question Answering\", Dongfei Yu, Jianlong Fu, Tao Mei, Yong Rui, CVPR, 2017.\n    *   \"A Joint Model for Question Answering and Question Generation\", Tong Wang, Xingdi (Eric) Yuan, Adam Trischler, ICML, 2017.\n    *   \"Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\", David Golub, Po-Sen Huang, Xiaodong He, Li Deng, EMNLP, 2017.\n    *   \"Question-Answering with Grammatically-Interpretable Representations\", Hamid Palangi, Paul Smolensky, Xiaodong He, Li Deng,\n    *   \"Search-based Neural Structured Learning for Sequential Question Answering\", Mohit Iyyer, Wen-tau Yih, Ming-Wei Chang, ACL, 2017.\n*   2016\n    *   [\"Stacked Attention Networks for Image Question Answering\"](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Yang_Stacked_Attention_Networks_CVPR_2016_paper.html), Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola, CVPR, 2016.\n    *   [\"Question Answering with Knowledge Base, Web and Beyond\"](https://www.microsoft.com/en-us/research/publication/question-answering-with-knowledge-base-web-and-beyond/), Yih, Scott Wen-tau and Ma, Hao, ACM SIGIR, 2016.\n    *   [\"NewsQA: A Machine Comprehension Dataset\"](https://arxiv.org/abs/1611.09830), Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman, RepL4NLP, 2016.\n    *   [\"Table Cell Search for Question Answering\"](https://dl.acm.org/citation.cfm?id=2883080), Sun, Huan and Ma, Hao and He, Xiaodong and Yih, Wen-tau and Su, Yu and Yan, Xifeng, WWW, 2016.\n*   2015\n    *   [\"WIKIQA: A Challenge Dataset for Open-Domain Question Answering\"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf), Yi Yang, Wen-tau Yih, and Christopher Meek, EMNLP, 2015.\n    *   [\"Web-based Question Answering: Revisiting AskMSR\"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/AskMSRPlusTR_082815.pdf), Chen-Tse Tsai, Wen-tau Yih, and Christopher J.C. Burges, MSR-TR, 2015.\n    *   [\"Open Domain Question Answering via Semantic Enrichment\"](https://dl.acm.org/citation.cfm?id=2741651), Huan Sun, Hao Ma, Wen-tau Yih, Chen-Tse Tsai, Jingjing Liu, and Ming-Wei Chang, WWW, 2015.\n*   2014\n    *   [\"An Overview of Microsoft Deep QA System on Stanford WebQuestions Benchmark\"](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Microsoft20Deep20QA.pdf), Zhenghao Wang, Shengquan Yan, Huaming Wang, and Xuedong Huang, MSR-TR, 2014.\n    *   [\"Semantic Parsing for Single-Relation Question Answering\"](https://github.com/seriousran/awesome-qa/blob/master/README.md/), Wen-tau Yih, Xiaodong He, Christopher Meek, ACL, 2014.\n\n### Google AI's publication within 5 years / Subtypes of QA\n\n*   2018\n    *   Google QA <a name=\"qanet\"></a>\n        *   [\"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\"](https://openreview.net/pdf?id=B14TlG-RW), Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, Quoc V. Le, ICLR, 2018.\n        *   [\"Ask the Right Questions: Active Question Reformulation with Reinforcement Learning\"](https://openreview.net/pdf?id=S1CChZ-CZ), Christian Buck and Jannis Bulian and Massimiliano Ciaramita and Wojciech Pawe≈Ç Gajewski and Andrea Gesmundo and Neil Houlsby and Wei Wang, ICLR, 2018.\n        *   [\"Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors\"](https://arxiv.org/pdf/1612.04342.pdf), Radu Soricut, Nan Ding, 2018.\n    *   Sentence representation\n        *   [\"An efficient framework for learning sentence representations\"](https://arxiv.org/pdf/1803.02893.pdf), Lajanugen Logeswaran, Honglak Lee, ICLR, 2018.\n    *   [\"Did the model understand the question?\"](https://arxiv.org/pdf/1805.05492.pdf), Pramod K. Mudrakarta and Ankur Taly and Mukund Sundararajan and Kedar Dhamdhere, ACL, 2018.\n*   2014\n    *   \"Great Question! Question Quality in Community Q\\&A\", Sujith Ravi and Bo Pang and Vibhor Rastogi and Ravi Kumar, ICWSM, 2014.\n\n### Books / Subtypes of QA\n\n*   Natural Language Question Answering system Paperback - Boris Galitsky (2003)\n*   New Directions in Question Answering - Mark T. Maybury (2004)\n*   Part 3. 5. Question Answering in The Oxford Handbook of Computational Linguistics - Sanda Harabagiu and Dan Moldovan (2005)\n*   Chap.28 Question Answering in Speech and Language Processing - Daniel Jurafsky & James H. Martin (2017)\n\n### Links / Subtypes of QA\n\n*   [Building a Question-Answering System from Scratch‚Äî Part 1](https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507)\n*   [Qeustion Answering with Tensorflow By Steven Hewitt, O'REILLY, 2017](https://www.oreilly.com/ideas/question-answering-with-tensorflow)",
      "content_html": "<h3><p>Types of QA</p>\n</h3>\n<ul>\n<li>Single-turn QA: answer without considering any context</li>\n</ul>\n\n<ul>\n<li>Conversational QA: use previsous conversation turns</li>\n</ul>\n<h3><p>Events / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Wolfram Alpha launced the answer engine in 2009.</li>\n</ul>\n\n<ul>\n<li>IBM Watson system defeated top <em><a href=\"https://www.jeopardy.com\" rel=\"noopener noreferrer\">Jeopardy!</a></em> champions in 2011.</li>\n</ul>\n\n<ul>\n<li>Apple's Siri integrated Wolfram Alpha's answer engine in 2011.</li>\n</ul>\n\n<ul>\n<li>Google embraced QA by launching its Knowledge Graph, leveraging the free base knowledge base in 2012.</li>\n</ul>\n\n<ul>\n<li>Amazon Echo | Alexa (2015), Google Home | Google Assistant (2016), INVOKE | MS Cortana (2017), HomePod (2017)</li>\n</ul>\n<h3><p>Dataset Collections / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://github.com/dice-group/NLIWOD/tree/master/qa.datasets\" rel=\"noopener noreferrer\">NLIWOD's Question answering datasets (‚≠ê93)</a></li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/karthikncode/nlp-datasets\" rel=\"noopener noreferrer\">karthinkncode's Datasets for Natural Language Processing (‚≠ê923)</a></li>\n</ul>\n<h3><p>Datasets / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://uclmr.github.io/ai4exams/data.html\" rel=\"noopener noreferrer\">Children's Book Test</a></li>\n</ul>\n\n<ul>\n<li>It is one of the bAbI project of Facebook AI Research which is organized towards the goal of automatic text understanding and reasoning. The CBT is designed to measure directly how well language models can exploit wider linguistic context.</li>\n</ul>\n\n<ul>\n<li><a href=\"https://github.com/ysu1989/GraphQuestions\" rel=\"noopener noreferrer\">GraphQuestions (‚≠ê93)</a><ul>\n<li>On generating Characteristic-rich Question sets for QA evaluation.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"http://sda.cs.uni-bonn.de/projects/qa-dataset/\" rel=\"noopener noreferrer\">LC-QuAD</a><ul>\n<li>It is a gold standard KBQA (Question Answering over Knowledge Base) dataset containing 5000 Question and SPARQL queries. LC-QuAD uses DBpedia v04.16 as the target KB.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li><a href=\"http://www.cs.cmu.edu/~ark/QA-data/\" rel=\"noopener noreferrer\">Qestion-Answer Dataset by CMU</a><ul>\n<li>This is a corpus of Wikipedia articles, manually-generated factoid questions from them, and manually-generated answers to these questions, for use in academic research. These data were collected by Noah Smith, Michael Heilman, Rebecca Hwa, Shay Cohen, Kevin Gimpel, and many students at Carnegie Mellon University and the University of Pittsburgh between 2008 and 2010.</li>\n</ul>\n</li>\n</ul>\n<h3><p>The DeepQA Research Team in IBM Watson's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2015<ul>\n<li>\"Automated Problem List Generation from Electronic Medical Records in IBM Watson\", Murthy Devarakonda, Ching-Huei Tsou, IAAI, 2015.</li>\n<li>\"Decision Making in IBM Watson Question Answering\", J. William Murdock, Ontology summit, 2015.</li>\n<li><a href=\"http://www.cogsys.org/papers/ACS2015/article12.pdf\" rel=\"noopener noreferrer\">\"Unsupervised Entity-Relation Analysis in IBM Watson\"</a>, Aditya Kalyanpur, J William Murdock, ACS, 2015.</li>\n<li>\"Commonsense Reasoning: An Event Calculus Based Approach\", E T Mueller, Morgan Kaufmann/Elsevier, 2015.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2014<ul>\n<li>\"Problem-oriented patient record summary: An early report on a Watson application\", M. Devarakonda, Dongyang Zhang, Ching-Huei Tsou, M. Bornea, Healthcom, 2014.</li>\n<li><a href=\"http://domino.watson.ibm.com/library/Cyberdig.nsf/1e4115aea78b6e7c85256b360066f0d4/088f74984a07645485257d5f006ace96!OpenDocument&amp;Highlight=0,RC25489\" rel=\"noopener noreferrer\">\"WatsonPaths: Scenario-based Question Answering and Inference over Unstructured Information\"</a>, Adam Lally, Sugato Bachi, Michael A. Barborak, David W. Buchanan, Jennifer Chu-Carroll, David A. Ferrucci*, Michael R. Glass, Aditya Kalyanpur, Erik T. Mueller, J. William Murdock, Siddharth Patwardhan, John M. Prager, Christopher A. Welty, IBM Research Report RC25489, 2014.</li>\n<li><a href=\"http://acl2014.org/acl2014/P14-1/pdf/P14-1078.pdf\" rel=\"noopener noreferrer\">\"Medical Relation Extraction with Manifold Models\"</a>, Chang Wang and James Fan, ACL, 2014.</li>\n</ul>\n</li>\n</ul>\n<h3><p>MS Research's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2018<ul>\n<li>\"Characterizing and Supporting Question Answering in Human-to-Human Communication\", Xiao Yang, Ahmed Hassan Awadallah, Madian Khabsa, Wei Wang, Miaosen Wang, ACM SIGIR, 2018.</li>\n<li><a href=\"https://arxiv.org/abs/1710.07300\" rel=\"noopener noreferrer\">\"FigureQA: An Annotated Figure Dataset for Visual Reasoning\"</a>, Samira Ebrahimi Kahou, Vincent Michalski, Adam Atkinson, Akos Kadar, Adam Trischler, Yoshua Bengio, ICLR, 2018</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2017<ul>\n<li>\"Multi-level Attention Networks for Visual Question Answering\", Dongfei Yu, Jianlong Fu, Tao Mei, Yong Rui, CVPR, 2017.</li>\n<li>\"A Joint Model for Question Answering and Question Generation\", Tong Wang, Xingdi (Eric) Yuan, Adam Trischler, ICML, 2017.</li>\n<li>\"Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\", David Golub, Po-Sen Huang, Xiaodong He, Li Deng, EMNLP, 2017.</li>\n<li>\"Question-Answering with Grammatically-Interpretable Representations\", Hamid Palangi, Paul Smolensky, Xiaodong He, Li Deng,</li>\n<li>\"Search-based Neural Structured Learning for Sequential Question Answering\", Mohit Iyyer, Wen-tau Yih, Ming-Wei Chang, ACL, 2017.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2016<ul>\n<li><a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Yang_Stacked_Attention_Networks_CVPR_2016_paper.html\" rel=\"noopener noreferrer\">\"Stacked Attention Networks for Image Question Answering\"</a>, Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola, CVPR, 2016.</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/publication/question-answering-with-knowledge-base-web-and-beyond/\" rel=\"noopener noreferrer\">\"Question Answering with Knowledge Base, Web and Beyond\"</a>, Yih, Scott Wen-tau and Ma, Hao, ACM SIGIR, 2016.</li>\n<li><a href=\"https://arxiv.org/abs/1611.09830\" rel=\"noopener noreferrer\">\"NewsQA: A Machine Comprehension Dataset\"</a>, Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, Kaheer Suleman, RepL4NLP, 2016.</li>\n<li><a href=\"https://dl.acm.org/citation.cfm?id=2883080\" rel=\"noopener noreferrer\">\"Table Cell Search for Question Answering\"</a>, Sun, Huan and Ma, Hao and He, Xiaodong and Yih, Wen-tau and Su, Yu and Yan, Xifeng, WWW, 2016.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2015<ul>\n<li><a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/YangYihMeek_EMNLP-15_WikiQA.pdf\" rel=\"noopener noreferrer\">\"WIKIQA: A Challenge Dataset for Open-Domain Question Answering\"</a>, Yi Yang, Wen-tau Yih, and Christopher Meek, EMNLP, 2015.</li>\n<li><a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/AskMSRPlusTR_082815.pdf\" rel=\"noopener noreferrer\">\"Web-based Question Answering: Revisiting AskMSR\"</a>, Chen-Tse Tsai, Wen-tau Yih, and Christopher J.C. Burges, MSR-TR, 2015.</li>\n<li><a href=\"https://dl.acm.org/citation.cfm?id=2741651\" rel=\"noopener noreferrer\">\"Open Domain Question Answering via Semantic Enrichment\"</a>, Huan Sun, Hao Ma, Wen-tau Yih, Chen-Tse Tsai, Jingjing Liu, and Ming-Wei Chang, WWW, 2015.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2014<ul>\n<li><a href=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/Microsoft20Deep20QA.pdf\" rel=\"noopener noreferrer\">\"An Overview of Microsoft Deep QA System on Stanford WebQuestions Benchmark\"</a>, Zhenghao Wang, Shengquan Yan, Huaming Wang, and Xuedong Huang, MSR-TR, 2014.</li>\n<li><a href=\"https://github.com/seriousran/awesome-qa/blob/master/README.md/\" rel=\"noopener noreferrer\">\"Semantic Parsing for Single-Relation Question Answering\"</a>, Wen-tau Yih, Xiaodong He, Christopher Meek, ACL, 2014.</li>\n</ul>\n</li>\n</ul>\n<h3><p>Google AI's publication within 5 years / Subtypes of QA</p>\n</h3>\n<ul>\n<li>2018<ul>\n<li>Google QA <a></a><ul>\n<li><a href=\"https://openreview.net/pdf?id=B14TlG-RW\" rel=\"noopener noreferrer\">\"QANet: Combining Local Convolution with Global Self-Attention for Reading Comprehension\"</a>, Adams Wei Yu, David Dohan, Minh-Thang Luong, Rui Zhao, Kai Chen, Mohammad Norouzi, Quoc V. Le, ICLR, 2018.</li>\n<li><a href=\"https://openreview.net/pdf?id=S1CChZ-CZ\" rel=\"noopener noreferrer\">\"Ask the Right Questions: Active Question Reformulation with Reinforcement Learning\"</a>, Christian Buck and Jannis Bulian and Massimiliano Ciaramita and Wojciech Pawe≈Ç Gajewski and Andrea Gesmundo and Neil Houlsby and Wei Wang, ICLR, 2018.</li>\n<li><a href=\"https://arxiv.org/pdf/1612.04342.pdf\" rel=\"noopener noreferrer\">\"Building Large Machine Reading-Comprehension Datasets using Paragraph Vectors\"</a>, Radu Soricut, Nan Ding, 2018.</li>\n</ul>\n</li>\n<li>Sentence representation<ul>\n<li><a href=\"https://arxiv.org/pdf/1803.02893.pdf\" rel=\"noopener noreferrer\">\"An efficient framework for learning sentence representations\"</a>, Lajanugen Logeswaran, Honglak Lee, ICLR, 2018.</li>\n</ul>\n</li>\n<li><a href=\"https://arxiv.org/pdf/1805.05492.pdf\" rel=\"noopener noreferrer\">\"Did the model understand the question?\"</a>, Pramod K. Mudrakarta and Ankur Taly and Mukund Sundararajan and Kedar Dhamdhere, ACL, 2018.</li>\n</ul>\n</li>\n</ul>\n\n<ul>\n<li>2014<ul>\n<li>\"Great Question! Question Quality in Community Q&amp;A\", Sujith Ravi and Bo Pang and Vibhor Rastogi and Ravi Kumar, ICWSM, 2014.</li>\n</ul>\n</li>\n</ul>\n<h3><p>Books / Subtypes of QA</p>\n</h3>\n<ul>\n<li>Natural Language Question Answering system Paperback - Boris Galitsky (2003)</li>\n</ul>\n\n<ul>\n<li>New Directions in Question Answering - Mark T. Maybury (2004)</li>\n</ul>\n\n<ul>\n<li>Part 3. 5. Question Answering in The Oxford Handbook of Computational Linguistics - Sanda Harabagiu and Dan Moldovan (2005)</li>\n</ul>\n\n<ul>\n<li>Chap.28 Question Answering in Speech and Language Processing - Daniel Jurafsky &amp; James H. Martin (2017)</li>\n</ul>\n<h3><p>Links / Subtypes of QA</p>\n</h3>\n<ul>\n<li><a href=\"https://towardsdatascience.com/building-a-question-answering-system-part-1-9388aadff507\" rel=\"noopener noreferrer\">Building a Question-Answering System from Scratch‚Äî Part 1</a></li>\n</ul>\n\n<ul>\n<li><a href=\"https://www.oreilly.com/ideas/question-answering-with-tensorflow\" rel=\"noopener noreferrer\">Qeustion Answering with Tensorflow By Steven Hewitt, O'REILLY, 2017</a></li>\n</ul>\n"
    }
  ]
}
