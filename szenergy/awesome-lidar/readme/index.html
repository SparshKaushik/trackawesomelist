<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Awesome Lidar (szenergy/awesome-lidar) Overview - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com/szenergy/awesome-lidar/readme/" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Awesome Lidar Overview" />
    <meta property="og:description" content="üòé Awesome LIDAR list. The list includes LIDAR manufacturers, datasets, point cloud-processing algorithms, point cloud frameworks and simulators." />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Awesome Lidar Overview</h1>
<p>üòé Awesome LIDAR list. The list includes LIDAR manufacturers, datasets, point cloud-processing algorithms, point cloud frameworks and simulators.</p>
<p><a href="/">üè† Home</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/szenergy/awesome-lidar/rss.xml">üî• Feed</a><span> ¬∑ </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">üìÆ Subscribe</a><span> ¬∑ </span><a href="https://github.com/sponsors/theowenyoung">‚ù§Ô∏è  Sponsor</a><span> ¬∑ </span><a href="https://github.com/szenergy/awesome-lidar">üò∫ szenergy/awesome-lidar</a><span> ¬∑ </span><span>‚≠ê 1.1K</span><span> ¬∑ </span><span>üè∑Ô∏è Hardware</span></p>
<p><span>[ </span><a href="/szenergy/awesome-lidar/">Daily</a><span> / </span><a href="/szenergy/awesome-lidar/week/">Weekly</a><span> / </span><span>Overview</span><span> ]</span></p>
<h1 id="awesome-lidar-awesome"><a class="anchor" aria-hidden="true" tabindex="-1" href="#awesome-lidar-awesome"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Awesome LIDAR <a href="https://awesome.re" rel="noopener noreferrer"><img src="https://awesome.re/badge-flat.svg" alt="Awesome" /></a></h1><img src="https://github.com/szenergy/awesome-lidar/raw/main/img/lidar.svg" align="right" width="100" />

<blockquote>
<p>A curated list of awesome LIDAR sensors and its applications.</p>
</blockquote>
<p><a href="https://en.wikipedia.org/wiki/Lidar" rel="noopener noreferrer">LIDAR</a> is a remote sensing sensor that uses laser light to measure the surroundings in ~cm accuracy. The sensory data is usually referred as point cloud which means set of data points in 3D or 2D. The list contains hardwares, datasets, point cloud-processing algorithms, point cloud frameworks, simulators etc.</p>
<p>Contributions are welcome! Please <a href="https://github.com/szenergy/awesome-lidar/blob/main/README.md/contributing.md" rel="noopener noreferrer">check out</a> our guidelines.</p>
<blockquote>
<p>[!TIP]
An optional view: <a href="https://www.trackawesomelist.com/szenergy/awesome-lidar/readme/" rel="noopener noreferrer">trackawesomelist.com/szenergy/awesome-lidar</a></p>
</blockquote>
<h2 id="contents"><a class="anchor" aria-hidden="true" tabindex="-1" href="#contents"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contents</h2><ul>
<li><a href="#awesome-lidar-">Awesome LIDAR </a><ul>
<li><a href="#contents">Contents</a></li>
<li><a href="#conventions">Conventions</a></li>
<li><a href="#manufacturers">Manufacturers</a></li>
<li><a href="#datasets">Datasets</a></li>
<li><a href="#libraries">Libraries</a></li>
<li><a href="#frameworks">Frameworks</a></li>
<li><a href="#algorithms">Algorithms</a><ul>
<li><a href="#basic-matching-algorithms">Basic matching algorithms</a></li>
<li><a href="#semantic-segmentation">Semantic segmentation</a></li>
<li><a href="#ground-segmentation">Ground segmentation</a></li>
<li><a href="#simultaneous-localization-and-mapping-slam-and-lidar-based-odometry-and-or-mapping-loam">Simultaneous localization and mapping SLAM and LIDAR-based odometry and or mapping LOAM</a></li>
<li><a href="#object-detection-and-object-tracking">Object detection and object tracking</a></li>
<li><a href="#lidar-other-sensor-calibration">LIDAR-other-sensor calibration</a></li>
</ul>
</li>
<li><a href="#simulators">Simulators</a></li>
<li><a href="#related-awesome">Related awesome</a></li>
<li><a href="#others">Others</a></li>
</ul>
</li>
</ul>
<h2 id="conventions"><a class="anchor" aria-hidden="true" tabindex="-1" href="#conventions"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conventions</h2><ul>
<li>Any list item with <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /> badge has a GitHub repo or organization</li>
<li>Any list item with <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /> badge has YouTube videos or channel</li>
<li>Any list item with <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /> badge has a scientific paper or detailed description</li>
<li>Any list item with <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /> badge is <a href="https://docs.ros.org/" rel="noopener noreferrer"><code>ROS 2</code></a> compatible</li>
</ul>
<h2 id="manufacturers"><a class="anchor" aria-hidden="true" tabindex="-1" href="#manufacturers"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Manufacturers</h2><ul>
<li><a href="https://velodynelidar.com/" rel="noopener noreferrer">Velodyne</a> - Ouster and Velodyne announced the successful completion of their <em>merger</em> of equals, effective February 10, 2023. Velodyne was a mechanical and solid-state LIDAR manufacturer. The headquarter is in San Jose, California, USA.<ul>
<li><a href="https://www.youtube.com/user/VelodyneLiDAR" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/ros-drivers/velodyne" rel="noopener noreferrer">ROS driver <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/valgur/velodyne_decoder" rel="noopener noreferrer">C++/Python library <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://ouster.com/" rel="noopener noreferrer">Ouster</a> - LIDAR manufacturer, specializing in digital-spinning LiDARs. Ouster is headquartered in San Francisco, USA.<ul>
<li><a href="https://www.youtube.com/c/Ouster-lidar" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/ouster-lidar" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.livoxtech.com/" rel="noopener noreferrer">Livox</a> - LIDAR manufacturer.<ul>
<li><a href="https://www.youtube.com/channel/UCnLpB5QxlQUexi40vM12mNQ" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/Livox-SDK" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.sick.com/ag/en/" rel="noopener noreferrer">SICK</a> - Sensor and automation manufacturer, the headquarter is located in Waldkirch, Germany.<ul>
<li><a href="https://www.youtube.com/user/SICKSensors" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/SICKAG" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.hokuyo-aut.jp/" rel="noopener noreferrer">Hokuyo</a> - Sensor and automation manufacturer, headquartered in Osaka, Japan.<ul>
<li><a href="https://www.youtube.com/channel/UCYzJXC82IEy-h-io2REin5g" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://autonomousdriving.pioneer/en/3d-lidar/" rel="noopener noreferrer">Pioneer</a> - LIDAR manufacturer, specializing in MEMS mirror-based raster scanning LiDARs (3D-LiDAR). Pioneer is headquartered in Tokyo, Japan.<ul>
<li><a href="https://www.youtube.com/user/PioneerCorporationPR" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.luminartech.com/" rel="noopener noreferrer">Luminar</a> - LIDAR manufacturer focusing on compact, auto-grade sensors. Luminar is headquartered Palo Alto, California, USA.<ul>
<li><a href="https://vimeo.com/luminartech" rel="noopener noreferrer">Vimeo channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/luminartech" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://www.hesaitech.com/" rel="noopener noreferrer">Hesai</a> - Hesai Technology is a LIDAR manufacturer, founded in Shanghai, China.<ul>
<li><a href="https://www.youtube.com/channel/UCG2_ffm6sdMsK-FX8yOLNYQ/videos" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/HesaiTechnology" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="http://www.robosense.ai/" rel="noopener noreferrer">Robosense</a> - RoboSense (Suteng Innovation Technology Co., Ltd.) is a LIDAR sensor, AI algorithm and IC chipset maufactuirer based in Shenzhen and Beijing (China).<ul>
<li><a href="https://www.youtube.com/channel/UCYCK8j678N6d_ayWE_8F3rQ" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/RoboSense-LiDAR" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.lslidar.com/" rel="noopener noreferrer">LSLIDAR</a> - LSLiDAR (Leishen Intelligent System Co., Ltd.) is a LIDAR sensor manufacturer and complete solution provider based in Shenzhen, China.<ul>
<li><a href="https://www.youtube.com/@lslidar2015" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/Lslidar" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.ibeo-as.com/" rel="noopener noreferrer">Ibeo</a> - Ibeo Automotive Systems GmbH is an automotive industry / environmental detection laserscanner / LIDAR manufacturer, based in Hamburg, Germany.<ul>
<li><a href="https://www.youtube.com/c/IbeoAutomotive/" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://innoviz.tech/" rel="noopener noreferrer">Innoviz</a> - Innoviz technologies / specializes in solid-state LIDARs.<ul>
<li><a href="https://www.youtube.com/channel/UCVc1KFsu2eb20M8pKFwGiFQ" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://quanergy.com/" rel="noopener noreferrer">Quanenergy</a> - Quanenergy Systems / solid-state and mechanical LIDAR sensors / offers End-to-End solutions in Mapping, Industrial Automation, Transportation and Security. The headquarter is located in Sunnyvale, California, USA.<ul>
<li><a href="https://www.youtube.com/c/QuanergySystems" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.cepton.com/index.html" rel="noopener noreferrer">Cepton</a> - Cepton (Cepton Technologies, Inc.) / pioneers in frictionless, and mirrorless design, self-developed MMT (micro motion technology) lidar technology. The headquarter is located in San Jose, California, USA.<ul>
<li><a href="https://www.youtube.com/channel/UCUgkBZZ1UWWkkXJ5zD6o8QQ" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.blickfeld.com/" rel="noopener noreferrer">Blickfeld</a> - Blickfeld is a solid-state LIDAR manufacturer for autonomous mobility and IoT, based in M√ºnchen, Germany.<ul>
<li><a href="https://www.youtube.com/c/BlickfeldLiDAR" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/Blickfeld" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://www.neuvition.com/" rel="noopener noreferrer">Neuvition</a> - Neuvition is a solid-state LIDAR manufacturer based in Wujiang, China.<ul>
<li><a href="https://www.youtube.com/channel/UClFjlekWJo4T5bfzxX0ZW3A" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.aeva.com/" rel="noopener noreferrer">Aeva</a> - Aeva is bringing the next wave of perception technology to all devices for automated driving, consumer electronics, health, industrial robotics and security, Mountain View, California, USA.<ul>
<li><a href="https://www.youtube.com/c/AevaInc" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/aevainc" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://www.xenomatix.com/" rel="noopener noreferrer">XenomatiX</a> - XenomatiX offers true solid-state lidar sensors based on a multi-beam lasers concept. XenomatiX is headquartered in Leuven, Belgium.<ul>
<li><a href="https://www.youtube.com/@XenomatiXTruesolidstatelidar" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://microvision.com/" rel="noopener noreferrer">MicroVision</a> - A pioneer in MEMS-based laser beam scanning technology, the main focus is on building Automotive grade Lidar sensors, located in Hamburg, Germany.<ul>
<li><a href="https://www.youtube.com/user/mvisvideo" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/MicroVision-Inc" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://www.preact-tech.com/" rel="noopener noreferrer">PreAct</a> - PreAct's mission is to make life safer and more efficient for the automotive industry and beyond. The headquarter is located in Portland, Oregon, USA.<ul>
<li><a href="https://www.youtube.com/@PreActTechnologies" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.pepperl-fuchs.com/" rel="noopener noreferrer">Pepperl+Fuchs</a> - Is a global technology company, specialized in innovative automation solutions and sensor technologies, such as LiDAR, based in Mannheim, Germany.<ul>
<li><a href="https://www.youtube.com/c/pepperl-fuchs" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://www.youtube.com/user/PepperlFuchsUSA" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/PepperlFuchs" rel="noopener noreferrer">GitHub organization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
</ul>
<h2 id="datasets"><a class="anchor" aria-hidden="true" tabindex="-1" href="#datasets"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Datasets</h2><ul>
<li><a href="https://avdata.ford.com/" rel="noopener noreferrer">Ford Dataset</a> - The dataset is time-stamped and contains raw data from all the sensors, calibration values, pose trajectory, ground truth pose, and 3D maps. The data is Robot Operating System (ROS) compatible.<ul>
<li><a href="https://arxiv.org/pdf/2003.07969.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
<li><a href="https://github.com/Ford/AVData" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://www.a2d2.audi" rel="noopener noreferrer">Audi A2D2 Dataset</a> - The dataset features 2D semantic segmentation, 3D point clouds, 3D bounding boxes, and vehicle bus data.<ul>
<li><a href="https://www.a2d2.audi/content/dam/a2d2/dataset/a2d2-audi-autonomous-driving-dataset.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://waymo.com/open/" rel="noopener noreferrer">Waymo Open Dataset</a> - The dataset contains independently-generated labels for lidar and camera data, not simply projections.</li>
<li><a href="https://robotcar-dataset.robots.ox.ac.uk/" rel="noopener noreferrer">Oxford RobotCar</a> - The Oxford RobotCar Dataset contains over 100 repetitions of a consistent route through Oxford, UK, captured over a period of over a year.<ul>
<li><a href="https://www.youtube.com/c/ORIOxfordRoboticsInstitute" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://robotcar-dataset.robots.ox.ac.uk/images/RCD_RTK.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://epan-utbm.github.io/utbm_robocar_dataset/" rel="noopener noreferrer">EU Long-term Dataset</a> - This dataset was collected with our robocar (in human driving mode of course), equipped up to eleven heterogeneous sensors, in the downtown (for long-term data) and a suburb (for roundabout data) of Montb√©liard in France. The vehicle speed was limited to 50 km/h following the French traffic rules.</li>
<li><a href="https://www.nuscenes.org/" rel="noopener noreferrer">NuScenes</a> - Public large-scale dataset for autonomous driving.<ul>
<li><a href="https://arxiv.org/pdf/1903.11027.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://level5.lyft.com/dataset/" rel="noopener noreferrer">Lyft</a> - Public dataset collected by a fleet of Ford Fusion vehicles equipped with LIDAR and camera.</li>
<li><a href="http://www.cvlibs.net/datasets/kitti/raw_data.php" rel="noopener noreferrer">KITTI</a> - Widespread public dataset, pirmarily focusing on computer vision applications, but also contains LIDAR point cloud. <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="http://semantic-kitti.org/" rel="noopener noreferrer">Semantic KITTI</a> - Dataset for semantic and panoptic scene segmentation.<ul>
<li><a href="https://www.youtube.com/watch?v=3qNOXvkpK4I" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://cadcd.uwaterloo.ca/" rel="noopener noreferrer">CADC - Canadian Adverse Driving Conditions Dataset</a> - Public large-scale dataset for autonomous driving in adverse weather conditions (snowy weather).<ul>
<li><a href="https://arxiv.org/pdf/2001.10117.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://www.autodrive.utoronto.ca/uoftped50" rel="noopener noreferrer">UofTPed50 Dataset</a> - University of Toronto, aUToronto's self-driving car dataset, which contains GPS/IMU, 3D LIDAR, and Monocular camera data. It can be used for 3D pedestrian detection.<ul>
<li><a href="https://arxiv.org/pdf/1905.08758.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://scale.com/open-datasets/pandaset" rel="noopener noreferrer">PandaSet Open Dataset</a> - Public large-scale dataset for autonomous driving provided by Hesai &amp; Scale. It enables researchers to study challenging urban driving situations using the full sensor suit of a real self-driving-car.</li>
<li><a href="https://developer.volvocars.com/open-datasets/cirrus/" rel="noopener noreferrer">Cirrus dataset</a> A public datatset from non-uniform distribution of LIDAR scanning patterns with emphasis on long range. In this dataset Luminar Hydra LIDAR is used. The dataset is available at the Volvo Cars Innovation Portal.<ul>
<li><a href="https://arxiv.org/pdf/2012.02938.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="http://its.acfr.usyd.edu.au/datasets/usyd-campus-dataset/" rel="noopener noreferrer">USyd Dataset- The Univerisity of Sydney Campus- Dataset</a> - Long-term, large-scale dataset collected over the period of 1.5 years on a weekly basis over the University of Sydney campus and surrounds. It includes multiple sensor modalities and covers various environmental conditions. ROS compatible<ul>
<li><a href="https://ieeexplore.ieee.org/document/9109704" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/Robotics-BUT/Brno-Urban-Dataset" rel="noopener noreferrer">Brno Urban Dataset <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Navigation and localisation dataset for self driving cars and autonomous robots in Brno, Czechia.<ul>
<li><a href="https://ieeexplore.ieee.org/document/9197277" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=wDFePIViwqY" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.argoverse.org/" rel="noopener noreferrer">Argoverse <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - A dataset designed to support autonomous vehicle perception tasks including 3D tracking and motion forecasting collected in Pittsburgh, Pennsylvania and Miami, Florida, USA.<ul>
<li><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Chang_Argoverse_3D_Tracking_and_Forecasting_With_Rich_Maps_CVPR_2019_paper.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=DM8jWfi69zM" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.boreas.utias.utoronto.ca/" rel="noopener noreferrer">Boreas Dataset</a> - The Boreas dataset was collected by driving a repeated route over the course of 1 year resulting in stark seasonal variations. In total, Boreas contains over 350km of driving data including several sequences with adverse weather conditions such as rain and heavy snow. The Boreas data-taking platform features a unique high-quality sensor suite with a 128-channel Velodyne Alpha Prime lidar, a 360-degree Navtech radar, and accurate ground truth poses obtained from an Applanix POSLV GPS/IMU.<ul>
<li><a href="https://arxiv.org/abs/2203.10168" rel="noopener noreferrer">Paper üì∞</a></li>
<li><a href="https://github.com/utiasASRL/pyboreas" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
</ul>
<h2 id="libraries"><a class="anchor" aria-hidden="true" tabindex="-1" href="#libraries"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Libraries</h2><ul>
<li><a href="http://www.pointclouds.org/" rel="noopener noreferrer">Point Cloud Library (PCL)</a> - Popular highly parallel programming library, with numerous industrial and research use-cases.<ul>
<li><a href="https://github.com/PointCloudLibrary/pcl" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="http://www.open3d.org/docs/release/" rel="noopener noreferrer">Open3D library</a> - Open3D library contanins 3D data processing and visualization algorithms. It is open-source and supports both C++ and Python.<ul>
<li><a href="https://github.com/intel-isl/Open3D" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/channel/UCRJBlASPfPBtPXJSPffJV-w" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1903.02428.pdf" rel="noopener noreferrer">PyTorch Geometric <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - A geometric deep learning extension library for PyTorch.<ul>
<li><a href="https://github.com/rusty1s/pytorch_geometric" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://pytorch3d.org/" rel="noopener noreferrer">PyTorch3d</a> - PyTorch3d is a library for deep learning with 3D data written and maintained by the Facebook AI Research Computer Vision Team.<ul>
<li><a href="https://github.com/facebookresearch/pytorch3d" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://kaolin.readthedocs.io/en/latest/" rel="noopener noreferrer">Kaolin</a> - Kaolin is a PyTorch Library for Accelerating 3D Deep Learning Research written by NVIDIA Technologies for game and application developers.<ul>
<li><a href="https://github.com/NVIDIAGameWorks/kaolin/" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://arxiv.org/pdf/1911.05063.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://docs.pyvista.org/" rel="noopener noreferrer">PyVista</a> - 3D plotting and mesh analysis through a streamlined interface for the Visualization Toolkit.<ul>
<li><a href="https://github.com/pyvista/pyvista" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://joss.theoj.org/papers/10.21105/joss.01450" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://pyntcloud.readthedocs.io/en/latest/" rel="noopener noreferrer">pyntcloud</a> - Pyntcloud is a Python 3 library for working with 3D point clouds leveraging the power of the Python scientific stack.<ul>
<li><a href="https://github.com/daavoo/pyntcloud" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://virtual-vehicle.github.io/pointcloudset/" rel="noopener noreferrer">pointcloudset</a> - Python library for efficient analysis of large datasets of point clouds recorded over time.<ul>
<li><a href="https://github.com/virtual-vehicle/pointcloudset" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://rapidlasso.de/lastools/" rel="noopener noreferrer">LAStools</a> - C++ library and command-line tools for pointcloud processing and data compressing.<ul>
<li><a href="https://github.com/LAStools/LAStools" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
</ul>
<h2 id="frameworks"><a class="anchor" aria-hidden="true" tabindex="-1" href="#frameworks"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Frameworks</h2><ul>
<li><a href="https://www.autoware.ai/" rel="noopener noreferrer">Autoware</a> - Popular framework in academic and research applications of autonomous vehicles.<ul>
<li><a href="https://github.com/autowarefoundation" rel="noopener noreferrer">GitHub oragnization <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.researchgate.net/profile/Takuya_Azumi/publication/327198306_Autoware_on_Board_Enabling_Autonomous_Vehicles_with_Embedded_Systems/links/5c9085da45851564fae6dcd0/Autoware-on-Board-Enabling-Autonomous-Vehicles-with-Embedded-Systems.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://apollo.auto/" rel="noopener noreferrer">Baidu Apollo</a> - Apollo is a popular framework which accelerates the development, testing, and deployment of Autonomous Vehicles.<ul>
<li><a href="https://github.com/ApolloAuto/apollo" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/c/ApolloAuto" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://ieeexplore.ieee.org/document/11024231" rel="noopener noreferrer">ALFA Framework <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - An open-source framework for developing processing algorithms, with a focus on embedded platforms and hardware acceleration.<ul>
<li><a href="https://github.com/alfa-project/alfa-framework" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></a></li>
</ul>
</li>
</ul>
<h2 id="algorithms"><a class="anchor" aria-hidden="true" tabindex="-1" href="#algorithms"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Algorithms</h2><h3 id="basic-matching-algorithms"><a class="anchor" aria-hidden="true" tabindex="-1" href="#basic-matching-algorithms"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Basic matching algorithms</h3><ul>
<li><a href="https://www.youtube.com/watch?v=uzOCS_gdZuM" rel="noopener noreferrer">Iterative closest point (ICP) <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a> - The must-have algorithm for feature matching applications (ICP).<ul>
<li><a href="https://github.com/pglira/simpleICP" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - simpleICP C++ /Julia / Matlab / Octave / Python implementation.</li>
<li><a href="https://github.com/ethz-asl/libpointmatcher" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - libpointmatcher, a modular library implementing the ICP algorithm.</li>
<li><a href="https://link.springer.com/content/pdf/10.1007/s10514-013-9327-2.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - libpointmatcher: Comparing ICP variants on real-world data sets.</li>
</ul>
</li>
<li><a href="https://www.youtube.com/watch?v=0YV4a2asb8Y" rel="noopener noreferrer">Normal distributions transform <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a> - More recent massively-parallel approach to feature matching (NDT).</li>
<li><a href="https://www.youtube.com/watch?v=kMMH8rA1ggI" rel="noopener noreferrer">KISS-ICP <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a> - In Defense of Point-to-Point ICP ‚Äì Simple, Accurate, and Robust Registration If Done the Right Way.<ul>
<li><a href="https://github.com/PRBonn/kiss-icp" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://arxiv.org/pdf/2209.15397.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
</ul>
<h3 id="semantic-segmentation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#semantic-segmentation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Semantic segmentation</h3><ul>
<li><a href="https://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/milioto2019iros.pdf" rel="noopener noreferrer">RangeNet++ <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Fast and Accurate LiDAR Sematnic Segmentation with fully convolutional network.<ul>
<li><a href="https://github.com/PRBonn/rangenet_lib" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=uo3ZuLuFAzk" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2003.14032.pdf" rel="noopener noreferrer">PolarNet <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - An Improved Grid Representation for Online LiDAR Point Clouds Semantic Segmentation.<ul>
<li><a href="https://github.com/edwardzhou130/PolarSeg" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=iIhttRSMqjE" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1711.08488.pdf" rel="noopener noreferrer">Frustum PointNets <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Frustum PointNets for 3D Object Detection from RGB-D Data.<ul>
<li><a href="https://github.com/charlesq34/frustum-pointnets" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://larissa.triess.eu/scan-semseg/" rel="noopener noreferrer">Study of LIDAR Semantic Segmentation</a> - Scan-based Semantic Segmentation of LiDAR Point Clouds: An Experimental Study IV 2020.<ul>
<li><a href="https://arxiv.org/abs/2004.11803" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
<li><a href="http://ltriess.github.io/scan-semseg" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://www.ipb.uni-bonn.de/pdfs/chen2021ral-iros.pdf" rel="noopener noreferrer">LIDAR-MOS <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Moving Object Segmentation in 3D LIDAR Data<ul>
<li><a href="https://github.com/PRBonn/LiDAR-MOS" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=NHvsYhk4dhw" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1711.09869.pdf" rel="noopener noreferrer">SuperPoint Graph <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>- Large-scale Point Cloud Semantic Segmentation with Superpoint Graphs<ul>
<li><a href="https://github.com/loicland/superpoint_graph" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=Ijr3kGSU_tU" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2306.08045.pdf" rel="noopener noreferrer">SuperPoint Transformer <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>- Efficient 3D Semantic Segmentation with Superpoint Transformer<ul>
<li><a href="https://github.com/drprojects/superpoint_transformer" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=2qKhpQs9gJw" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1911.11236.pdf" rel="noopener noreferrer">RandLA-Net <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Efficient Semantic Segmentation of Large-Scale Point Clouds<ul>
<li><a href="https://github.com/QingyongHu/RandLA-Net" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=Ar3eY_lwzMk" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2108.13757.pdf" rel="noopener noreferrer">Automatic labelling <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Automatic labelling of urban point clouds using data fusion<ul>
<li><a href="https://github.com/Amsterdam-AI-Team/Urban_PointCloud_Processing" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=qMj_WM6D0vI" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
</ul>
<h3 id="ground-segmentation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#ground-segmentation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Ground segmentation</h3><ul>
<li><a href="https://github.com/ori-drs/plane_seg" rel="noopener noreferrer">Plane Seg <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - ROS comapatible ground plane segmentation; a library for fitting planes to LIDAR.<ul>
<li><a href="https://www.youtube.com/watch?v=YYs4lJ9t-Xo" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://ieeexplore.ieee.org/abstract/document/5548059" rel="noopener noreferrer">LineFit Graph <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>- Line fitting-based fast ground segmentation for horizontal 3D LiDAR data<ul>
<li><a href="https://github.com/lorenwel/linefit_ground_segmentation" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2108.05560.pdf" rel="noopener noreferrer">Patchwork <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>- Region-wise plane fitting-based robust and fast ground segmentation for 3D LiDAR data<ul>
<li><a href="https://github.com/LimHyungTae/patchwork" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=rclqeDi4gow" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2207.11919.pdf" rel="noopener noreferrer">Patchwork++ <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>- Improved version of Patchwork. Patchwork++ provides pybinding as well for deep learning users<ul>
<li><a href="https://github.com/url-kaist/patchwork-plusplus-ros" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=fogCM159GRk" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
</ul>
<h3 id="simultaneous-localization-and-mapping-slam-and-lidar-based-odometry-and-or-mapping-loam"><a class="anchor" aria-hidden="true" tabindex="-1" href="#simultaneous-localization-and-mapping-slam-and-lidar-based-odometry-and-or-mapping-loam"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simultaneous localization and mapping SLAM and LIDAR-based odometry and or mapping LOAM</h3><ul>
<li><a href="https://youtu.be/8ezyhTAEyHs" rel="noopener noreferrer">LOAM J. Zhang and S. Singh <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a> - LOAM: Lidar Odometry and Mapping in Real-time.</li>
<li><a href="https://github.com/RobustFieldAutonomyLab/LeGO-LOAM" rel="noopener noreferrer">LeGO-LOAM <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - A lightweight and ground optimized lidar odometry and mapping (LeGO-LOAM) system for ROS compatible UGVs.<ul>
<li><a href="https://www.youtube.com/watch?v=7uCxLUs9fwQ" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li>ROS 2 verison on different repo: <a href="https://github.com/eperdices/LeGO-LOAM-SR" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://github.com/cartographer-project/cartographer" rel="noopener noreferrer">Cartographer <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Cartographer is ROS compatible system that provides real-time simultaneous localization and mapping (SLAM) in 2D and 3D across multiple platforms and sensor configurations. <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /><ul>
<li><a href="https://www.youtube.com/watch?v=29Knm-phAyI" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2019iros.pdf" rel="noopener noreferrer">SuMa++ <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - LiDAR-based Semantic SLAM.<ul>
<li><a href="https://github.com/PRBonn/semantic_suma/" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://youtu.be/uo3ZuLuFAzk" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://www.ipb.uni-bonn.de/wp-content/papercite-data/pdf/chen2020rss.pdf" rel="noopener noreferrer">OverlapNet <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> -  Loop Closing for LiDAR-based SLAM.<ul>
<li><a href="https://github.com/PRBonn/OverlapNet" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=YTfliBco6aw" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2007.00258.pdf" rel="noopener noreferrer">LIO-SAM <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping.<ul>
<li><a href="https://github.com/TixiaoShan/LIO-SAM" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=A0H8CoORZJU" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://ras.papercept.net/images/temp/IROS/files/0855.pdf" rel="noopener noreferrer">Removert <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Remove, then Revert: Static Point cloud Map Construction using Multiresolution Range Images.<ul>
<li><a href="https://github.com/irapkaist/removert" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=M9PEGi5fAq8" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/2504.11580" rel="noopener noreferrer">RESPLE <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - Recursive Spline Estimation for LiDAR-Based Odometry<ul>
<li><a href="https://github.com/ASIG-X/RESPLE" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=3-xLRRT25ys" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
</ul>
<h3 id="object-detection-and-object-tracking"><a class="anchor" aria-hidden="true" tabindex="-1" href="#object-detection-and-object-tracking"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Object detection and object tracking</h3><ul>
<li><a href="https://arxiv.org/abs/1912.04976" rel="noopener noreferrer">Learning to Optimally Segment Point Clouds <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - By Peiyun Hu, David Held, and Deva Ramanan at Carnegie Mellon University. IEEE Robotics and Automation Letters, 2020.<ul>
<li><a href="https://www.youtube.com/watch?v=wLxIAwIL870" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/peiyunh/opcseg" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1809.05590.pdf" rel="noopener noreferrer">Leveraging Heteroscedastic Aleatoric Uncertainties for Robust Real-Time LiDAR 3D Object Detection <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - By Di Feng, Lars Rosenbaum, Fabian Timm, Klaus Dietmayer. 30th IEEE Intelligent Vehicles Symposium, 2019.<ul>
<li><a href="https://www.youtube.com/watch?v=2DzH9COLpkU" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://arxiv.org/pdf/1912.04986.pdf" rel="noopener noreferrer">What You See is What You Get: Exploiting Visibility for 3D Object Detection <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - By Peiyun Hu, Jason Ziglar, David Held, Deva Ramanan, 2019.<ul>
<li><a href="https://www.youtube.com/watch?v=497OF-otY2k" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
<li><a href="https://github.com/peiyunh/WYSIWYG" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://doi.org/10.3390/s22010194" rel="noopener noreferrer">urban_road_filter <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a>-
Real-Time LIDAR-Based Urban Road and Sidewalk Detection for Autonomous Vehicles<ul>
<li><a href="https://github.com/jkk-research/urban_road_filter" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=T2qi4pldR-E" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.semanticscholar.org/paper/3D-LIDAR-Multi-Object-Tracking-for-Autonomous-and-Rachman/bafc8fcdee9b22708491ea1293524ece9e314851" rel="noopener noreferrer">detection_by_tracker <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a> - 3D-LIDAR Multi Object Tracking for Autonomous Driving: Multi-target Detection and Tracking under Urban Road Uncertainties, also used in Autoware Universe<ul>
<li><a href="https://autowarefoundation.github.io/autoware.universe/main/perception/detection_by_tracker/" rel="noopener noreferrer">GitHub <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=xSGCpb24dhI" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
</ul>
<h3 id="lidar-other-sensor-calibration"><a class="anchor" aria-hidden="true" tabindex="-1" href="#lidar-other-sensor-calibration"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>LIDAR-other-sensor calibration</h3><ul>
<li><a href="https://koide3.github.io/direct_visual_lidar_calibration/" rel="noopener noreferrer">direct_visual_lidar_calibration</a> - General, Single-shot, Target-less, and Automatic LiDAR-Camera Extrinsic Calibration Toolbox<ul>
<li><a href="https://github.com/koide3/direct_visual_lidar_calibration" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://staff.aist.go.jp/k.koide/assets/pdf/icra2023.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/PJLab-ADG/SensorsCalibration" rel="noopener noreferrer">OpenCalib <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - A Multi-sensor Calibration Toolbox for Autonomous Driving<ul>
<li><a href="https://arxiv.org/pdf/2205.14087" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
</ul>
</li>
</ul>
<h2 id="simulators"><a class="anchor" aria-hidden="true" tabindex="-1" href="#simulators"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Simulators</h2><ul>
<li><a href="https://www.coppeliarobotics.com/coppeliaSim" rel="noopener noreferrer">CoppeliaSim</a> - Cross-platform general-purpose robotic simulator (formerly known as V-REP).<ul>
<li><a href="https://www.youtube.com/user/VirtualRobotPlatform" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="http://gazebosim.org/" rel="noopener noreferrer">OSRF Gazebo</a> - OGRE-based general-purpose robotic simulator, ROS/ROS 2 compatible.<ul>
<li><a href="https://github.com/osrf/gazebo" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
</ul>
</li>
<li><a href="https://carla.org/" rel="noopener noreferrer">CARLA</a> - Unreal Engine based simulator for automotive applications. Compatible with Autoware, Baidu Apollo and ROS/ROS 2.<ul>
<li><a href="https://github.com/carla-simulator/carla" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/channel/UC1llP9ekCwt8nEJzMJBQekg" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.lgsvlsimulator.com/" rel="noopener noreferrer">LGSVL / SVL</a> - Unity Engine based simulator for automotive applications. Compatible with Autoware, Baidu Apollo and ROS/ROS 2. <em>Note:</em> LG has made the difficult decision to <a href="https://www.svlsimulator.com/news/2022-01-20-svl-simulator-sunset" rel="noopener noreferrer">suspend</a> active development of SVL Simulator.<ul>
<li><a href="https://github.com/lgsvl/simulator" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/c/LGSVLSimulator" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/OSSDC/OSSDC-SIM" rel="noopener noreferrer">OSSDC SIM</a> - Unity Engine based simulator for automotive applications, based on the suspended LGSVL simulator, but an active development. Compatible with Autoware, Baidu Apollo and ROS/ROS 2.<ul>
<li><a href="https://github.com/OSSDC/OSSDC-SIM" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=fU_C38WEwGw" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://microsoft.github.io/AirSim" rel="noopener noreferrer">AirSim</a> - Unreal Engine based simulator for drones and automotive. Compatible with ROS.<ul>
<li><a href="https://github.com/microsoft/AirSim" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=gnz1X3UNM5Y" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://tier4.github.io/AWSIM" rel="noopener noreferrer">AWSIM</a> - Unity Engine based simulator for automotive applications. Compatible with Autoware and ROS 2.<ul>
<li><a href="https://github.com/tier4/AWSIM" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/watch?v=FH7aBWDmSNA" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
</ul>
<h2 id="related-awesome"><a class="anchor" aria-hidden="true" tabindex="-1" href="#related-awesome"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Related awesome</h2><ul>
<li><a href="https://github.com/Yochengliu/awesome-point-cloud-analysis#readme" rel="noopener noreferrer">Awesome point cloud analysis <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/Kiloreux/awesome-robotics#readme" rel="noopener noreferrer">Awesome robotics <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/jslee02/awesome-robotics-libraries#readme" rel="noopener noreferrer">Awesome robotics libraries <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/fkromer/awesome-ros2#readme" rel="noopener noreferrer">Awesome ROS 2 <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://github.com/owainlewis/awesome-artificial-intelligence#readme" rel="noopener noreferrer">Awesome artificial intelligence <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/jbhuang0604/awesome-computer-vision#readme" rel="noopener noreferrer">Awesome computer vision <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/josephmisiti/awesome-machine-learning#readme" rel="noopener noreferrer">Awesome machine learning <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/ChristosChristofidis/awesome-deep-learning#readme" rel="noopener noreferrer">Awesome deep learning <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/aikorea/awesome-rl/#readme" rel="noopener noreferrer">Awesome reinforcement learning <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/youngguncho/awesome-slam-datasets#readme" rel="noopener noreferrer">Awesome SLAM datasets <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/kitspace/awesome-electronics#readme" rel="noopener noreferrer">Awesome electronics <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/jaredthecoder/awesome-vehicle-security#readme" rel="noopener noreferrer">Awesome vehicle security and car hacking <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/Deephome/Awesome-LiDAR-Camera-Calibration" rel="noopener noreferrer">Awesome LIDAR-Camera calibration <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/hogyun2/awesome-lidar-place-recognition" rel="noopener noreferrer">Awesome LiDAR Place Recognition <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
<li><a href="https://github.com/neng-wang/Awesome-LiDAR-MOS" rel="noopener noreferrer">Awesome-LiDAR-MOS <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> Moving Object Segmentation</li>
<li><a href="https://github.com/sjtuyinjie/awesome-LiDAR-Visual-SLAM" rel="noopener noreferrer">Awesome-LiDAR-Visual-SLAM <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
<h2 id="others"><a class="anchor" aria-hidden="true" tabindex="-1" href="#others"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Others</h2><ul>
<li><a href="https://github.com/philipturner/ARHeadsetKit" rel="noopener noreferrer">ARHeadsetKit</a> - Using $5 Google Cardboard to replicate Microsoft Hololens. Hosts the source code for research on <a href="https://github.com/philipturner/scene-color-reconstruction" rel="noopener noreferrer">scene color reconstruction</a>.</li>
<li><a href="https://github.com/marian42/pointcloudprinter" rel="noopener noreferrer">Pointcloudprinter <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - A tool to turn point cloud data from aerial lidar scans into solid meshes for 3D printing.</li>
<li><a href="https://cloudcompare.org/" rel="noopener noreferrer">CloudCompare</a> - CloudCompare is a free, cross-platform point cloud editor software.<ul>
<li><a href="https://github.com/CloudCompare" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/keijiro/Pcx" rel="noopener noreferrer">Pcx <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Point cloud importer/renderer for Unity.</li>
<li><a href="https://github.com/uhlik/bpy" rel="noopener noreferrer">Bpy <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Point cloud importer/renderer/editor for Blender, Point Cloud visualizer.</li>
<li><a href="https://github.com/Hitachi-Automotive-And-Industry-Lab/semantic-segmentation-editor" rel="noopener noreferrer">Semantic Segmentation Editor <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Point cloud and image semantic segmentation editor by Hitachi Automotive And Industry Laboratory, point cloud annotator / labeling.</li>
<li><a href="https://github.com/walzimmer/3d-bat" rel="noopener noreferrer">3D Bounding Box Annotation Tool <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - 3D BAT: A Semi-Automatic, Web-based 3D Annotation Toolbox for Full-Surround, Multi-Modal Data Streams, point cloud annotator / labeling.<ul>
<li><a href="https://arxiv.org/pdf/1905.00525.pdf" rel="noopener noreferrer">Paper <img src="https://img.shields.io/badge/paper-blue?style=flat-square&amp;logo=semanticscholar" alt /></a></li>
<li><a href="https://www.youtube.com/watch?v=gSGG4Lw8BSU" rel="noopener noreferrer">YouTube video <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/SBCV/Blender-Addon-Photogrammetry-Importer" rel="noopener noreferrer">Photogrammetry importer <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> - Blender addon to import reconstruction results of several libraries.</li>
<li><a href="https://foxglove.dev/" rel="noopener noreferrer">Foxglove</a> - Foxglove Studio is an integrated visualization and diagnosis tool for robotics, available in your browser or for download as a desktop app on Linux, Windows, and macOS.<ul>
<li><a href="https://github.com/foxglove/studio" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a> <img src="https://img.shields.io/badge/ROS-2-34aec5?style=flat-square&amp;logo=ros" alt /></li>
<li><a href="https://www.youtube.com/channel/UCrIbrBxb9HBAnlhbx2QycsA" rel="noopener noreferrer">YouTube channel <img src="https://img.shields.io/badge/youtube-red?style=flat-square&amp;logo=youtube" alt /></a></li>
</ul>
</li>
<li><a href="https://www.meshlab.net/" rel="noopener noreferrer">MeshLab</a> - MeshLab is an open source, portable, and extensible system for the processing and editing 3D triangular meshes and pointcloud.<ul>
<li><a href="https://github.com/cnr-isti-vclab/meshlab" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
<li><a href="https://github.com/Geekgineer/CloudPeek" rel="noopener noreferrer">CloudPeek</a> is a lightweight, c++ single-header, cross-platform point cloud viewer, designed for simplicity and efficiency without relying on heavy external libraries like PCL or Open3D.<ul>
<li><a href="https://github.com/Geekgineer/CloudPeek" rel="noopener noreferrer">GitHub repository <img src="https://img.shields.io/badge/github-black?style=flat-square&amp;logo=github" alt /></a></li>
</ul>
</li>
</ul>


    </main>
  </body>
</html>
