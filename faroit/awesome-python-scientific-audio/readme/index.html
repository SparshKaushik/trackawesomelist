<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Awesome Python Scientific Audio (faroit/awesome-python-scientific-audio) Overview - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com/faroit/awesome-python-scientific-audio/readme/" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Awesome Python Scientific Audio Overview" />
    <meta property="og:description" content=" Curated list of python software and packages related to scientific research in audio" />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Awesome Python Scientific Audio Overview</h1>
<p> Curated list of python software and packages related to scientific research in audio</p>
<p><a href="/">ğŸ  Home</a><span> Â· </span><a href="https://www.trackawesomelist.com/faroit/awesome-python-scientific-audio/rss.xml">ğŸ”¥ Feed</a><span> Â· </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">ğŸ“® Subscribe</a><span> Â· </span><a href="https://github.com/sponsors/theowenyoung">â¤ï¸  Sponsor</a><span> Â· </span><a href="https://github.com/faroit/awesome-python-scientific-audio">ğŸ˜º faroit/awesome-python-scientific-audio</a><span> Â· </span><span>â­ 1.6K</span><span> Â· </span><span>ğŸ·ï¸ Programming Languages</span></p>
<p><span>[ </span><a href="/faroit/awesome-python-scientific-audio/">Daily</a><span> / </span><a href="/faroit/awesome-python-scientific-audio/week/">Weekly</a><span> / </span><span>Overview</span><span> ]</span></p>
<h1 id="python-for-scientific-audio"><a class="anchor" aria-hidden="true" tabindex="-1" href="#python-for-scientific-audio"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Python for Scientific Audio</h1><p><a href="https://github.com/sindresorhus/awesome" rel="noopener noreferrer"><img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome" /></a> <a href="https://github.com/faroit/awesome-python-scientific-audio/actions?query=workflow%3ACI+branch%3Amaster+event%3Apush" rel="noopener noreferrer"><img src="https://github.com/faroit/awesome-python-scientific-audio/workflows/CI/badge.svg" alt="Build Status" /></a></p>
<p>The aim of this repository is to create a comprehensive, curated list of python software/tools related and used for scientific research in audio/music applications.</p>
<h2 id="contents"><a class="anchor" aria-hidden="true" tabindex="-1" href="#contents"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contents</h2><ul>
<li><a href="#audio-related-packages">Audio Related Packages</a><ul>
<li><a href="#read-write">Read/Write</a></li>
<li><a href="#transformations---general-dsp">Transformations - General DSP</a></li>
<li><a href="#feature-extraction">Feature extraction</a></li>
<li><a href="#data-augmentation">Data augmentation</a></li>
<li><a href="#speech-processing">Speech Processing</a></li>
<li><a href="#environmenta">Environmental Sounds</a></li>
<li><a href="#perceptial-models---auditory-models">Perceptial Models - Auditory Models</a></li>
<li><a href="#source-separation">Source Separation</a></li>
<li><a href="#music-information-retrieval">Music Information Retrieval</a></li>
<li><a href="#deep-learning">Deep Learning</a></li>
<li><a href="#symbolic-music---midi---musicology">Symbolic Music - MIDI - Musicology</a></li>
<li><a href="#realtime-applications">Realtime applications</a></li>
<li><a href="#web-audio">Web - Audio</a></li>
<li><a href="#audio-related-apis-and-datasets">Audio related APIs and Datasets</a></li>
<li><a href="#wrappers-for-audio-plugins">Wrappers for Audio Plugins</a></li>
</ul>
</li>
<li><a href="#tutorials">Tutorials</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#scientific-papers">Scientific Paper</a></li>
<li><a href="#other-resources">Other Resources</a></li>
<li><a href="#related-lists">Related lists</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<h2 id="audio-related-packages"><a class="anchor" aria-hidden="true" tabindex="-1" href="#audio-related-packages"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Audio Related Packages</h2><ul>
<li>Total number of packages: 66</li>
</ul>
<h4 id="read-write"><a class="anchor" aria-hidden="true" tabindex="-1" href="#read-write"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Read-Write</h4><ul>
<li><a href="https://github.com/danilobellini/audiolazy" rel="noopener noreferrer">audiolazy</a> <a href="https://github.com/danilobellini/audiolazy" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audiolazy/" rel="noopener noreferrer">ğŸ“¦</a> - Expressive Digital Signal Processing (DSP) package for Python.</li>
<li><a href="https://github.com/beetbox/audioread" rel="noopener noreferrer">audioread</a> <a href="https://github.com/beetbox/audioread" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audioread/" rel="noopener noreferrer">ğŸ“¦</a> - Cross-library (GStreamer + Core Audio + MAD + FFmpeg) audio decoding.</li>
<li><a href="https://mutagen.readthedocs.io/" rel="noopener noreferrer">mutagen</a> <a href="https://github.com/quodlibet/mutagen" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mutagen" rel="noopener noreferrer">ğŸ“¦</a> - Reads and writes all kind of audio metadata for various formats.</li>
<li><a href="http://docs.mikeboers.com/pyav/" rel="noopener noreferrer">pyAV</a> <a href="https://github.com/mikeboers/PyAV" rel="noopener noreferrer">:octocat:</a> - PyAV is a Pythonic binding for FFmpeg or Libav.</li>
<li><a href="http://pysoundfile.readthedocs.io/" rel="noopener noreferrer">(Py)Soundfile</a> <a href="https://github.com/bastibe/PySoundFile" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/SoundFile" rel="noopener noreferrer">ğŸ“¦</a> - Library based on libsndfile, CFFI, and NumPy.</li>
<li><a href="https://github.com/rabitt/pysox" rel="noopener noreferrer">pySox</a> <a href="https://github.com/rabitt/pysox" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pysox/" rel="noopener noreferrer">ğŸ“¦</a> - Wrapper for sox.</li>
<li><a href="https://github.com/faroit/stempeg" rel="noopener noreferrer">stempeg</a> <a href="https://github.com/faroit/stempeg" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/stempeg/" rel="noopener noreferrer">ğŸ“¦</a> - read/write of STEMS multistream audio.</li>
<li><a href="https://github.com/devsnd/tinytag" rel="noopener noreferrer">tinytag</a> <a href="https://github.com/devsnd/tinytag" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/tinytag/" rel="noopener noreferrer">ğŸ“¦</a> - reading music meta data of MP3, OGG, FLAC and Wave files.</li>
</ul>
<h4 id="transformations---general-dsp"><a class="anchor" aria-hidden="true" tabindex="-1" href="#transformations---general-dsp"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Transformations - General DSP</h4><ul>
<li><a href="http://python-acoustics.github.io/python-acoustics/" rel="noopener noreferrer">acoustics</a> <a href="https://github.com/python-acoustics/python-acoustics/" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/acoustics" rel="noopener noreferrer">ğŸ“¦</a> - useful tools for acousticians.</li>
<li><a href="https://github.com/mbrucher/AudioTK" rel="noopener noreferrer">AudioTK</a> <a href="https://github.com/mbrucher/AudioTK" rel="noopener noreferrer">:octocat:</a> - DSP filter toolbox (lots of filters).</li>
<li><a href="https://audiotsm.readthedocs.io/" rel="noopener noreferrer">AudioTSM</a> <a href="https://github.com/Muges/audiotsm" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audiotsm/" rel="noopener noreferrer">ğŸ“¦</a> - real-time audio time-scale modification procedures.</li>
<li><a href="https://github.com/detly/gammatone" rel="noopener noreferrer">Gammatone</a> <a href="https://github.com/detly/gammatone" rel="noopener noreferrer">:octocat:</a> - Gammatone filterbank implementation.</li>
<li><a href="http://pyfftw.github.io/pyFFTW/" rel="noopener noreferrer">pyFFTW</a> <a href="https://github.com/pyFFTW/pyFFTW" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pyFFTW/" rel="noopener noreferrer">ğŸ“¦</a> - Wrapper for FFTW(3).</li>
<li><a href="https://grrrr.org/research/software/nsgt/" rel="noopener noreferrer">NSGT</a> <a href="https://github.com/grrrr/nsgt" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/nsgt" rel="noopener noreferrer">ğŸ“¦</a> - Non-stationary gabor transform, constant-q.</li>
<li><a href="https://github.com/sergree/matchering" rel="noopener noreferrer">matchering</a> <a href="https://github.com/sergree/matchering" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/matchering/" rel="noopener noreferrer">ğŸ“¦</a> - Automated reference audio mastering.</li>
<li><a href="https://github.com/nils-werner/mdct" rel="noopener noreferrer">MDCT</a> <a href="https://github.com/nils-werner/mdct" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mdct" rel="noopener noreferrer">ğŸ“¦</a> - MDCT transform.</li>
<li><a href="http://pydub.com" rel="noopener noreferrer">pydub</a> <a href="https://github.com/jiaaro/pydub" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mdct" rel="noopener noreferrer">ğŸ“¦</a> - Manipulate audio with a simple and easy high level interface.</li>
<li><a href="http://tftb.nongnu.org" rel="noopener noreferrer">pytftb</a> <a href="https://github.com/scikit-signal/pytftb" rel="noopener noreferrer">:octocat:</a> - Implementation of the MATLAB Time-Frequency Toolbox.</li>
<li><a href="https://github.com/LCAV/pyroomacoustics" rel="noopener noreferrer">pyroomacoustics</a> <a href="https://github.com/LCAV/pyroomacoustics" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pyroomacoustics" rel="noopener noreferrer">ğŸ“¦</a> - Room Acoustics Simulation (RIR generator)</li>
<li><a href="https://github.com/bmcfee/pyrubberband" rel="noopener noreferrer">PyRubberband</a> <a href="https://github.com/bmcfee/pyrubberband" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pyrubberband/" rel="noopener noreferrer">ğŸ“¦</a> - Wrapper for <a href="http://breakfastquay.com/rubberband/" rel="noopener noreferrer">rubberband</a> to do pitch-shifting and time-stretching.</li>
<li><a href="http://pywavelets.readthedocs.io" rel="noopener noreferrer">PyWavelets</a> <a href="https://github.com/PyWavelets/pywt" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/PyWavelets" rel="noopener noreferrer">ğŸ“¦</a> - Discrete Wavelet Transform in Python.</li>
<li><a href="http://resampy.readthedocs.io" rel="noopener noreferrer">Resampy</a> <a href="https://github.com/bmcfee/resampy" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/resampy" rel="noopener noreferrer">ğŸ“¦</a> - Sample rate conversion.</li>
<li><a href="http://www.sfstoolbox.org" rel="noopener noreferrer">SFS-Python</a> <a href="https://github.com/sfstoolbox/sfs-python" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/sfs/" rel="noopener noreferrer">ğŸ“¦</a> - Sound Field Synthesis Toolbox.</li>
<li><a href="https://appliedacousticschalmers.github.io/sound_field_analysis-py/" rel="noopener noreferrer">sound_field_analysis</a> <a href="https://github.com/AppliedAcousticsChalmers/sound_field_analysis-py" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/sound-field-analysis/" rel="noopener noreferrer">ğŸ“¦</a> - Analyze, visualize and process sound field data recorded by spherical microphone arrays.</li>
<li><a href="http://stft.readthedocs.io" rel="noopener noreferrer">STFT</a> <a href="https://github.com/nils-werner/stft" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/stft" rel="noopener noreferrer">ğŸ“¦</a> - Standalone package for Short-Time Fourier Transform.</li>
</ul>
<h4 id="feature-extraction"><a class="anchor" aria-hidden="true" tabindex="-1" href="#feature-extraction"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Feature extraction</h4><ul>
<li><a href="http://aubio.org/" rel="noopener noreferrer">aubio</a> <a href="https://github.com/aubio/aubio" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/aubio" rel="noopener noreferrer">ğŸ“¦</a> - Feature extractor, written in C, Python interface.</li>
<li><a href="https://github.com/libAudioFlux/audioFlux" rel="noopener noreferrer">audioFlux</a> <a href="https://github.com/libAudioFlux/audioFlux" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audioflux" rel="noopener noreferrer">ğŸ“¦</a> - A library for audio and music analysis, feature extraction.</li>
<li><a href="https://github.com/danilobellini/audiolazy" rel="noopener noreferrer">audiolazy</a> <a href="https://github.com/danilobellini/audiolazy" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audiolazy/" rel="noopener noreferrer">ğŸ“¦</a> - Realtime Audio Processing lib, general purpose.</li>
<li><a href="http://essentia.upf.edu" rel="noopener noreferrer">essentia</a> <a href="https://github.com/MTG/essentia" rel="noopener noreferrer">:octocat:</a> - Music related low level and high level feature extractor, C++ based, includes Python bindings.</li>
<li><a href="https://github.com/jameslyons/python_speech_features" rel="noopener noreferrer">python_speech_features</a> <a href="https://github.com/jameslyons/python_speech_features" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/python_speech_features" rel="noopener noreferrer">ğŸ“¦</a> - Common speech features for ASR.</li>
<li><a href="https://github.com/Yaafe/Yaafe" rel="noopener noreferrer">pyYAAFE</a> <a href="https://github.com/Yaafe/Yaafe" rel="noopener noreferrer">:octocat:</a> - Python bindings for YAAFE feature extractor.</li>
<li><a href="https://github.com/astorfi/speechpy" rel="noopener noreferrer">speechpy</a> <a href="https://github.com/astorfi/speechpy" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/speechpy" rel="noopener noreferrer">ğŸ“¦</a> - Library for Speech Processing and Recognition, mostly feature extraction for now.</li>
<li><a href="https://github.com/SuperKogito/spafe" rel="noopener noreferrer">spafe</a> <a href="https://github.com/SuperKogito/spafe" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/spafe/" rel="noopener noreferrer">ğŸ“¦</a> - Python library for features extraction from audio files.</li>
</ul>
<h4 id="data-augmentation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#data-augmentation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Data augmentation</h4><ul>
<li><a href="https://github.com/iver56/audiomentations" rel="noopener noreferrer">audiomentations</a> <a href="https://github.com/iver56/audiomentations" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/audiomentations/" rel="noopener noreferrer">ğŸ“¦</a> -  Audio Data Augmentation.</li>
<li><a href="https://muda.readthedocs.io/en/latest/" rel="noopener noreferrer">muda</a> <a href="https://github.com/bmcfee/muda" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/muda" rel="noopener noreferrer">ğŸ“¦</a> -  Musical Data Augmentation.</li>
<li><a href="https://github.com/SuperKogito/pydiogment" rel="noopener noreferrer">pydiogment</a> <a href="https://github.com/SuperKogito/pydiogment" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/pydiogment/" rel="noopener noreferrer">ğŸ“¦</a> -  Audio Data Augmentation.</li>
</ul>
<h4 id="speech-processing"><a class="anchor" aria-hidden="true" tabindex="-1" href="#speech-processing"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Speech Processing</h4><ul>
<li><a href="https://www.readbeyond.it/aeneas/" rel="noopener noreferrer">aeneas</a> <a href="https://github.com/readbeyond/aeneas/" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/aeneas/" rel="noopener noreferrer">ğŸ“¦</a> - Forced aligner, based on MFCC+DTW, 35+ languages.</li>
<li><a href="https://github.com/mozilla/DeepSpeech" rel="noopener noreferrer">deepspeech</a> <a href="https://github.com/mozilla/DeepSpeech" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/deepspeech/" rel="noopener noreferrer">ğŸ“¦</a> - Pretrained automatic speech recognition.</li>
<li><a href="https://github.com/lowerquality/gentle" rel="noopener noreferrer">gentle</a> <a href="https://github.com/lowerquality/gentle" rel="noopener noreferrer">:octocat:</a> - Forced-aligner built on Kaldi.</li>
<li><a href="https://github.com/YannickJadoul/Parselmouth" rel="noopener noreferrer">Parselmouth</a> <a href="https://github.com/YannickJadoul/Parselmouth" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/praat-parselmouth/" rel="noopener noreferrer">ğŸ“¦</a> - Python interface to the <a href="http://www.praat.org" rel="noopener noreferrer">Praat</a> phonetics and speech analysis, synthesis, and manipulation software.</li>
<li><a href="https://persephone.readthedocs.io/en/latest/" rel="noopener noreferrer">persephone</a> <a href="https://github.com/persephone-tools/persephone" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/persephone/" rel="noopener noreferrer">ğŸ“¦</a> - Automatic phoneme transcription tool.</li>
<li><a href="https://github.com/pyannote/pyannote-audio" rel="noopener noreferrer">pyannote.audio</a> <a href="https://github.com/pyannote/pyannote-audio" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/pyannote-audio/" rel="noopener noreferrer">ğŸ“¦</a> - Neural building blocks for speaker diarization.</li>
<li><a href="https://github.com/tyiannak/pyAudioAnalysis" rel="noopener noreferrer">pyAudioAnalysis</a>Â² <a href="https://github.com/tyiannak/pyAudioAnalysis" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pyAudioAnalysis/" rel="noopener noreferrer">ğŸ“¦</a> - Feature Extraction, Classification, Diarization.</li>
<li><a href="https://github.com/wiseman/py-webrtcvad" rel="noopener noreferrer">py-webrtcvad</a> <a href="https://github.com/wiseman/py-webrtcvad" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/webrtcvad/" rel="noopener noreferrer">ğŸ“¦</a> -  Interface to the WebRTC Voice Activity Detector.</li>
<li><a href="https://github.com/vBaiCai/python-pesq" rel="noopener noreferrer">pypesq</a> <a href="https://github.com/vBaiCai/python-pesq" rel="noopener noreferrer">:octocat:</a> - Wrapper for the PESQ score calculation.</li>
<li><a href="https://github.com/mpariente/pystoi" rel="noopener noreferrer">pystoi</a> <a href="https://github.com/mpariente/pystoi" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/pystoi" rel="noopener noreferrer">ğŸ“¦</a> - Short Term Objective Intelligibility measure (STOI).</li>
<li><a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder" rel="noopener noreferrer">PyWorldVocoder</a> <a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder" rel="noopener noreferrer">:octocat:</a> - Wrapper for Morise's World Vocoder.</li>
<li><a href="https://montrealcorpustools.github.io/Montreal-Forced-Aligner/" rel="noopener noreferrer">Montreal Forced Aligner</a> <a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner" rel="noopener noreferrer">:octocat:</a> - Forced aligner, based on Kaldi (HMM), English (others can be trained).</li>
<li><a href="http://lium.univ-lemans.fr/sidekit/" rel="noopener noreferrer">SIDEKIT</a> <a href="https://pypi.python.org/pypi/SIDEKIT/" rel="noopener noreferrer">ğŸ“¦</a> - Speaker and Language recognition.</li>
<li><a href="https://github.com/Uberi/speech_recognition" rel="noopener noreferrer">SpeechRecognition</a> <a href="https://github.com/Uberi/speech_recognition" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="noopener noreferrer">ğŸ“¦</a> -  Wrapper for several ASR engines and APIs, online and offline.</li>
</ul>
<h4 id="environmental-sounds"><a class="anchor" aria-hidden="true" tabindex="-1" href="#environmental-sounds"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Environmental Sounds</h4><ul>
<li><a href="http://tut-arg.github.io/sed_eval" rel="noopener noreferrer">sed_eval</a> <a href="https://github.com/TUT-ARG/sed_eval" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/sed_eval/" rel="noopener noreferrer">ğŸ“¦</a> - Evaluation toolbox for Sound Event Detection</li>
</ul>
<h4 id="perceptial-models---auditory-models"><a class="anchor" aria-hidden="true" tabindex="-1" href="#perceptial-models---auditory-models"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Perceptial Models - Auditory Models</h4><ul>
<li><a href="https://github.com/mrkrd/cochlea" rel="noopener noreferrer">cochlea</a> <a href="https://github.com/mrkrd/cochlea" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/cochlea/" rel="noopener noreferrer">ğŸ“¦</a> - Inner ear models.</li>
<li><a href="http://briansimulator.org/" rel="noopener noreferrer">Brian2</a> <a href="https://github.com/brian-team/brian2" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/Brian2" rel="noopener noreferrer">ğŸ“¦</a> - Spiking neural networks simulator, includes cochlea model.</li>
<li><a href="https://github.com/deeuu/loudness" rel="noopener noreferrer">Loudness</a> <a href="https://github.com/deeuu/loudness" rel="noopener noreferrer">:octocat:</a> - Perceived loudness, includes Zwicker, Moore/Glasberg model.</li>
<li><a href="https://www.christiansteinmetz.com/projects-blog/pyloudnorm" rel="noopener noreferrer">pyloudnorm</a> <a href="https://github.com/csteinmetz1/pyloudnorm" rel="noopener noreferrer">:octocat:</a> - Audio loudness meter and normalization, implements ITU-R BS.1770-4.</li>
<li><a href="http://www.sfstoolbox.org" rel="noopener noreferrer">Sound Field Synthesis Toolbox</a> <a href="https://github.com/sfstoolbox/sfs-python" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/sfs/" rel="noopener noreferrer">ğŸ“¦</a> - Sound Field Synthesis Toolbox.</li>
</ul>
<h4 id="source-separation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#source-separation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Source Separation</h4><ul>
<li><a href="https://github.com/aliutkus/commonfate" rel="noopener noreferrer">commonfate</a> <a href="https://github.com/aliutkus/commonfate" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/commonfate" rel="noopener noreferrer">ğŸ“¦</a> - Common Fate Model and Transform.</li>
<li><a href="https://github.com/stitchfix/NTFLib" rel="noopener noreferrer">NTFLib</a> <a href="https://github.com/stitchfix/NTFLib" rel="noopener noreferrer">:octocat:</a> - Sparse Beta-Divergence Tensor Factorization.</li>
<li><a href="https://interactiveaudiolab.github.io/project/nussl.html" rel="noopener noreferrer">NUSSL</a> <a href="https://github.com/interactiveaudiolab/nussl" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/nussl" rel="noopener noreferrer">ğŸ“¦</a> - Holistic source separation framework including DSP methods and deep learning methods.</li>
<li><a href="http://nimfa.biolab.si" rel="noopener noreferrer">NIMFA</a> <a href="https://github.com/marinkaz/nimfa" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/nimfa" rel="noopener noreferrer">ğŸ“¦</a> - Several flavors of non-negative-matrix factorization.</li>
</ul>
<h4 id="music-information-retrieval"><a class="anchor" aria-hidden="true" tabindex="-1" href="#music-information-retrieval"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Music Information Retrieval</h4><ul>
<li><a href="https://github.com/jvbalen/catchy" rel="noopener noreferrer">Catchy</a> <a href="https://github.com/jvbalen/catchy" rel="noopener noreferrer">:octocat:</a> - Corpus Analysis Tools for Computational Hook Discovery.</li>
<li><a href="https://github.com/sevagh/chord-detection" rel="noopener noreferrer">chord-detection</a> <a href="https://github.com/sevagh/chord-detection" rel="noopener noreferrer">:octocat:</a> - Algorithms for chord detection and key estimation.</li>
<li><a href="https://madmom.readthedocs.io/en/latest/" rel="noopener noreferrer">Madmom</a> <a href="https://github.com/CPJKU/madmom" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/madmom" rel="noopener noreferrer">ğŸ“¦</a> - MIR packages with strong focus on beat detection, onset detection and chord recognition.</li>
<li><a href="http://craffel.github.io/mir_eval/" rel="noopener noreferrer">mir_eval</a> <a href="https://github.com/craffel/mir_eval" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mir_eval" rel="noopener noreferrer">ğŸ“¦</a> - Common scores for various MIR tasks. Also includes bss_eval implementation.</li>
<li><a href="http://pythonhosted.org/msaf/" rel="noopener noreferrer">msaf</a> <a href="https://github.com/urinieto/msaf" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/msaf" rel="noopener noreferrer">ğŸ“¦</a> - Music Structure Analysis Framework.</li>
<li><a href="http://librosa.github.io/librosa/" rel="noopener noreferrer">librosa</a> <a href="https://github.com/librosa/librosa" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/librosa" rel="noopener noreferrer">ğŸ“¦</a> - General audio and music analysis.</li>
</ul>
<h4 id="deep-learning"><a class="anchor" aria-hidden="true" tabindex="-1" href="#deep-learning"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deep Learning</h4><ul>
<li><a href="https://github.com/keunwoochoi/kapre" rel="noopener noreferrer">Kapre</a> <a href="https://github.com/keunwoochoi/kapre" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/kapre" rel="noopener noreferrer">ğŸ“¦</a> - Keras Audio Preprocessors</li>
<li><a href="https://github.com/pytorch/audio" rel="noopener noreferrer">TorchAudio</a> <a href="https://github.com/pytorch/audio" rel="noopener noreferrer">:octocat:</a> - PyTorch Audio Loaders</li>
<li><a href="https://github.com/KinWaiCheuk/nnAudio" rel="noopener noreferrer">nnAudio</a> <a href="https://github.com/KinWaiCheuk/nnAudio" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/nnAudio/" rel="noopener noreferrer">ğŸ“¦</a> - Accelerated audio processing using 1D convolution networks in PyTorch.</li>
</ul>
<h4 id="symbolic-music---midi---musicology"><a class="anchor" aria-hidden="true" tabindex="-1" href="#symbolic-music---midi---musicology"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Symbolic Music - MIDI - Musicology</h4><ul>
<li><a href="http://web.mit.edu/music21/" rel="noopener noreferrer">Music21</a> <a href="https://github.com/cuthbertLab/music21" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/music21" rel="noopener noreferrer">ğŸ“¦</a> - Toolkit for Computer-Aided Musicology.</li>
<li><a href="https://mido.readthedocs.io/en/latest/" rel="noopener noreferrer">Mido</a> <a href="https://github.com/olemb/mido" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mido" rel="noopener noreferrer">ğŸ“¦</a> - Realtime MIDI wrapper.</li>
<li><a href="https://github.com/bspaans/python-mingus" rel="noopener noreferrer">mingus</a> <a href="https://github.com/bspaans/python-mingus" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.org/project/mingus" rel="noopener noreferrer">ğŸ“¦</a> - Advanced music theory and notation package with MIDI file and playback support.</li>
<li><a href="http://craffel.github.io/pretty-midi/" rel="noopener noreferrer">Pretty-MIDI</a> <a href="https://github.com/craffel/pretty-midi" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/pretty-midi" rel="noopener noreferrer">ğŸ“¦</a> - Utility functions for handling MIDI data in a nice/intuitive way.</li>
</ul>
<h4 id="realtime-applications"><a class="anchor" aria-hidden="true" tabindex="-1" href="#realtime-applications"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Realtime applications</h4><ul>
<li><a href="https://github.com/nir/jupylet" rel="noopener noreferrer">Jupylet</a> <a href="https://github.com/nir/jupylet" rel="noopener noreferrer">:octocat:</a> - Subtractive, additive, FM, and sample-based sound synthesis.</li>
<li><a href="http://ajaxsoundstudio.com/software/pyo/" rel="noopener noreferrer">PYO</a> <a href="https://github.com/belangeo/pyo" rel="noopener noreferrer">:octocat:</a> - Realtime audio dsp engine.</li>
<li><a href="https://github.com/spatialaudio/python-sounddevice" rel="noopener noreferrer">python-sounddevice</a> <a href="http://python-sounddevice.readthedocs.io" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/sounddevice" rel="noopener noreferrer">ğŸ“¦</a> - PortAudio wrapper providing realtime audio I/O with NumPy.</li>
<li><a href="https://github.com/AppliedAcousticsChalmers/ReTiSAR" rel="noopener noreferrer">ReTiSAR</a> <a href="https://github.com/AppliedAcousticsChalmers/ReTiSAR" rel="noopener noreferrer">:octocat:</a> - Binarual rendering of streamed or IR-based high-order spherical microphone array signals.</li>
</ul>
<h4 id="web-audio"><a class="anchor" aria-hidden="true" tabindex="-1" href="#web-audio"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Web Audio</h4><ul>
<li><a href="https://github.com/Parisson/TimeSide/tree/dev" rel="noopener noreferrer">TimeSide (Beta)</a> <a href="https://github.com/Parisson/TimeSide/tree/dev" rel="noopener noreferrer">:octocat:</a> - high level audio analysis, imaging, transcoding, streaming and labelling.</li>
</ul>
<h4 id="audio-dataset-and-dataloaders"><a class="anchor" aria-hidden="true" tabindex="-1" href="#audio-dataset-and-dataloaders"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Audio Dataset and Dataloaders</h4><ul>
<li><a href="http://beets.io/" rel="noopener noreferrer">beets</a> <a href="https://github.com/beetbox/beets" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/beets" rel="noopener noreferrer">ğŸ“¦</a> - Music library manager and <a href="https://musicbrainz.org/" rel="noopener noreferrer">MusicBrainz</a> tagger.</li>
<li><a href="http://dsdtools.readthedocs.io" rel="noopener noreferrer">musdb</a> <a href="https://github.com/sigsep/sigsep-mus-db" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/musdb" rel="noopener noreferrer">ğŸ“¦</a> - Parse and process the MUSDB18 dataset.</li>
<li><a href="http://medleydb.readthedocs.io" rel="noopener noreferrer">medleydb</a> <a href="https://github.com/marl/medleydb" rel="noopener noreferrer">:octocat:</a> - Parse <a href="http://medleydb.weebly.com/" rel="noopener noreferrer">medleydb</a> audio + annotations.</li>
<li><a href="https://github.com/soundcloud/soundcloud-python" rel="noopener noreferrer">Soundcloud API</a> <a href="https://github.com/soundcloud/soundcloud-python" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/soundcloud" rel="noopener noreferrer">ğŸ“¦</a> - Wrapper for <a href="https://developers.soundcloud.com/" rel="noopener noreferrer">Soundcloud API</a>.</li>
<li><a href="http://rg3.github.io/youtube-dl/" rel="noopener noreferrer">Youtube-Downloader</a> <a href="https://github.com/rg3/youtube-dl" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/youtube_dl" rel="noopener noreferrer">ğŸ“¦</a> - Download youtube videos (and the audio).</li>
<li><a href="https://github.com/ynop/audiomate" rel="noopener noreferrer">audiomate</a> <a href="https://github.com/ynop/audiomate" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/audiomate/" rel="noopener noreferrer">ğŸ“¦</a> - Loading different types of audio datasets.</li>
<li><a href="https://mirdata.readthedocs.io/en/latest/" rel="noopener noreferrer">mirdata</a> <a href="https://github.com/mir-dataset-loaders/mirdata" rel="noopener noreferrer">:octocat:</a> <a href="https://pypi.python.org/pypi/mirdata" rel="noopener noreferrer">ğŸ“¦</a> - Common loaders for Music Information Retrieval (MIR) datasets.</li>
</ul>
<h4 id="wrappers-for-audio-plugins"><a class="anchor" aria-hidden="true" tabindex="-1" href="#wrappers-for-audio-plugins"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Wrappers for Audio Plugins</h4><ul>
<li><a href="https://code.soundsoftware.ac.uk/projects/vampy-host" rel="noopener noreferrer">VamPy Host</a> <a href="https://pypi.python.org/pypi/vamp" rel="noopener noreferrer">ğŸ“¦</a> - Interface compiled vamp plugins.</li>
</ul>
<h2 id="tutorials"><a class="anchor" aria-hidden="true" tabindex="-1" href="#tutorials"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Tutorials</h2><ul>
<li><a href="https://jakevdp.github.io/WhirlwindTourOfPython/" rel="noopener noreferrer">Whirlwind Tour Of Python</a> <a href="https://github.com/jakevdp/WhirlwindTourOfPython" rel="noopener noreferrer">:octocat:</a> - fast-paced introduction to Python essentials, aimed at researchers and developers.</li>
<li><a href="http://www.scipy-lectures.org/index.html" rel="noopener noreferrer">Introduction to Numpy and Scipy</a> <a href="https://github.com/scipy-lectures/scipy-lecture-notes" rel="noopener noreferrer">:octocat:</a> - Highly recommended tutorial, covers large parts of the scientific Python ecosystem.</li>
<li><a href="https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html" rel="noopener noreferrer">Numpy for MATLABÂ® Users</a> - Short overview of equivalent python functions for switchers.</li>
<li><a href="http://musicinformationretrieval.com/" rel="noopener noreferrer">MIR Notebooks</a> <a href="https://github.com/stevetjoa/stanford-mir" rel="noopener noreferrer">:octocat:</a> - collection of instructional iPython Notebooks for music information retrieval (MIR).</li>
<li><a href="https://github.com/spatialaudio/selected-topics-in-audio-signal-processing-exercises" rel="noopener noreferrer">Selected Topics in Audio Signal Processing</a> - Exercises as iPython notebooks.</li>
<li><a href="https://www.youtube.com/watch?v=SSyQ0kRHzis" rel="noopener noreferrer">Live-coding a music synthesizer</a> Live-coding video showing how to use the SoundDevice library to reproduce realistic sounds. <a href="https://github.com/cool-RR/python_synthesizer" rel="noopener noreferrer">Code</a>.</li>
</ul>
<h2 id="books"><a class="anchor" aria-hidden="true" tabindex="-1" href="#books"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Books</h2><ul>
<li><a href="https://github.com/jakevdp/PythonDataScienceHandbook" rel="noopener noreferrer">Python Data Science Handbook</a> - Jake Vanderplas, Excellent Book and accompanying tutorial notebooks.</li>
<li><a href="https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP" rel="noopener noreferrer">Fundamentals of Music Processing</a> - Meinard MÃ¼ller, comes with Python exercises.</li>
</ul>
<h2 id="scientific-papers"><a class="anchor" aria-hidden="true" tabindex="-1" href="#scientific-papers"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Scientific Papers</h2><ul>
<li><a href="http://eprints.maynoothuniversity.ie/4115/1/40.pdf" rel="noopener noreferrer">Python for audio signal processing</a> - John C. Glover, Victor Lazzarini and Joseph Timoney, Linux Audio Conference 2011.</li>
<li><a href="http://conference.scipy.org/proceedings/scipy2015/pdfs/brian_mcfee.pdf" rel="noopener noreferrer">librosa: Audio and Music Signal Analysis in Python</a>, <a href="https://www.youtube.com/watch?v=MhOdbtPhbLU" rel="noopener noreferrer">Video</a> - Brian McFee, Colin Raffel, Dawen Liang, Daniel P.W. Ellis, Matt McVicar, Eric Battenberg, Oriol Nieto, Scipy 2015.</li>
<li><a href="https://arxiv.org/abs/1911.01255" rel="noopener noreferrer">pyannote.audio: neural building blocks for speaker diarization</a>, <a href="https://www.youtube.com/watch?v=37R_R82lfwA" rel="noopener noreferrer">Video</a> - HervÃ© Bredin, Ruiqing Yin, Juan Manuel Coria, Gregory Gelly, Pavel Korshunov, Marvin Lavechin, Diego Fustes, Hadrien Titeux, Wassim Bouaziz, Marie-Philippe Gill, ICASSP 2020.</li>
</ul>
<h2 id="other-resources"><a class="anchor" aria-hidden="true" tabindex="-1" href="#other-resources"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Other Resources</h2><ul>
<li><a href="https://www.coursera.org/learn/audio-signal-processing" rel="noopener noreferrer">Coursera Course</a> -  Audio Signal Processing, Python based course from UPF of Barcelona and Stanford University.</li>
<li><a href="http://dsp-nbsphinx.readthedocs.io/en/nbsphinx-experiment/index.html" rel="noopener noreferrer">Digital Signal Processing Course</a> - Masters Course Material (University of Rostock) with many Python examples.</li>
<li><a href="https://mircommunity.slack.com" rel="noopener noreferrer">Slack Channel</a> - Music Information Retrieval Community.</li>
</ul>
<h2 id="related-lists"><a class="anchor" aria-hidden="true" tabindex="-1" href="#related-lists"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Related lists</h2><p>There is already <a href="https://wiki.python.org/moin/PythonInMusic" rel="noopener noreferrer">PythonInMusic</a> but it is not up to date and includes too many packages of special interest that are mostly not relevant for scientific applications. <a href="https://github.com/vinta/awesome-python" rel="noopener noreferrer">Awesome-Python</a> is large curated list of python packages. However, the audio section is very small.</p>
<h2 id="contributing"><a class="anchor" aria-hidden="true" tabindex="-1" href="#contributing"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contributing</h2><p>Your contributions are always welcome! Please take a look at the <a href="https://github.com/faroit/awesome-python-scientific-audio/blob/master/README.md/CONTRIBUTING.md" rel="noopener noreferrer">contribution guidelines</a> first.</p>
<p>I will keep some pull requests open if I'm not sure whether those libraries are awesome, you could vote for them by adding ğŸ‘ to them.</p>
<h2 id="license"><a class="anchor" aria-hidden="true" tabindex="-1" href="#license"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>License</h2><p><a href="https://creativecommons.org/licenses/by/4.0/" rel="noopener noreferrer"><img src="https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg" alt="License: CC BY 4.0" /></a></p>


    </main>
  </body>
</html>
