<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Track Awesome Ai4lam (AI4LAM/awesome-ai4lam) Updates Weekly - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com/AI4LAM/awesome-ai4lam/week/" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Track Awesome Ai4lam Updates Weekly" />
    <meta property="og:description" content="A list of awesome AI in libraries, archives, and museum collections from around the world 🕶️" />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Track Awesome Ai4lam Updates Weekly</h1>
<p>A list of awesome AI in libraries, archives, and museum collections from around the world 🕶️</p>
<p><a href="/">🏠 Home</a><span> · </span><a href="https://www.trackawesomelist.com/search/">🔍 Search</a><span> · </span><a href="https://www.trackawesomelist.com/AI4LAM/awesome-ai4lam/week/rss.xml">🔥 Feed</a><span> · </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">📮 Subscribe</a><span> · </span><a href="https://github.com/sponsors/theowenyoung">❤️  Sponsor</a><span> · </span><a href="https://github.com/AI4LAM/awesome-ai4lam">😺 AI4LAM/awesome-ai4lam</a><span> · </span><span>⭐ 121</span><span> · </span><span>🏷️ Library systems</span></p>
<p><span>[ </span><a href="/AI4LAM/awesome-ai4lam/">Daily</a><span> / </span><span>Weekly</span><span> / </span><a href="/AI4LAM/awesome-ai4lam/readme/">Overview</a><span> ]</span></p>

<h2><a href="https://www.trackawesomelist.com/2024/25/">Jun 17 - Jun 23, 2024</a></h2><h3><p>Policies and recommendations / Frameworks</p>
</h3>
<ul>
<li><a href="https://blogs.loc.gov/thesignal/2023/11/introducing-the-lc-labs-artificial-intelligence-planning-framework/" rel="noopener noreferrer">LC Labs Artificial Intelligence Planning Framework</a> – US Library of Congress planning framework for responsible exploration and adoption of AI<ul>
<li>French translation: <a href="https://github.com/altomator/Planification-de-projets-IA" rel="noopener noreferrer">Planification de projets IA dans les GLAM (⭐0)</a></li>
</ul>
</li>
</ul>
<h3><p>Conferences and Workshops / Past Conferences and Workshops</p>
</h3>
<ul>
<li><a href="https://www.nfsa.gov.au/fantastic-futures-conference-canberra-2024" rel="noopener noreferrer">Fantastic Futures 2024</a> – Oct. 15–18 at The National Film and Sound Archive of Australia (NFSA) in Canberra, Australia.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/24/">Jun 10 - Jun 16, 2024</a></h2><h3><p>Tools and Frameworks / Document analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://www.coconut-libtool.com" rel="noopener noreferrer">Coconut Libtool</a> – web-based textual analysis tool designed to assist social scientists, librarians, or anyone in data analysis</li>
</ul>
<h3><p>Publications and News Sources / Journals and Magazines</p>
</h3>
<ul>
<li><a href="https://www.dukeupress.edu/critical-ai" rel="noopener noreferrer">Critical AI</a></li>
</ul>
<h3><p>Publications and News Sources / News sources</p>
</h3>
<ul>
<li><a href="https://www.arl.org/category/day-in-review" rel="noopener noreferrer">ARL Day in Review</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/18/">Apr 29 - May 05, 2024</a></h2><h3><p>Tools and Frameworks / Document analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://teklia.com/blog/arkindex-goes-open-source/" rel="noopener noreferrer">Arkindex</a> – open-source platform for managing &amp; processing collections of digitized documents</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/12/">Mar 18 - Mar 24, 2024</a></h2><h3><p>Policies and recommendations / Surveys of policies and recommendations</p>
</h3>
<ul>
<li><a href="https://www.lib.montana.edu/responsible-ai/" rel="noopener noreferrer">Responsible AI in Libraries and Archives</a> - IMLS funded project to produce tools and strategies that support responsible use of AI in the field (2022-2025)</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/11/">Mar 11 - Mar 17, 2024</a></h2><h3><p>Learning Resources / Introductions to AI</p>
</h3>
<ul>
<li><a href="https://www.codecademy.com/catalog/subject/artificial-intelligence" rel="noopener noreferrer">Codecademy AI Courses</a> – many topics; some lessons are free, some are for-fee</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/10/">Mar 04 - Mar 10, 2024</a></h2><h3><p>Tools and Frameworks / Audio and video analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://archive.mpi.nl/tla/elan" rel="noopener noreferrer">ELAN</a> – addS textual annotations to audio and/or video recordings (Max Planck Institute for Psycholinguistics, The Netherlands)</li>
</ul>
<h3><p>Datasets / Datasets available on Hugging Face</p>
</h3>
<ul>
<li><a href="https://huggingface.co/search/full-text?q=handwritten%20text%20recognition&amp;type=dataset" rel="noopener noreferrer">Full-text search for "handwritten text recognition"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/search/full-text?q=optical%20character%20recognition&amp;type=dataset" rel="noopener noreferrer">Full-text search for "optical text recognition"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Asummarization&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "summarization"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Afeature-extraction&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "feature extraction"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Aimage-classification&amp;type=dataset&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "image classification"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Avideo-classification&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "video classification"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Atext-classification&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "text classification"</a></li>
</ul>

<ul>
<li><a href="https://huggingface.co/datasets?task_categories=task_categories%3Aaudio-classification&amp;type=dataset" rel="noopener noreferrer">Datasets tagged "audio classification"</a></li>
</ul>
<h3><p>Datasets / Datasets available elsewhere</p>
</h3>
<ul>
<li><a href="https://zenodo.org/search?q=metadata.subjects.subject%3A%22handwritten%20text%20recognition%22&amp;l=list&amp;p=1&amp;s=10&amp;sort=bestmatch" rel="noopener noreferrer">HTR datasets in Zenodo</a> – subject search in Zenodo</li>
</ul>

<ul>
<li><a href="https://data.nls.uk/" rel="noopener noreferrer">Open data collections from the National Library of Scotland</a></li>
</ul>
<h3><p>Projects, Initiatives, and Case Studies / Select individual projects</p>
</h3>
<ul>
<li><a href="https://huggingface.co/spaces/DIBT/prompt-collective" rel="noopener noreferrer">Argilla prompt-collective</a> – crowdsourcing effort to rank 50,000 prompts, on Hugging Face</li>
</ul>

<ul>
<li><a href="https://huggingface.co/biglam" rel="noopener noreferrer">BigLAM</a> – BigScience Libraries, Archives and Museums on Hugging Face</li>
</ul>

<ul>
<li><a href="https://huggingface.co/NbAiLab" rel="noopener noreferrer">Nasjonalbiblioteket AI Lab</a> – National Library of Norway on Hugging Face</li>
</ul>

<ul>
<li><a href="https://huggingface.co/KBLab" rel="noopener noreferrer">KBLab</a> – National Library of Sweden on Hugging Face</li>
</ul>

<ul>
<li><a href="https://huggingface.co/PleIAs" rel="noopener noreferrer">PleIAs</a> – French organization training LLMs with an open science approach</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/7/">Feb 12 - Feb 18, 2024</a></h2><h3><p>Learning Resources / Other "awesome" lists in AI and ML</p>
</h3>
<ul>
<li><a href="https://github.com/Hannibal046/Awesome-LLM#readme" rel="noopener noreferrer">Awesome LLM (⭐24k)</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/6/">Feb 05 - Feb 11, 2024</a></h2><h3><p>Learning Resources / Introductions to AI</p>
</h3>
<ul>
<li><a href="https://carpentries-incubator.github.io/machine-learning-librarians-archivists/" rel="noopener noreferrer">Introduction to AI for GLAM</a> – by Library Carpentries</li>
</ul>
<h3><p>Learning Resources / Computer vision</p>
</h3>
<ul>
<li><a href="https://docs.google.com/document/d/1FpKfX4hI38ZKG81osa3bXgitEArxK45NKmT6NOyrnJk" rel="noopener noreferrer">Computer Vision for Heritage Collections</a> – French-language 2 hr workshop designed to introduce computer vision applications to cultural heritage professionals</li>
</ul>
<h3><p>Learning Resources / Other "awesome" lists in AI and ML</p>
</h3>
<ul>
<li><a href="https://github.com/ChristosChristofidis/awesome-deep-learning#readme" rel="noopener noreferrer">Awesome Deep Learning (⭐26k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/guillaume-chevalier/awesome-deep-learning-resources#readme" rel="noopener noreferrer">Awesome Deep Learning Resources (⭐1.7k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/kjw0612/awesome-deep-vision#readme" rel="noopener noreferrer">Awesome Deep Vision (⭐11k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/tstanislawek/awesome-document-understanding#readme" rel="noopener noreferrer">Awesome Document Understanding (⭐1.4k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/weiaicunzai/awesome-image-classification#readme" rel="noopener noreferrer">Awesome Image Classification (⭐3k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/josephmisiti/awesome-machine-learning#readme" rel="noopener noreferrer">Awesome Machine Learning (⭐69k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/ujjwalkarn/Machine-Learning-Tutorials#readme" rel="noopener noreferrer">Awesome Machine Learning &amp; Deep Learning Tutorials (⭐16k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/accelerated-text/awesome-nlg#readme" rel="noopener noreferrer">Awesome Natural Language Generation (⭐468)</a></li>
</ul>

<ul>
<li><a href="https://github.com/keon/awesome-nlp#readme" rel="noopener noreferrer">Awesome NLP (⭐17k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/EthicalML/awesome-production-machine-learning#readme" rel="noopener noreferrer">Awesome Production Machine Learning (⭐19k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/SE-ML/awesome-seml#readme" rel="noopener noreferrer">Awesome Software Engineering for Machine Learning (⭐1.3k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/dk-liang/Awesome-Visual-Transformer#readme" rel="noopener noreferrer">Awesome Visual Transformer (⭐3.5k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/altamiracorp/awesome-xai#readme" rel="noopener noreferrer">Awesome XAI (⭐165)</a></li>
</ul>
<h3><p>Conferences and Workshops / Upcoming Conferences and Workshops</p>
</h3>
<ul>
<li><a href="https://bitcuratorconsortium.org/forum" rel="noopener noreferrer">BitCurator Forum</a> – Mar. 19–22 virtual event on digital forensics, digital archives, and related digital analysis workflows</li>
</ul>

<ul>
<li><a href="https://forum2024.diglib.org" rel="noopener noreferrer">Digital Library Federation (DLF) 2024 Forum</a> – Jul. 29–31 at Michigan State U., East Lansing, Michigan, USA.</li>
</ul>

<ul>
<li><a href="https://icdar2024.net" rel="noopener noreferrer">International Conference on Document Analysis and Recognition (ICDAR) 2024</a> – Aug. 30–Sep. 4 in Athens, Greece.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/4/">Jan 22 - Jan 28, 2024</a></h2><h3><p>Learning Resources / Generative AI</p>
</h3>
<ul>
<li><a href="https://www.youtube.com/watch?v=iR2O2GPbB0E" rel="noopener noreferrer">What are large language models (LLMs)?</a> – (YouTube) by Google for Developers</li>
</ul>

<ul>
<li><a href="https://www.coursera.org/learn/generative-ai-for-everyone?irclickid=S5hzeGTIExyPTTOSNn2PRyfHUkHzH8TNw0Bo1c0&amp;irgwc=1" rel="noopener noreferrer">Generative AI for Everyone</a> – free Coursera course by Andrew Ng</li>
</ul>

<ul>
<li><a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/" rel="noopener noreferrer">What Is ChatGPT Doing … and Why Does It Work?</a> – by Stephen Wolfram</li>
</ul>
<h3><p>Publications and News Sources / Journals and Magazines</p>
</h3>
<ul>
<li><a href="https://link.springer.com/journal/146/articles" rel="noopener noreferrer">AI &amp; Society</a></li>
</ul>

<ul>
<li><a href="https://link.springer.com/journal/10502" rel="noopener noreferrer">Archival Science</a></li>
</ul>

<ul>
<li><a href="https://journals.sagepub.com/home/bds" rel="noopener noreferrer">Big Data &amp; Society</a></li>
</ul>

<ul>
<li><a href="https://digitalhumanities.org/dhq/" rel="noopener noreferrer">Digital Humanities Quarterly</a></li>
</ul>

<ul>
<li><a href="https://academic.oup.com/dsh" rel="noopener noreferrer">Digital Scholarship in the Humanities</a></li>
</ul>

<ul>
<li><a href="https://culturalanalytics.org" rel="noopener noreferrer">Journal of Cultural Analytics</a></li>
</ul>

<ul>
<li><a href="https://www.emerald.com/insight/publication/issn/0022-0418" rel="noopener noreferrer">Journal of Documentation</a></li>
</ul>

<ul>
<li><a href="https://openhumanitiesdata.metajnl.com" rel="noopener noreferrer">Journal of Open Humanities Data</a></li>
</ul>

<ul>
<li><a href="https://asistdl.onlinelibrary.wiley.com/journal/23301643" rel="noopener noreferrer">Journal of the Association for Information Science and Technology</a></li>
</ul>

<ul>
<li><a href="https://www.emerald.com/insight/publication/issn/0737-8831" rel="noopener noreferrer">Library Hi Tech</a></li>
</ul>

<ul>
<li><a href="https://dl.acm.org/journal/lilc" rel="noopener noreferrer">Literary and Linguistic Computing</a></li>
</ul>

<ul>
<li><a href="https://journals.sagepub.com/description/SSC" rel="noopener noreferrer">Social Science Computer Review</a></li>
</ul>

<ul>
<li><a href="https://content.iospress.com/journals/world-digital-libraries-an-international-journal" rel="noopener noreferrer">World Digital Libraries – An International Journal</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/3/">Jan 15 - Jan 21, 2024</a></h2><h3><p>Learning Resources / Introductions to AI</p>
</h3>
<ul>
<li><a href="https://www.elementsofai.com/" rel="noopener noreferrer">Elements of AI</a> – free course by MinnaLearn &amp; University of Helsinki</li>
</ul>

<ul>
<li><a href="https://aipedagogy.org" rel="noopener noreferrer">AI Guide by the AI Pedagogy Project</a> – collection of materials by <a href="https://mlml.io/about/" rel="noopener noreferrer">metaLAB</a></li>
</ul>

<ul>
<li><a href="https://docs.google.com/presentation/d/1dVdS3u-XS2RDexNm3RlwICCsh5gBmdi1pBARgIGnPN8" rel="noopener noreferrer">Slides from FF23 workshop on <em>Intro to AI for GLAM</em></a> and <a href="https://pad.carpentries.org/intro-ai-ff2023" rel="noopener noreferrer">shared notes</a></li>
</ul>

<ul>
<li><a href="https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/edit#slide=id.g168a3288f7_0_58" rel="noopener noreferrer">Machine Learning 101</a> – by Jason Mayes from Google</li>
</ul>

<ul>
<li><a href="https://exploreai.jisc.ac.uk/" rel="noopener noreferrer">A Collection of AI Demos to Discover and Explore</a></li>
</ul>
<h3><p>Learning Resources / Computer vision</p>
</h3>
<ul>
<li><a href="https://machinelearningmastery.com/what-is-computer-vision/" rel="noopener noreferrer">A Gentle Introduction to Computer Vision</a> – from Machine Learning Mastery</li>
</ul>

<ul>
<li><a href="https://programminghistorian.org/en/lessons/computer-vision-deep-learning-pt1" rel="noopener noreferrer">Computer Vision for the Humanities: An Introduction to Deep Learning for Image Classification</a> – two-part intro by the Programming Historian</li>
</ul>
<h3><p>Learning Resources / Natural language processing</p>
</h3>
<ul>
<li><a href="https://www.fast.ai/posts/2019-07-08-fastai-nlp.html" rel="noopener noreferrer">A Code-First Introduction to NLP</a> – by Rachel Thomas of fast.ai</li>
</ul>

<ul>
<li><a href="https://lena-voita.github.io/nlp_course.html" rel="noopener noreferrer">NLP course</a> and associated <a href="https://github.com/yandexdataschool/nlp_course#readme" rel="noopener noreferrer">GitHub repo (⭐10k)</a> – by Elena Voita</li>
</ul>

<ul>
<li><a href="https://www.youtube.com/playlist?list=PL8P_Z6C4GcuWfAq8Pt6PBYlck4OprHXsw" rel="noopener noreferrer">NLP accelerated class</a> – by Machine Learning University</li>
</ul>

<ul>
<li><a href="https://nlpoverview.com/index.html" rel="noopener noreferrer">Overview of deep learning techniques applied to NLP (2018)</a></li>
</ul>

<ul>
<li><a href="https://machinelearningmastery.com/category/natural-language-processing/" rel="noopener noreferrer">Deep Learning for NLP</a> – from Machine Learning Mastery</li>
</ul>

<ul>
<li><a href="https://github.com/hb20007/hands-on-nltk-tutorial#readme" rel="noopener noreferrer">Hands-on NLTK Tutorial (⭐558)</a></li>
</ul>

<ul>
<li><a href="https://github.com/NirantK/NLP_Quickbook#readme" rel="noopener noreferrer">NLP in Python - Quickstart Guide (⭐588)</a></li>
</ul>

<ul>
<li><a href="https://pytorch.org/tutorials/beginner/deep_learning_nlp_tutorial.html" rel="noopener noreferrer">Deep Learning for NLP With Pytorch</a></li>
</ul>
<h3><p>Learning Resources / Generative AI</p>
</h3>
<ul>
<li><a href="https://mark-riedl.medium.com/a-very-gentle-introduction-to-large-language-models-without-the-hype-5f67941fa59e" rel="noopener noreferrer">A Very Gentle Introduction to LLMs without the Hype</a> – by Mark Riedl</li>
</ul>

<ul>
<li><a href="https://docs.google.com/presentation/d/1X3VpadTOsUe2neFts24pURy3nNQ2k64k4d3MEqHlEgk/edit#slide=id.g25b6aed46c6_0_492" rel="noopener noreferrer">A brief introduction to GenAI</a> – by U. Michigan MIDAS</li>
</ul>

<ul>
<li><a href="https://sebastianraschka.com/blog/2023/llm-reading-list.html" rel="noopener noreferrer">Understanding LLMs – A Transformative Reading List</a></li>
</ul>

<ul>
<li><a href="https://github.com/mlabonne/llm-course#readme" rel="noopener noreferrer">Large Language Model Course (⭐57k)</a></li>
</ul>
<h3><p>Learning Resources / Other "awesome" lists in AI and ML</p>
</h3>
<ul>
<li><a href="https://github.com/jbhuang0604/awesome-computer-vision#readme" rel="noopener noreferrer">Awesome Computer Vision (⭐22k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/brianspiering/awesome-dl4nlp#readme" rel="noopener noreferrer">Awesome Deep Learning for Natural Language Processing (NLP) (⭐1.3k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/steven2358/awesome-generative-ai#readme" rel="noopener noreferrer">Awesome Generative AI (⭐8.8k)</a></li>
</ul>

<ul>
<li><a href="https://github.com/LibraryCarpentry/awesome-jupyter-glam#readme" rel="noopener noreferrer">Awesome Jupyter GLAM (⭐19)</a></li>
</ul>

<ul>
<li><a href="https://index.quantumstat.com" rel="noopener noreferrer">The NLP Index</a></li>
</ul>
<h3><p>Tools and Frameworks / Document analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://teklia.com/blog/open-sourcing-callico/" rel="noopener noreferrer">Callico</a> – open-source web platform for document annotation</li>
</ul>

<ul>
<li><a href="https://github.com/CLARIAH/DANE#readme" rel="noopener noreferrer">Distributed Annotation 'n' Enrichment (DANE) (⭐4)</a> – compute task assignment &amp; file storage for automatic annotation of content (<a href="https://www.clariah.nl/about-clariah" rel="noopener noreferrer">CLARIAH</a>, Norway)</li>
</ul>

<ul>
<li><a href="https://huggingface.co/spaces/Riksarkivet/htr_demo" rel="noopener noreferrer">HTRFLOW demo</a> and associated <a href="https://github.com/Swedish-National-Archives-AI-lab/htrflow_app" rel="noopener noreferrer">GitHub repo (⭐33)</a> – explore AI models for Handwritten Text Recogntion (Swedish National Archives)</li>
</ul>

<ul>
<li><a href="https://labelstud.io" rel="noopener noreferrer">Label Studio</a> – data labeling platform to fine-tune LLMs, prepare training data, or validate AI models</li>
</ul>

<ul>
<li><a href="https://bnl.public.lu/en.html" rel="noopener noreferrer">OCR correction</a> – OCR correction tools (Bibliothèque nationale, Luxembourg)</li>
</ul>

<ul>
<li><a href="https://github.com/VikParuchuri/surya#readme" rel="noopener noreferrer">Surya (⭐18k)</a> – multilingual document OCR toolkit with line-level text detection</li>
</ul>

<ul>
<li><a href="https://huggingface.co/KBLab" rel="noopener noreferrer">Text models from the National Library of Sweden</a> – available on Hugging Face</li>
</ul>

<ul>
<li><a href="https://readcoop.eu/transkribus/" rel="noopener noreferrer">Transkribus</a> – transcription, recognition, &amp; searching of historical documents</li>
</ul>
<h3><p>Tools and Frameworks / Audio and video analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://huggingface.co/KBLab" rel="noopener noreferrer">Acoustic models from the National Library of Sweden</a> – available on Hugging Face</li>
</ul>

<ul>
<li><a href="https://uisapp2.iu.edu/confluence-prd/display/AMP/AMP%3A+Audiovisual+Metadata+Platform" rel="noopener noreferrer">Audiovisual Metadata Platform (AMP)</a> – generation of metadata for discovery &amp; use of digital audio &amp; video collections (Indiana U., USA)</li>
</ul>

<ul>
<li><a href="https://kilthub.cmu.edu/articles/preprint/CAMPI_Computer-Aided_Metadata_Generation_for_Photo_archives_Initiative/12791807" rel="noopener noreferrer">CAMPI</a> – Computer-Aided Metadata Generation for Photo archives Initiative (Carnegie Mellonw U., USA)</li>
</ul>

<ul>
<li><a href="https://github.com/ina-foss/inaFaceAnalyzer#readme" rel="noopener noreferrer">inaFaceAnalyzer (⭐23)</a> – Python toolbox for face-based description of gender representation in media (Institut National de l'Audiovisuel, France)</li>
</ul>

<ul>
<li><a href="https://labs.loc.gov/work/experiments/newspaper-navigator/" rel="noopener noreferrer">Newspaper Navigator</a> – explore visual &amp; textual content in the <em>Chronicling America</em> digitized newspaper collection (Library of Congress, USA)</li>
</ul>

<ul>
<li><a href="https://medium.com/headai-customer-stories/customer-story-oodi-1d1ef2554bb6" rel="noopener noreferrer">Oodi</a> – virtual information assistant (Helsinki Central Library)</li>
</ul>

<ul>
<li><a href="https://retv-project.eu" rel="noopener noreferrer">ReTV</a> – video analysis &amp; summarization (Modul Univesrity, Austria)</li>
</ul>
<h3><p>Tools and Frameworks / Indexing and classification</p>
</h3>
<ul>
<li><a href="https://annif.org" rel="noopener noreferrer">Annif</a> and <a href="https://github.com/NatLibFi/Annif-tutorial" rel="noopener noreferrer">associated tutorial (⭐42)</a> – tool for automated subject indexing and classification (National Library of Finland)</li>
</ul>
<h3><p>Tools and Frameworks / Search and retrieval</p>
</h3>
<ul>
<li><a href="https://gallicapix.bnf.fr/rest?run=findIllustrations-form.xq" rel="noopener noreferrer">GallicaPix</a> – retrieval of heritage images (Bibliothèque nationale de France)</li>
</ul>

<ul>
<li><a href="https://www.bnf.fr/sites/default/files/2022-05/Poster_Gallica_Snoop.pdf" rel="noopener noreferrer">GallicaSNOOP</a> – framework for large-scale content-based image retrieval (Bibliothèque nationale de France)</li>
</ul>

<ul>
<li><a href="https://www.nb.no/maken/" rel="noopener noreferrer">Maken Similarity Service</a> – tools for alternative reading &amp; finding similar photographs (National Library of Norway)</li>
</ul>

<ul>
<li><a href="https://beta.nasjonalmuseet.no/2023/08/add-semantic-search-to-a-online-collection/" rel="noopener noreferrer">Semantic search for Nasjonalmuseet’s online collection</a> – open beta test (National Museum of Norway)</li>
</ul>

<ul>
<li><a href="https://www.robots.ox.ac.uk/~vgg/software/vts/" rel="noopener noreferrer">VGG Text Search (VTS) Engine</a> – search for text strings over a user-defined image set</li>
</ul>
<h3><p>Tools and Frameworks / Applications of Transformers, LLMs, and GPT</p>
</h3>
<ul>
<li><a href="https://maartengr.github.io/BERTopic/index.html" rel="noopener noreferrer">BERTopic</a> – topic modeling technique that leverages Transformers and c-TF-IDF</li>
</ul>

<ul>
<li><a href="https://chat.eluxemburgensia.lu/login?next=/" rel="noopener noreferrer">Chatbot for Luxembourgish newspapers</a> – uses ChatGPT and understands French, German and English (Bibliothèque nationale de Luxembourg)</li>
</ul>

<ul>
<li><a href="https://github.com/NBAiLab/notram#readme" rel="noopener noreferrer">Norwegian Transformer Model (NoTraM) (⭐116)</a> – transformer model for Norwegian and Nordic languages (National Library of Norway)</li>
</ul>

<ul>
<li><a href="https://github.com/Kungbib/swedish-bert-models#readme" rel="noopener noreferrer">Swedish BERT (⭐140)</a> – BERT model for the Swedish language (Royal Library of Sweden)</li>
</ul>

<ul>
<li><a href="https://www.robots.ox.ac.uk/~vgg/projects/visualai/index.html" rel="noopener noreferrer">Visual AI</a> – open-world interpretable visual transformer (UK)</li>
</ul>
<h3><p>Datasets / Datasets available elsewhere</p>
</h3>
<ul>
<li><a href="https://github.com/piskvorky/gensim-data#readme" rel="noopener noreferrer">Gensim datasets (⭐1k)</a> – repository of datasets for unstructured text processing</li>
</ul>

<ul>
<li><a href="https://htr-united.github.io" rel="noopener noreferrer">HTR-United</a> – datasets for training transcription or segmentation models</li>
</ul>

<ul>
<li><a href="https://www.kaggle.com/datasets" rel="noopener noreferrer">Kaggle datasets</a></li>
</ul>

<ul>
<li><a href="https://github.com/niderhoff/nlp-datasets#readme" rel="noopener noreferrer">nlp-datasets (⭐5.9k)</a> – free/public domain datasets with text data for use in NLP</li>
</ul>

<ul>
<li><a href="https://openlibrary.org/developers/dumps" rel="noopener noreferrer">Open Library data dumps</a> – from the Internet Archive</li>
</ul>

<ul>
<li><a href="https://registry.opendata.aws" rel="noopener noreferrer">Registry of Open Data on AWS</a> – datasets tagged by topic</li>
</ul>
<h3><p>Projects, Initiatives, and Case Studies / Project lists &amp; directories</p>
</h3>
<ul>
<li><a href="https://docs.google.com/spreadsheets/d/1A7IVnucQZ0ICxYSOCjqQ1oV3xGgNzDKtIYGrk6smV7w/edit#gid=0" rel="noopener noreferrer">List of Artificial Intelligence (AI) initiatives in museums</a> – compiled in 2021 by Elena Villaespesa, Oonagh Murphy and Kate Nadel for the <a href="https://themuseumsai.network" rel="noopener noreferrer">Museums+AI Network</a> project.</li>
</ul>

<ul>
<li><a href="https://libraries.ou.edu/content/project-highlight-projects-ai-registry-pair" rel="noopener noreferrer">Projects in AI Registry (PAIR)</a> – registry of AI projects in higher education (U. Oklahoma Libraries, USA)</li>
</ul>
<h3><p>Projects, Initiatives, and Case Studies / Select individual projects</p>
</h3>
<ul>
<li><a href="https://livingwithmachines.ac.uk" rel="noopener noreferrer">Living with Machines</a> – Turing Institute &amp; British Library</li>
</ul>

<ul>
<li><a href="https://blog.archiveshub.jisc.ac.uk/2022/02/28/machine-learning-with-archive-collections/" rel="noopener noreferrer">Machine Learning with Archive Collections</a></li>
</ul>

<ul>
<li><a href="https://www.youtube.com/watch?v=8khPUtwaVaw" rel="noopener noreferrer">Vatican Manuscripts</a> – machine transcription in the Vatican Secret Archive</li>
</ul>
<h3><p>Policies and recommendations / Statements by organizations and government bodies</p>
</h3>
<ul>
<li><a href="https://dl.acm.org/doi/pdf/10.1145/3626110" rel="noopener noreferrer">ACM TechBrief on Generative AI, by the ACM Technology Policy Council</a></li>
</ul>

<ul>
<li><a href="https://www.priv.gc.ca/en/privacy-topics/technology/artificial-intelligence/gd_principles_ai/" rel="noopener noreferrer">Canadian Government <em>Principles for responsible, trustworthy and privacy-protective generative AI technologies</em></a></li>
</ul>
<h3><p>Policies and recommendations / Surveys of policies and recommendations</p>
</h3>
<ul>
<li><a href="https://www.brookings.edu/articles/a-cluster-analysis-of-national-ai-strategies/" rel="noopener noreferrer">A cluster analysis of national AI strategies</a> – Brookings Institute analysis of different countries’ national AI strategies, Dec. 2023</li>
</ul>

<ul>
<li><a href="https://link.springer.com/article/10.1007/s43681-022-00205-0" rel="noopener noreferrer">A principled governance for emerging AI regimes: lessons from China, the European Union, and the United States</a> by R. B. L. Dixon in <em>AI and Ethics</em>, 3, 793–810, 2023</li>
</ul>

<ul>
<li><a href="https://www.weforum.org/publications/ai-governance-alliance-briefing-paper-series/" rel="noopener noreferrer">AI Governance Alliance: Briefing Paper Series</a> – by the World Economic Forum, Jan. 2024</li>
</ul>

<ul>
<li><a href="https://doi.org/10.1177/0340035223119617" rel="noopener noreferrer">AI policies across the globe: Implications and recommendations for libraries</a> by L. S. Lo in <em>IFLA Journal</em>, 49(4), 645–649, 2023</li>
</ul>

<ul>
<li><a href="http://dx.doi.org/10.2139/ssrn.3518482" rel="noopener noreferrer">Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-Based Approaches to Principles for AI</a> by Fjeld et al, Berkman Klein Center Research Publication No. 2020-1, 2020</li>
</ul>

<ul>
<li><a href="https://www.muchaduabout.com/post/what-ethics-do-i-need-to-consider-when-using-ai" rel="noopener noreferrer">What ethics do I need to consider when using AI?</a> – blog posting by Livi Adu, Nov. 2023</li>
</ul>
<h3><p>Conferences and Workshops / Upcoming Conferences and Workshops</p>
</h3>
<ul>
<li><a href="https://ipres2024.pubpub.org" rel="noopener noreferrer">International Conference on Digital Preservation (iPRES) 2024</a> – Sep. 16–20 in Ghent &amp; Flanders, Belgium.</li>
</ul>
<h3><p>Publications and News Sources / Journals and Magazines</p>
</h3>
<ul>
<li><a href="https://onlinelibrary.wiley.com/loi/23719621" rel="noopener noreferrer">AI Magazine</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2024/2/">Jan 08 - Jan 14, 2024</a></h2><h3><p>Tools and Frameworks / Audio and video analysis, transcription, and labeling</p>
</h3>
<ul>
<li><a href="https://annotorious.github.io" rel="noopener noreferrer">Annotorious</a> – JavaScript image annotation library</li>
</ul>

<ul>
<li><a href="https://www.robots.ox.ac.uk/~vgg/software/via/" rel="noopener noreferrer">VGG Image Annotator</a> – manual annotation software for image, audio and video</li>
</ul>
<h3><p>Projects, Initiatives, and Case Studies / Project lists &amp; directories</p>
</h3>
<ul>
<li><a href="https://www.archives.gov/data/ai-inventory" rel="noopener noreferrer">Inventory of NARA Artificial Intelligence (AI) Use Cases</a> - the US National Archives and Records Administration (NARA)'s inventory of AI use cases</li>
</ul>
<h3><p>Publications and News Sources / Journals and Magazines</p>
</h3>
<ul>
<li><a href="https://link.springer.com/journal/799" rel="noopener noreferrer">International Journal on Digital Libraries</a></li>
</ul>

<ul>
<li><a href="https://www.sciencedirect.com/journal/the-journal-of-academic-librarianship/special-issue/10WVZWS842J" rel="noopener noreferrer">Journal of Academic Librarianship</a></li>
</ul>

<ul>
<li><a href="https://journals.sagepub.com/home/LIS" rel="noopener noreferrer">Journal of Librarianship and Information Science</a></li>
</ul>

<ul>
<li><a href="https://dl.acm.org/journal/jocch" rel="noopener noreferrer">Journal on Computing and Cultural Heritage</a></li>
</ul>

<ul>
<li><a href="https://journals.ala.org/index.php/lrts" rel="noopener noreferrer">Library Resources &amp; Technical Services</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2023/51/">Dec 18 - Dec 24, 2023</a></h2><h3><p>Learning Resources / Generative AI</p>
</h3>
<ul>
<li><a href="https://towardsdatascience.com/the-map-of-transformers-e14952226398" rel="noopener noreferrer">The Map Of Transformers</a></li>
</ul>

<ul>
<li><a href="https://jalammar.github.io/illustrated-transformer/" rel="noopener noreferrer">The Illustrated Transformer</a>, a visual introduction to transformers</li>
</ul>

<ul>
<li><a href="https://www.cloudskillsboost.google/paths/118" rel="noopener noreferrer">Introduction to Generative AI</a>, by Google</li>
</ul>

<ul>
<li><a href="https://microsoft.github.io/generative-ai-for-beginners/#/" rel="noopener noreferrer">Generative AI for Beginners - A Course</a>, by Microsoft</li>
</ul>

<ul>
<li><a href="https://nationalcentreforai.jiscinvolve.org/wp/2023/10/16/generative-ai-primer/" rel="noopener noreferrer">A Generative AI Primer</a>, by the UK's National Centre for AI</li>
</ul>
<h3><p>Learning Resources / AI in galleries, libraries, archives and museums</p>
</h3>
<ul>
<li>The <a href="https://www.cenl.org/networkgroups/ai-in-libraries-network-group/" rel="noopener noreferrer">CENL "AI in Libraries" network group</a> is also organizing webinars on AI implementation in GLAM.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2023/50/">Dec 11 - Dec 17, 2023</a></h2><h3><p>Learning Resources / Introductions to AI</p>
</h3>
<ul>
<li><a href="https://www.deeplearning.ai/short-courses/" rel="noopener noreferrer">DeepLearning.AI Short Courses</a>, a free courses from a platform created by Andrew Ng</li>
</ul>

<ul>
<li><a href="https://www.codecademy.com/learn/intro-to-hugging-face" rel="noopener noreferrer">Introduction to Hugging Face</a>, a free course by Codecademy</li>
</ul>
<h3><p>Learning Resources / AI in galleries, libraries, archives and museums</p>
</h3>
<ul>
<li>The <a href="https://www.youtube.com/@ai4lam120/videos" rel="noopener noreferrer">AI4LAM YouTube channel</a> has introductory presentations on many topics</li>
</ul>
<h3><p>Policies and recommendations / Frameworks</p>
</h3>
<ul>
<li><a href="https://computing.mit.edu/wp-content/uploads/2023/11/AIPolicyBrief.pdf" rel="noopener noreferrer">A Framework for U.S. AI Governance: Creating a Safe and Thriving AI Sector</a> white paper by the MIT Schwarzman College of Computing, Dec. 11, 2023. (See also <a href="https://news.mit.edu/2023/mit-group-releases-white-papers-governance-ai-1211" rel="noopener noreferrer">related article in MIT News</a>.)</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2023/49/">Dec 04 - Dec 10, 2023</a></h2><h3><p>Learning Resources / Introductions to AI</p>
</h3>
<ul>
<li><a href="https://sebastianraschka.com/blog/2021/dl-course.html" rel="noopener noreferrer">Introduction to Deep Learning</a>, by Sebastian Raschka</li>
</ul>

<ul>
<li><a href="https://d2l.ai/index.html" rel="noopener noreferrer">Dive into Deep Learning</a>, by Zhang et al.</li>
</ul>
<h3><p>Policies and recommendations / Statements by organizations and government bodies</p>
</h3>
<ul>
<li><a href="https://repository.ifla.org/bitstream/123456789/1646/1/ifla_statement_on_libraries_and_artificial_intelligence-full-text.pdf" rel="noopener noreferrer">IFLA Statement on Libraries and Artificial Intelligence</a></li>
</ul>

<ul>
<li><a href="https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/" rel="noopener noreferrer">US Government <em>Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence</em></a></li>
</ul>
<h3><p>Policies and recommendations / Frameworks</p>
</h3>
<ul>
<li><a href="https://educationaltechnologyjournal.springeropen.com/articles/10.1186/s41239-023-00408-3" rel="noopener noreferrer">A Comprehensive AI Policy Education Framework for University Teaching and Learning</a> by C. K. Y. Chan in <em>International Journal of Educational Technology in Higher Education</em>, 20(38), 2023.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/2023/48/">Nov 27 - Dec 03, 2023</a></h2><h3><p>Conferences and Workshops / Upcoming Conferences and Workshops</p>
</h3>
<ul>
<li><a href="https://netpreserve.org/ga2024/" rel="noopener noreferrer">IIPC General Assembly &amp; Web Archiving Conference</a> – Apr. 24–26 at the Bibliothèque nationale de France, Paris, France.</li>
</ul>

<ul>
<li><a href="https://www.nfsa.gov.au/fantastic-futures-canberra-2024-artificial-intelligence-libraries-archives-and-museums" rel="noopener noreferrer">Fantastic Futures 2024</a> – Oct. 16–18 at the National Film and Sound Archive of Australia (NFSA), Canberra, Australia.</li>
</ul>
<h3><p>Conferences and Workshops / Past Conferences and Workshops</p>
</h3>
<ul>
<li><a href="https://www.ai4libraries.org" rel="noopener noreferrer">ai4Libraries Conference</a> – Oct. 19 virtual event hosted by Georgia Tech Library, Atlanta, Georgia, USA.</li>
</ul>

<ul>
<li><a href="https://www.nb.no/hva-skjer/ai-conference/" rel="noopener noreferrer">Fantastic Futures 2018</a> – Dec. 5 at the National Library of Norway, Oslo, Norway.</li>
</ul>

<ul>
<li><a href="https://wayback.stanford.edu/was/20230508165810/http://library.stanford.edu/projects/fantastic-futures" rel="noopener noreferrer">Fantastic Futures 2019</a> – Dec. 4–6 at Stanford University, Stanford, California, USA.</li>
</ul>

<ul>
<li><a href="https://www.bnf.fr/fr/captations-et-supports-de-la-conference-2021" rel="noopener noreferrer">Fantastic Futures 2021</a> – Dec. 8–10 at the Bibliothèque nationale de France, Paris, France.</li>
</ul>

<ul>
<li><a href="https://sites.google.com/view/ai4lam/ai4lam-2022-virtual-event" rel="noopener noreferrer">Fantastic Futures 2022</a> – Nov. 30–Dec. 2 virtual event hosted by the British Library, London, England.</li>
</ul>

<ul>
<li><a href="https://ff2023.archive.org" rel="noopener noreferrer">Fantastic Futures 2023</a> – Nov. 15–17 at Internet Archive Canada Headquarters, Vancouver, British Columbia, Canada.</li>
</ul>

    </main>
  </body>
</html>
