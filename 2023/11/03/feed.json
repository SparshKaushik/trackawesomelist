{
  "version": "https://jsonfeed.org/version/1",
  "icon": "https://www.trackawesomelist.com/icon.png",
  "favicon": "https://www.trackawesomelist.com/favicon.ico",
  "language": "en",
  "title": "Awesome List Updates on Nov 03, 2023",
  "_site_title": "Track Awesome List",
  "description": "10 awesome lists updated today.",
  "_seo_title": "Awesome List Updates on Nov 03, 2023 - Track Awesome List",
  "feed_url": "https://www.trackawesomelist.com/feed.json",
  "home_page_url": "https://www.trackawesomelist.com",
  "items": [
    {
      "id": "https://www.trackawesomelist.com/enaqx/awesome-pentest/",
      "title": "Awesome Pentest",
      "_slug": "enaqx/awesome-pentest/",
      "_filepath": "/content/enaqx/awesome-pentest/README.md",
      "url": "https://www.trackawesomelist.com/enaqx/awesome-pentest/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Collaboration Tools / Malware Analysis Books\n\n*   [Hexway Hive](https://hexway.io/hive/) - Commercial collaboration, data aggregation, and reporting framework for red teams with a limited free self-hostable option.\n*   [Reconmap](https://reconmap.com/) - Open-source collaboration platform for InfoSec professionals that streamlines the pentest process.",
      "content_html": "<h3><p>Collaboration Tools / Malware Analysis Books</p>\n</h3><ul>\n<li><a href=\"https://hexway.io/hive/\" rel=\"noopener noreferrer\">Hexway Hive</a> - Commercial collaboration, data aggregation, and reporting framework for red teams with a limited free self-hostable option.</li>\n</ul>\n<ul>\n<li><a href=\"https://reconmap.com/\" rel=\"noopener noreferrer\">Reconmap</a> - Open-source collaboration platform for InfoSec professionals that streamlines the pentest process.</li>\n</ul>\n",
      "date_published": "2023-11-03T23:45:37.000Z",
      "date_modified": "2023-11-03T23:46:29.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/unixorn/awesome-zsh-plugins/",
      "title": "Awesome Zsh Plugins",
      "_slug": "unixorn/awesome-zsh-plugins/",
      "_filepath": "/content/unixorn/awesome-zsh-plugins/README.md",
      "url": "https://www.trackawesomelist.com/unixorn/awesome-zsh-plugins/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Themes / [superconsole](https://github.com/alexchmykhalo/superconsole) - Windows-only\n\n*   [magpie (‚≠ê0)](https://github.com/wdjcodes/magpie) - Minimalist theme with custom logic to display paths relative to the root of the current `git`. Includes decorators for time, current directory, username\\@hostname and `git` status.\n*   [princess (‚≠ê3)](https://github.com/mellypop/princess) - Modeled after [abhiyan.zsh (‚≠ê7)](https://github.com/abhiyandhakal/abhiyan.zsh) with perhaps a bit too much pink and arguably too few emojis. Includes decorators for current directory and `git` status.",
      "content_html": "<h3><p>Themes / <a href=\"https://github.com/alexchmykhalo/superconsole\" rel=\"noopener noreferrer\">superconsole</a> - Windows-only</p>\n</h3><ul>\n<li><a href=\"https://github.com/wdjcodes/magpie\" rel=\"noopener noreferrer\">magpie (‚≠ê0)</a> - Minimalist theme with custom logic to display paths relative to the root of the current <code>git</code>. Includes decorators for time, current directory, username@hostname and <code>git</code> status.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/mellypop/princess\" rel=\"noopener noreferrer\">princess (‚≠ê3)</a> - Modeled after <a href=\"https://github.com/abhiyandhakal/abhiyan.zsh\" rel=\"noopener noreferrer\">abhiyan.zsh (‚≠ê7)</a> with perhaps a bit too much pink and arguably too few emojis. Includes decorators for current directory and <code>git</code> status.</li>\n</ul>\n",
      "date_published": "2023-11-03T23:30:41.000Z",
      "date_modified": "2023-11-03T23:35:36.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/wsvincent/awesome-django/",
      "title": "Awesome Django",
      "_slug": "wsvincent/awesome-django/",
      "_filepath": "/content/wsvincent/awesome-django/README.md",
      "url": "https://www.trackawesomelist.com/wsvincent/awesome-django/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Python Packages / Views\n\n*   [python-socketio (‚≠ê4.2k)](https://github.com/miguelgrinberg/python-socketio) - Python implementation of the Socket.IO\\_ realtime client and server. [(create Socket.io Django server instance)](https://python-socketio.readthedocs.io/en/latest/server.html?highlight=django#creating-a-server-instance)",
      "content_html": "<h3><p>Python Packages / Views</p>\n</h3><ul>\n<li><a href=\"https://github.com/miguelgrinberg/python-socketio\" rel=\"noopener noreferrer\">python-socketio (‚≠ê4.2k)</a> - Python implementation of the Socket.IO_ realtime client and server. <a href=\"https://python-socketio.readthedocs.io/en/latest/server.html?highlight=django#creating-a-server-instance\" rel=\"noopener noreferrer\">(create Socket.io Django server instance)</a></li>\n</ul>\n",
      "date_published": "2023-11-03T19:51:35.000Z",
      "date_modified": "2023-11-03T19:51:35.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/awesome-foss/awesome-sysadmin/",
      "title": "Awesome Sysadmin",
      "_slug": "awesome-foss/awesome-sysadmin/",
      "_filepath": "/content/awesome-foss/awesome-sysadmin/README.md",
      "url": "https://www.trackawesomelist.com/awesome-foss/awesome-sysadmin/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Software / Control Panels\n\n*   [HestiaCP](https://hestiacp.com/) - Web server control panel (fork of VestaCP). ([Demo](https://demo.hestiacp.com:8083/login/), [Source Code (‚≠ê3.9k)](https://github.com/hestiacp/hestiacp)) `GPL-3.0` `PHP/Shell/Other`",
      "content_html": "<h3><p>Software / Control Panels</p>\n</h3><ul>\n<li><a href=\"https://hestiacp.com/\" rel=\"noopener noreferrer\">HestiaCP</a> - Web server control panel (fork of VestaCP). (<a href=\"https://demo.hestiacp.com:8083/login/\" rel=\"noopener noreferrer\">Demo</a>, <a href=\"https://github.com/hestiacp/hestiacp\" rel=\"noopener noreferrer\">Source Code (‚≠ê3.9k)</a>) <code>GPL-3.0</code> <code>PHP/Shell/Other</code></li>\n</ul>\n",
      "date_published": "2023-11-03T16:06:25.000Z",
      "date_modified": "2023-11-03T16:06:25.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/rothgar/awesome-tmux/",
      "title": "Awesome Tmux",
      "_slug": "rothgar/awesome-tmux/",
      "_filepath": "/content/rothgar/awesome-tmux/README.md",
      "url": "https://www.trackawesomelist.com/rothgar/awesome-tmux/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Plugins\n\n*   [tmux-timetrap (‚≠ê2)](https://github.com/croxarens/tmux-timetrap) Keep your time tracked directly with TMUX (The plugin is just a wrapper for [timetrap (‚≠ê1.5k)](https://github.com/samg/timetrap))",
      "content_html": "<h3><p>Plugins</p>\n</h3><ul>\n<li><a href=\"https://github.com/croxarens/tmux-timetrap\" rel=\"noopener noreferrer\">tmux-timetrap (‚≠ê2)</a> Keep your time tracked directly with TMUX (The plugin is just a wrapper for <a href=\"https://github.com/samg/timetrap\" rel=\"noopener noreferrer\">timetrap (‚≠ê1.5k)</a>)</li>\n</ul>\n",
      "date_published": "2023-11-03T15:50:25.000Z",
      "date_modified": "2023-11-03T15:50:25.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/filipecalegario/awesome-generative-deep-art/",
      "title": "Awesome Generative Deep Art",
      "_slug": "filipecalegario/awesome-generative-deep-art/",
      "_filepath": "/content/filipecalegario/awesome-generative-deep-art/README.md",
      "url": "https://www.trackawesomelist.com/filipecalegario/awesome-generative-deep-art/",
      "summary": "21 awesome projects updated",
      "content_text": "\n\n### Human-AI Interaction\n\n*   \\[üî•üî•üî•] [\\[2310.07127\\] An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions](https://arxiv.org/abs/2310.07127): \"a survey of 154 papers, providing a novel taxonomy and analysis of Human-GenAI Interactions from both human and Gen-AI perspectives\".\n*   [Guidelines for Human-AI Interaction - Microsoft Research](https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/): a set of \"18 generally applicable design guidelines for human-AI\" interaction\n\n### Generative AI history, timelines, maps, and definitions\n\n*   [\\[2309.07930\\] Generative AI](https://arxiv.org/abs/2309.07930): discusses a model-, system-, and application-level view on generative AI.\n\n### Ethics, Philosophical questions and Discussions about Generative AI\n\n*   [New Training Method Helps AI Generalize like People Do - Scientific American](https://www.scientificamerican.com/article/new-training-method-helps-ai-generalize-like-people-do/)\n*   [\\[2310.01405\\] Representation Engineering: A Top-Down Approach to AI Transparency](https://arxiv.org/abs/2310.01405): \"an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience\"\n*   [Generative AI Resources for Berkeley Law Faculty & Staff - Berkeley Law](https://www.law.berkeley.edu/library/legal-research/chatgpt/)\n*   [Licensing is neither feasible nor effective for addressing AI risks](https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor)\n*   [Generative AI companies must publish transparency reports](https://www.aisnakeoil.com/p/generative-ai-companies-must-publish)\n*   [Does ChatGPT have a liberal bias?](https://www.aisnakeoil.com/p/does-chatgpt-have-a-liberal-bias)\n*   [More human than human: measuring ChatGPT political bias | Public Choice](https://link.springer.com/article/10.1007/s11127-023-01097-2)\n*   [The Age of AI has begun | Bill Gates](https://www.gatesnotes.com/The-Age-of-AI-Has-Begun)\n\n### Critical Views about Generative AI\n\n*   [AI in Education Group Meeting Notes - Google Docs](https://docs.google.com/document/d/1PPHwa3KmoeRZwaoxjOS568aF2E-kUngOA2oI45G2Iaw/edit)\n*   [Syllabi Policies for AI Generative Tools - Google Docs](https://docs.google.com/document/d/1RMVwzjc1o0Mi8Blw_-JUTcXv02b2WRH86vw7mi16W3U/edit#heading=h.1cykjn2vg2wx)\n*   [Five takeaways from UK‚Äôs AI safety summit at Bletchley Park | Artificial intelligence (AI) | The Guardian](https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak)\n*   [Frontier AI: capabilities and risks ‚Äì discussion paper - GOV.UK](https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper)\n*   [AI Safety Summit Policy Updates | AISS 2023](https://www.aisafetysummit.gov.uk/policy-updates/#company-policies)\n\n### Courses and Educational Materials\n\n*   [Animated AI](https://animatedai.github.io/): animations and instructional videos about neural networks\n*   [Deep Learning AI - Learn the fundamentals of generative AI for real-world applications](https://www.deeplearning.ai/courses/generative-ai-with-llms/): created in partnership with AWS, this course presents the fundamentals of how generative AI works and how to deploy it in real-world applications.\n*   [Google Cloud Skills Boost - Introduction to Generative AI](https://www.cloudskillsboost.google/course_templates/536): an introductory level microlearning course covering Google Tools aimed at explaining what Generative AI is, how it is used, and how it differs from traditional machine learning methods.\n*   [Google Cloud Skills Boost: Generative AI learning path](https://www.cloudskillsboost.google/journeys/118): curated content on Generative AI \"from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud\"\n*   [AI for Industrial Design](https://industrialdesign.ai/): \"students at the National University of Singapore explore AI‚Äôs capability for design in a semester course and share what they learned. Directed by Donn Koh at the Division of Industrial Design, NUS.\"\n*   \\[üî•üî•üî•] [DAIR.AI](https://github.com/dair-ai): Democratizing Artificial Intelligence Research, Education, and Technologies\n*   [Welcome to the ü§ó Deep Reinforcement Learning Course](https://huggingface.co/deep-rl-course/unit0/introduction?fw=pt): a Hugging Face Course on Deep Reinforcement Learning\n*   [Crash course in AI art generation by PromptHero](https://prompthero.com/academy): paid ($99) course focused on prompt engineering\n*   [Visual intuition for diffusion models and AI art. #stablediffusionart #aiart #aiartwork #aiartcommunity](https://www.tiktok.com/@ham_made_art/video/7154863972729113899)\n*   [The Illustrated Stable Diffusion by Jay Alammar](https://jalammar.github.io/illustrated-stable-diffusion/): \"gentle introduction \\[on] how Stable Diffusion works\"\n*   \\[üî•][johnowhitaker/tglcourse (‚≠ê145)](https://github.com/johnowhitaker/tglcourse): The Generative Landscape - a course on generative modelling (currently unfinished)\n*   [Words are Images | BustBright - Machine Learning Art](https://www.bustbright.com/product/words-are-images-7-week-online-class-starting-october-24th-2022-/331): 7-week Online class starting October 24th, 2022 by [Derrick Schultz](https://twitter.com/dvsch/)\n*   [Grokking Stable Diffusion.ipynb - Colaboratory - Part 1](https://colab.research.google.com/drive/1dlgggNa5Mz8sEAGU0wFCHhGLFooW_pf1?usp=sharing): notebook by [@johnowhitaker](https://twitter.com/johnowhitaker) exploring Stable Diffusion details\n*   [Grokking Stable Diffusion: Textual Inversion.ipynb - Colaboratory - Part 2](https://colab.research.google.com/drive/1RTHDzE-otzmZOuy8w1WEOxmn9pNcEz3u?usp=sharing): sequel to Grokking Stable Diffusion by [@johnowhitaker](https://twitter.com/johnowhitaker) that focus on Text Inversion\n*   [GitHub - johnowhitaker/aiaiart (‚≠ê570)](https://github.com/johnowhitaker/aiaiart): Course content and resources for the AIAIART course\n*   [Implementation/tutorial of stable diffusion with side-by-side notes by labml.ai | Twitter](https://twitter.com/labmlai/status/1571080112459878401)\n*   [Practical Deep Learning for Coders 2023 - Part II](https://www.youtube.com/watch?v=_7rMfsA24Ls\\&list=PLfYUBJiXbdtRUvTUYpLdfHHp9a58nWVXP): continuation of the course focusing on the implementation of Stable Diffusion from scratch.\n*   [Practical Deep Learning for Coders 2022 - Part I](https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU): \"free course designed for people with some coding experience who want to learn how to apply deep learning and machine learning to practical problems\" by Jeremy Howard\n\n### Prompt Engineering\n\n*   \\[üî•üî•üî•] [ChatGPT Prompt Engineering for Developers - DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): short course taught by Isa Fulford (OpenAI) and Andrew Ng (DeepLearning.AI) that provide best practices for prompt engineering\n*   \\[üî•üî•üî•] [Learn Prompting](https://learnprompting.org/): series of lessons of prompt engineering\n*   \\[üî•üî•üî•] [Prompt Engineering | Lil'Log](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/): prompt engineering learning notes by Lilian Weng\n*   \\[üî•üî•üî•] [Prompt Engineering Guide](https://www.promptingguide.ai/): a project by DAIR.AI that intends to educate researchers and practitioners about prompt engineering\n*   [the Book](https://fedhoneypot.notion.site/25fdbdb69e9e44c6877d79e18336fe05?v=1d2bf4143680451986fd2836a04afbf4): collection of prompts and hints of prompt engineering\n*   [dair-ai/Prompt-Engineering-Guide (‚≠ê59k)](https://github.com/dair-ai/Prompt-Engineering-Guide): Guide and resources for prompt engineering\n\n### Papers Collection\n\n*   [dair-ai/ML-Papers-Explained (‚≠ê8k)](https://github.com/dair-ai/ML-Papers-Explained): Explanation to key concepts in ML\n*   [AI Reading List - Google Docs](https://docs.google.com/document/d/1bEQM1W-1fzSVWNbS4ne5PopB2b7j8zD4Jc3nm4rbK-U/edit): reading list organized by [Jack Soslow (@JackSoslow)](https://twitter.com/JackSoslow)\n*   [Aman's AI Journal ‚Ä¢ Papers List](https://aman.ai/papers/): set of seminal AI/ML papers curated by Aman Chadha\n*   [Casual GAN Papers Reading Club](https://casualgan.notion.site/casualgan/Casual-GAN-Papers-Reading-Club-327c158518e44d5296a5def74486c7e8): Community knowledge base for Casual GAN Papers\n*   [Casual GAN Papers](https://www.casualganpapers.com/): Easy to read summaries of popular AI papers\n*   [The Illustrated VQGAN](https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/): illustrated explanation on how VQGAN works\n*   [CLIP: Connecting Text and Images](https://openai.com/blog/clip/): OpenAI's explanation on how CLIP works\n*   [VQGAN+CLIP ‚Äî How does it work?. The synthetic imagery (‚ÄúGAN Art‚Äù) scene‚Ä¶ | by Alexa Steinbr√ºck | Medium](https://alexasteinbruck.medium.com/vqgan-clip-how-does-it-work-210a5dca5e52)\n*   [The Methods Corpus | Papers With Code](https://paperswithcode.com/methods)\n*   <https://ieeexplore.ieee.org/abstract/document/9043519>: A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks\n*   [Utilizando redes advers√°rias generativas (GANs) como agente de apoio √† inspira√ß√£o para artistas](https://www.cin.ufpe.br/~tg/2020-1/TG_CC/tg_cco2.pdf): Trabalho de Gradua√ß√£o de Cl√°udio Carvalho no Centro de Inform√°tica - UFPE\n*   [GAN Lab](https://poloclub.github.io/ganlab/): Play with Generative Adversarial Networks in Your Browser!\n*   [\\[PDF\\] Music2Video: Automatic Generation of Music Video with fusion of audio and text | Semantic Scholar](https://www.semanticscholar.org/paper/Music2Video%3A-Automatic-Generation-of-Music-Video-of-Jang-Shin/38e37c3a7dc22bb3356552e93e6685b99ca04264)\n*   [\\[PDF\\] Active Divergence with Generative Deep Learning - A Survey and Taxonomy | Semantic Scholar](https://www.semanticscholar.org/paper/Active-Divergence-with-Generative-Deep-Learning-A-Broad-Berns/091c4ea2efaba23cd9024d8a063609c9a313b5cb)\n*   [\\[PDF\\] Automating Generative Deep Learning for Artistic Purposes: Challenges and Opportunities | Semantic Scholar](https://www.semanticscholar.org/paper/Automating-Generative-Deep-Learning-for-Artistic-Berns-Broad/f3479740d4ec7f91b6d7a01167e9c875a72d386e)\n\n### Online Tools and Applications\n\n*   [Tailor](https://www.usetailor.com): Get a daily podcast and newsletter, created for you by an AI\n*   [Paint by Text](https://paintbytext.chat/): Edit your photos using written instructions, with the help of an AI.\n*   [Scenario AI](https://www.scenario.gg/): AI-generated game assets\n*   [AnimalAI](https://animalai.co/): custom AI-generated animal portraits (profits are directed to various wildlife conservation organizations)\n*   [starryai](https://www.starryai.com/): AI Art Generator App - AI Art Maker\n*   [ProsePainter](https://www.prosepainter.com/): an interactive tool to \"paint with words.\" It incorporates guidable text-to-image generation into a traditional digital painting interface\n*   [ProsePainter: Image + Sketching Interface + CLIP! - YouTube](https://www.youtube.com/watch?v=mK4F32xNrdw\\&t=429s)\n*   [Cocreator AI](https://cocreator.ai/): creative computer agent (in wait list)\n*   [Runway ML](http://runwayml.com/): AI video creation suite\n*   [Hotpot.ai - Hotpot.ai](https://hotpot.ai/): set of AI Tools to post-process images\n*   [Toonify yourself by Justin Pinkney](https://www.justinpinkney.com/toonify-yourself/): turn a human face into a cartoon\n*   [deepart.io](https://deepart.io/): a online tool for applying style transfer\n*   [Artbreeder](https://www.artbreeder.com/): web-based tool to generate images by breeding existing images\n*   [Ostagram.ru](https://www.ostagram.me/): image style transfer plataform\n*   [cleanup.pictures](https://cleanup.pictures/): remove objects, people, text and defects from any picture for free\n*   [remove.bg](https://www.remove.bg/): remove background from images\n*   [Quick, Draw!](https://quickdraw.withgoogle.com/): can a neural network learn to recognize doodling? A game to help NL by adding users drawing\n*   [Nekton.ai](https://nekton.ai/): automate your workflows with AI\n\n### Large Language Models (LLMs)\n\n*   [cpacker/MemGPT (‚≠ê17k)](https://github.com/cpacker/MemGPT): teaching LLMs memory management for unbounded context [\\[demo page\\]](https://memgpt.ai/) [\\[arxiv\\]](https://arxiv.org/abs/2310.08560)\n*   [\\[2307.10169\\] Challenges and Applications of Large Language Models](https://arxiv.org/abs/2307.10169): a systematic set of open problems and application successes of LLM area\n*   [Related resources from around the web | OpenAI Cookbook](https://cookbook.openai.com/articles/related_resources): tools and papers for improving outputs from GPT\n\n### Prompt Engineering / Prompt Engineering for Text-to-text\n\n*   \\[üî•] [\\[2307.11760\\] Large Language Models Understand and Can be Enhanced by Emotional Stimuli](https://arxiv.org/abs/2307.11760)\n*   \\[üî•] [\\[2305.13252\\] \"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data](https://arxiv.org/abs/2305.13252)\n*   [timqian/openprompt.co (‚≠ê1.2k)](https://github.com/timqian/openprompt.co): Create. Use. Share. ChatGPT prompts\n*   [60 ChatGPT Prompts for Data Science (Tried, Tested, and Rated)](https://medium.datadriveninvestor.com/60-chatgpt-prompts-for-data-science-tried-tested-and-rated-4994c7e6adb2): post by Travis Tang from DataDrivenInvestor\n*   [f/awesome-chatgpt-prompts (‚≠ê130k)](https://github.com/f/awesome-chatgpt-prompts): this repo includes ChatGPT prompt curation to use ChatGPT better\n*   [brexhq/prompt-engineering (‚≠ê9.2k)](https://github.com/brexhq/prompt-engineering): \"Tips and tricks for working with Large Language Models like OpenAI's GPT-4\"\n*   [How to write an effective GPT-3 prompt | Zapier](https://zapier.com/blog/gpt-3-prompt/): a list of 6 GPT-3 tips for getting the desired output\n*   [The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts](https://fka.gumroad.com/l/art-of-chatgpt-prompting): e-book by Fatih Kadir Akƒ±n ([@fkadev](http://twitter.com/fkadev))\n\n### Autonomous LLM Agents / Multi-agents\n\n*   [\\[2307.05300\\] Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration](https://arxiv.org/abs/2307.05300)\n*   [OpenBMB/ChatDev (‚≠ê27k)](https://github.com/OpenBMB/ChatDev): create customized software using natural language idea (through llm-powered multi-agent collaboration)\n*   [\\[2308.07201\\] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate](https://arxiv.org/abs/2308.07201)\n*   [\\[2308.10848\\] AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors](https://arxiv.org/abs/2308.10848)\n\n### Prompt Engineering / Prompt Engineering for Text-to-image\n\n*   [USP AI Prompt Book](https://app.usp.ai/static/Stable%20Diffusion%202.1%20Prompt%20Book%20by%20USP.ai.pdf): Stable Diffusion v2.1 Prompt Book\n*   [daspartho/prompt-extend (‚≠ê176)](https://github.com/daspartho/prompt-extend): extending stable diffusion prompts with suitable style cues using text generation\n*   [Prompt Box](https://www.promptbox.ai/): \"organize and save your AI prompts\"\n*   [Midjourney artist reference - Google Sheets](https://docs.google.com/spreadsheets/d/1e2MZ1K6WMTUuxlPAQ_2A0rz-H55NBykb66TY7DuerVg/edit#gid=2088669480)\n*   [Stable Diffusion Prompt Book ‚Äî Stability.Ai](https://stability.ai/sdv2-prompt-book): prompt book for Stable Diffusion v2.0 and v2.1 released by Stability.AI\n*   [The Ultimate Stable Diffusion Prompt Guide by PromptHero](https://prompthero.com/stable-diffusion-prompt-guide)\n*   [CLIP Interrogator - a Hugging Face Space by pharma](https://huggingface.co/spaces/pharma/CLIP-Interrogator): image-to-text tool to figure out what a good prompt might be to create new images like an existing one\n*   \\[üî•üî•üî•] [Prompt book for data lovers II - Google Slides](https://docs.google.com/presentation/d/1V8d6TIlKqB1j5xPFH7cCmgKOV_fMs4Cb4dwgjD5GIsg/edit#slide=id.g1834b964b0f_3_4): An open source exploration on text-to-image and data visualization\n*   [some9000/StylePile (‚≠ê580)](https://github.com/some9000/StylePile): A helper script for AUTOMATIC1111/stable-diffusion-webui. Basically a mix and match to quickly get different results without wasting a lot of time writing prompts.\n*   [Artists To Study | All images generated with Google Colab TPUs + CompVis/stable-diffusion-v1-4 + Huggingface Diffusers](https://artiststostudy.pages.dev/): a systematic study of artists' styles made by [@camenduru](https://twitter.com/camenduru)\n*   [PromptDesign | Reddit](https://www.reddit.com/r/PromptDesign/): Reddit community for \"the art of communicating with natural language models\"\n*   [Prompt Engineering and Zero-Shot/Few-Shot Learning \\[Guide\\] - inovex GmbH](https://www.inovex.de/de/blog/prompt-engineering-guide/): prompt engineering for text generation\n*   [clip-interrogator.ipynb - Colaboratory](https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb#scrollTo=rbDEMDGJrJEo): a tool for image-to-prompt\n*   [Useful Prompt Engineering tools and resources | Reddit](https://www.reddit.com/r/StableDiffusion/comments/xcrm4d/useful_prompt_engineering_tools_and_resources/)\n*   [PromptHero](https://prompthero.com/): Search the best prompts for Stable Diffusion, DALL-E and Midjourney\n*   [promptoMANIA](https://promptomania.com/): AI art community with prompt generator\n*   [Lexica](https://lexica.art/): search over 10M+ Stable Diffusion images and prompts\n*   [list of artists for SD v1.4 A-C / D-I / J-N / O-Z](https://rentry.org/artists_sd-v1-4)\n*   [succinctly/text2image-prompt-generator ¬∑ Hugging Face](https://huggingface.co/succinctly/text2image-prompt-generator): a GPT-2 model fine-tuned on the succinctly/midjourney-prompts dataset, which contains 250k text prompts that users issued to the Midjourney text-to-image service over a month period\n*   [The Prompter | vicc | Substack](https://theprompter.substack.com/): a newsletter about news, tips and thoughts around prompt engineering\n*   [(19) Nikhil Agrawal üìå on Twitter](https://twitter.com/HeyNikhila/status/1570005481896255490): 11 AI Images Prompt websites to level up the image quality\n*   [Phraser](https://phraser.tech/): a tool that support prompt creation\n*   [PromptBase | Prompt Marketplace](https://promptbase.com/): PromptBase is a marketplace for DALL¬∑E, Midjourney & GPT-3 prompts, where people can sell prompts and make money from their prompt crafting skills.\n*   [Professional AI whisperers have launched a marketplace for DALL-E prompts - The Verge](https://www.theverge.com/2022/9/2/23326868/dalle-midjourney-ai-promptbase-prompt-market-sales-artist-interview)\n*   [Visual Prompt Builder](https://tools.saxifrage.xyz/prompt): simple deck of illustrated card to combine modifiers for prompt building\n*   [Prompt Engineering Template - Google Sheets](https://docs.google.com/spreadsheets/d/1-snKDn38-KypoYCk9XLPg799bHcNFSBAVu2HVvFEAkA/edit#gid=0): spreadsheet with lists of modifiers for prompt building and a lot of interesting links for reference\n*   [Prompt Engineering: From Words to Art - Saxifrage Blog](https://www.saxifrage.xyz/post/prompt-engineering)\n*   [DALL¬∑Ery GALL¬∑Ery Resources](https://dallery.gallery/prompt-resources-tools-ai-art/): DALL¬∑E 2 and AI art prompt resources & tools to inspire beautiful images\n*   [\\[2204.13988\\] A Taxonomy of Prompt Modifiers for Text-To-Image Generation](https://arxiv.org/abs/2204.13988)\n*   [List of Aesthetics | Aesthetics Wiki | Fandom](https://aesthetics.fandom.com/wiki/List_of_Aesthetics)\n*   [Artist Directory (Volcano Comparison) | AI Art Creation Wiki | Fandom](https://aiartcreation.fandom.com/wiki/Artist_Directory_\\(Volcano_Comparison\\))\n*   [The DALL¬∑E 2 Prompt Book ‚Äì DALL¬∑Ery GALL¬∑Ery](https://dallery.gallery/the-dalle-2-prompt-book/)\n*   [DALL¬∑Ery GALL¬∑Ery](https://dallery.gallery/): A guide to OpenAI's DALL¬∑E ‚Äì prompts, projects, examples, and tips\n*   [(2) MASSIVE üí• DALL-E 2 ANIME ‚ö°Ô∏é KEYWORDS + MODIFIERS LIST ‚òÖ : haaaaven](https://www.reddit.com/user/haaaaven/comments/w05f56/massive_dalle_2_anime_keywords_modifiers_list/): image prompt modifier collection by haaaaven\n*   [DrawBench](https://docs.google.com/spreadsheets/d/1y7nAbmR4FREi6npB1u-Bo3GFdwdOPYJc617rBOxIRHY/edit#gid=0): a list of prompts the Google Imagen is organizing as a benchmark\n*   [CLIP Prompt Engineering for Generative Art - matthewmcateer.me](https://matthewmcateer.me/blog/clip-prompt-engineering/): list of styles tested with Quick CLIP Guided Diffusion\n*   [Adobe should make a boring app for prompt engineers (Interconnected)](https://interconnected.org/home/2022/06/02/dalle)\n*   [\\[2206.00169\\] Discovering the Hidden Vocabulary of DALLE-2](https://arxiv.org/abs/2206.00169)\n*   [When SD just doesn't understand the prompt no matter how hard I try | Reddit](https://www.reddit.com/r/StableDiffusion/comments/xgwcab/when_sd_just_doesnt_understand_the_prompt_no/)\n*   [It's very interesting how some prompts have very defined output but other specific ones are not | Reddit](https://www.reddit.com/r/StableDiffusion/comments/xgplii/its_very_interesting_how_some_prompts_have_very/)\n\n### Multimodal Embedding Space / Deforum\n\n*   [CLIP retrieval for laion5B](https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn5.laion.ai\\&index=laion5B\\&useMclip=false): CLIP retrieval using Laion5B. \"It works by converting the text query to a CLIP embedding , then using that embedding to query a knn index of clip image embedddings\".\n*   [rom1504/clip-retrieval (‚≠ê2.6k)](https://github.com/rom1504/clip-retrieval): Easily compute CLIP embeddings and build a CLIP retrieval system with them\n*   [Segment Anything | Meta AI](https://segment-anything.com/): \"a new AI model from Meta AI that can \"cut out\" any object, in any image, with a single click\"\n*   [Microsoft KOSMOS-2](https://twitter.com/mervenoyann/status/1720126908384366649): new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world [\\[HF demo\\]](https://huggingface.co/spaces/ydshieh/Kosmos-2) [\\[arxiv\\]](https://arxiv.org/abs/2306.14824)\n*   [facebookresearch/ImageBind (‚≠ê8.7k)](https://github.com/facebookresearch/ImageBind): ImageBind One Embedding Space to Bind Them All\n*   [RedPajama-Data-v2 by Together AI](https://together.ai/blog/redpajama-data-v2): an open dataset with 30 trillion tokens for training Large Language Models\n*   [Have I Been Trained?](https://haveibeentrained.com/): tool for searching 5.8 billion images used to train popular AI art models\n*   [laion-aesthetic-6pls](https://laion-aesthetic.datasette.io/laion-aesthetic-6pls/images): exploring 12 million of the 2.3 billion images used to train Stable Diffusion's image generator\n*   [LAION](https://laion.ai/): Large-scale Artificial Intelligence Open Network\n\n### Retrieval-Augmented Generation (RAG) / Prompt Engineering for Text-to-image\n\n*   [Rerankers and Two-Stage Retrieval | Pinecone](https://www.pinecone.io/learn/series/rag/rerankers/)\n*   [Retrieval Augmented Generation | Pinecone](https://www.pinecone.io/learn/series/rag/)\n*   [dssjon/biblos: biblos.app (‚≠ê212)](https://github.com/dssjon/biblos): example of RAG architecture using semantic search and summarization for retrieving Bible passages\n\n### Embeddings and Semantic Search / Prompt Engineering for Text-to-image\n\n*   [neuml/txtai (‚≠ê11k)](https://github.com/neuml/txtai): semantic search and workflows powered by language models\n*   [facebookresearch/faiss (‚≠ê36k)](https://github.com/facebookresearch/faiss): A library for efficient similarity search and clustering of dense vectors\n*   [Optimize Your Chatbot‚Äôs Conversational Intelligence Using GPT-3 | by Amogh Agastya | Better Programming](https://betterprogramming.pub/how-to-give-your-chatbot-the-power-of-neural-search-with-openai-ebcff5194170): tutorial presenting semantic search concepts\n*   [What is Semantic Search?](https://txt.cohere.ai/what-is-semantic-search/)\n*   [Learning Center | Pinecone](https://www.pinecone.io/learn/): Pinecone's guides to vector embeddings\n*   [BLIP+CLIP | CLIP Interrogator | Kaggle](https://www.kaggle.com/code/leonidkulyk/lb-0-45836-blip-clip-clip-interrogator): a Kaggle notebook for image description and captioning (imate-to-text)\n*   [jerryjliu/gpt\\_index: GPT Index (LlamaIndex) (‚≠ê43k)](https://github.com/jerryjliu/gpt_index): a project to make it easier to use large external knowledge bases with LLMs\n*   [Llama Hub](https://llamahub.ai/): a repository of data loaders for LlamaIndex (GPT Index) and LangChain\n*   [Chroma](https://www.trychroma.com/): an open-source AI-native database that makes it easy to use embeddings\n\n### Autonomous LLM Agents / Prompt Engineering for Text-to-image\n\n*   [joonspk-research/generative\\_agents - Generative Agents (‚≠ê19k)](https://github.com/joonspk-research/generative_agents): code for interactive simulacra of human behavior [\\[arxiv\\]](https://arxiv.org/abs/2304.03442)\n\n### LLM Evaluation / Multi-agents\n\n*   [LLM Evaluation at Scale ‚Äì Airtrain](https://www.airtrain.ai/): no-code batch compute platform for LLM evaluation and tuning workloads\n*   [How to evaluate a summarization task | OpenAI Cookbook](https://cookbook.openai.com/examples/evaluation/how_to_eval_abstractive_summarization)\n*   [openai/evals (‚≠ê17k)](https://github.com/openai/evals): Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.\n*   [Red teaming and model evaluations | Anthropic](https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/red-teaming-and-model-evaluations)\n*   [Challenges in evaluating AI systems | Anthropic](https://www.anthropic.com/index/evaluating-ai-systems)\n*   [Evaluating LLMs is a minefield](https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/): talk by Princeton professor Arvind Narayanan\n\n### AI Engineering / Multi-agents\n\n*   [Marvin](https://www.askmarvin.ai/): AI engineering framework for building natural language interfaces\n*   [Instructor](https://jxnl.github.io/instructor/): library for structured LLM extraction in Python\n\n### Image Segmentation / Deforum\n\n*   [Transforming 2D Images into 3D with the AdaMPI AI Model](https://notes.aimodels.fyi/transforming-2d-images-into-3d-with-the-adampi-ai-model/): guide on how to use the AdaMPI AI model for creating 3D photos from 2D images\n*   [Ssemble](https://www.ssemble.com/): collaborative video editor with a collection of AI plugins\n*   [Nathan Lands on Twitter: \"AI video has started to produce mindblowing results and could eventually disrupt Hollywood / Twitter](https://twitter.com/NathanLands/status/1659195191591596033): Twitter thread with examples of Generative AI tools for video\n*   [Stable Animation SDK](https://stability.ai/blog/stable-animation-sdk): a text-to-animation tool for developers by Stability AI [\\[dev platform\\]](https://platform.stability.ai/docs/features/animation)\n*   [Twelve Labs](https://twelvelabs.io/): multimodal, contextual understanding for video search\n*   [Align your Latents](https://research.nvidia.com/labs/toronto-ai/VideoLDM/): high-resolution video synthesis with latent diffusion models [\\[arxiv\\]](https://arxiv.org/abs/2304.08818)\n*   [Gen-2 by Runway](https://research.runwayml.com/gen2): \"a multi-modal AI system that can generate novel videos with text, images, or video clips\" [\\[arxiv\\]](https://arxiv.org/abs/2302.03011)\n*   [CiaraRowles/TemporalNet ¬∑ Hugging Face](https://huggingface.co/CiaraRowles/TemporalNet): a ControlNet model designed to enhance the temporal consistency of generated outputs [\\[tweet\\]](https://twitter.com/ciararowles1/status/1639321818581303310)\n*   [Video-P2P UI - a Hugging Face Space by video-p2p-library](https://huggingface.co/spaces/video-p2p-library/Video-P2P-Demo): video editing with cross-attention control [\\[tweet\\]](https://twitter.com/_akhaliq/status/1637838648463749120)\n*   [Text2Video-Zero - a Hugging Face Space by PAIR](https://huggingface.co/spaces/PAIR/Text2Video-Zero): zero-shot text-to-video synthesis diffusion framework [\\[tweet\\]](https://twitter.com/_akhaliq/status/1639062868850266112) [\\[arxiv\\]](https://arxiv.org/abs/2303.13439)\n*   [ModelScope - a Hugging Face Space by damo-vilab](https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis): text-to-video synthesis [\\[page\\]](https://www.modelscope.cn/models/damo/text-to-video-synthesis/summary)\n*   [neural frames](https://www.neuralframes.com/firstframe): tools for animation creation inspired on deforum\n*   \\[üî•] [dmarx/video-killed-the-radio-star (‚≠ê210)](https://github.com/dmarx/video-killed-the-radio-star): Notebook and tools for end-to-end automation of music video production with generative AI\n*   \\[üî•üî•üî•] [Phenaki ‚Äì Google Research](https://phenaki.research.google/): realistic video generation from open-domain textual descriptions\n*   [THUDM/CogVideo (‚≠ê12k)](https://github.com/THUDM/CogVideo): text-to-video generation\n*   [baowenbo/DAIN (‚≠ê8.3k)](https://github.com/baowenbo/DAIN): Depth-Aware Video Frame Interpolation (CVPR 2019)\n*   [Dain-App 1.0 \\[Nvidia Only\\] by GRisk](https://grisk.itch.io/dain-app): Depth-Aware Video Frame Interpolation (CVPR 2019)\n\n### Speech-to-text (STT) and spoken content analysis / Deforum\n\n*   [facebookresearch/seamless\\_communication (‚≠ê12k)](https://github.com/facebookresearch/seamless_communication): Foundational Models for State-of-the-Art Speech and Text Translation\n*   [LeMUR](https://www.assemblyai.com/blog/lemur/): a single API, enabling developers to reason over their spoken data with a few lines of code\n\n### Interesting Twitter Accounts / Deforum\n\n*   [Hassan El Mghari (@nutlope) / X](https://twitter.com/nutlope): the creator of [roomgpt](https://roomgpt.io)",
      "content_html": "<h3><p>Human-AI Interaction</p>\n</h3><ul>\n<li>[üî•üî•üî•] <a href=\"https://arxiv.org/abs/2310.07127\" rel=\"noopener noreferrer\">[2310.07127] An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions</a>: \"a survey of 154 papers, providing a novel taxonomy and analysis of Human-GenAI Interactions from both human and Gen-AI perspectives\".</li>\n</ul>\n<ul>\n<li><a href=\"https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/\" rel=\"noopener noreferrer\">Guidelines for Human-AI Interaction - Microsoft Research</a>: a set of \"18 generally applicable design guidelines for human-AI\" interaction</li>\n</ul>\n<h3><p>Generative AI history, timelines, maps, and definitions</p>\n</h3><ul>\n<li><a href=\"https://arxiv.org/abs/2309.07930\" rel=\"noopener noreferrer\">[2309.07930] Generative AI</a>: discusses a model-, system-, and application-level view on generative AI.</li>\n</ul>\n<h3><p>Ethics, Philosophical questions and Discussions about Generative AI</p>\n</h3><ul>\n<li><a href=\"https://www.scientificamerican.com/article/new-training-method-helps-ai-generalize-like-people-do/\" rel=\"noopener noreferrer\">New Training Method Helps AI Generalize like People Do - Scientific American</a></li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2310.01405\" rel=\"noopener noreferrer\">[2310.01405] Representation Engineering: A Top-Down Approach to AI Transparency</a>: \"an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience\"</li>\n</ul>\n<ul>\n<li><a href=\"https://www.law.berkeley.edu/library/legal-research/chatgpt/\" rel=\"noopener noreferrer\">Generative AI Resources for Berkeley Law Faculty &amp; Staff - Berkeley Law</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor\" rel=\"noopener noreferrer\">Licensing is neither feasible nor effective for addressing AI risks</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.aisnakeoil.com/p/generative-ai-companies-must-publish\" rel=\"noopener noreferrer\">Generative AI companies must publish transparency reports</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.aisnakeoil.com/p/does-chatgpt-have-a-liberal-bias\" rel=\"noopener noreferrer\">Does ChatGPT have a liberal bias?</a></li>\n</ul>\n<ul>\n<li><a href=\"https://link.springer.com/article/10.1007/s11127-023-01097-2\" rel=\"noopener noreferrer\">More human than human: measuring ChatGPT political bias | Public Choice</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.gatesnotes.com/The-Age-of-AI-Has-Begun\" rel=\"noopener noreferrer\">The Age of AI has begun | Bill Gates</a></li>\n</ul>\n<h3><p>Critical Views about Generative AI</p>\n</h3><ul>\n<li><a href=\"https://docs.google.com/document/d/1PPHwa3KmoeRZwaoxjOS568aF2E-kUngOA2oI45G2Iaw/edit\" rel=\"noopener noreferrer\">AI in Education Group Meeting Notes - Google Docs</a></li>\n</ul>\n<ul>\n<li><a href=\"https://docs.google.com/document/d/1RMVwzjc1o0Mi8Blw_-JUTcXv02b2WRH86vw7mi16W3U/edit#heading=h.1cykjn2vg2wx\" rel=\"noopener noreferrer\">Syllabi Policies for AI Generative Tools - Google Docs</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak\" rel=\"noopener noreferrer\">Five takeaways from UK‚Äôs AI safety summit at Bletchley Park | Artificial intelligence (AI) | The Guardian</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper\" rel=\"noopener noreferrer\">Frontier AI: capabilities and risks ‚Äì discussion paper - GOV.UK</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.aisafetysummit.gov.uk/policy-updates/#company-policies\" rel=\"noopener noreferrer\">AI Safety Summit Policy Updates | AISS 2023</a></li>\n</ul>\n<h3><p>Courses and Educational Materials</p>\n</h3><ul>\n<li><a href=\"https://animatedai.github.io/\" rel=\"noopener noreferrer\">Animated AI</a>: animations and instructional videos about neural networks</li>\n</ul>\n<ul>\n<li><a href=\"https://www.deeplearning.ai/courses/generative-ai-with-llms/\" rel=\"noopener noreferrer\">Deep Learning AI - Learn the fundamentals of generative AI for real-world applications</a>: created in partnership with AWS, this course presents the fundamentals of how generative AI works and how to deploy it in real-world applications.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.cloudskillsboost.google/course_templates/536\" rel=\"noopener noreferrer\">Google Cloud Skills Boost - Introduction to Generative AI</a>: an introductory level microlearning course covering Google Tools aimed at explaining what Generative AI is, how it is used, and how it differs from traditional machine learning methods.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.cloudskillsboost.google/journeys/118\" rel=\"noopener noreferrer\">Google Cloud Skills Boost: Generative AI learning path</a>: curated content on Generative AI \"from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud\"</li>\n</ul>\n<ul>\n<li><a href=\"https://industrialdesign.ai/\" rel=\"noopener noreferrer\">AI for Industrial Design</a>: \"students at the National University of Singapore explore AI‚Äôs capability for design in a semester course and share what they learned. Directed by Donn Koh at the Division of Industrial Design, NUS.\"</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://github.com/dair-ai\" rel=\"noopener noreferrer\">DAIR.AI</a>: Democratizing Artificial Intelligence Research, Education, and Technologies</li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/deep-rl-course/unit0/introduction?fw=pt\" rel=\"noopener noreferrer\">Welcome to the ü§ó Deep Reinforcement Learning Course</a>: a Hugging Face Course on Deep Reinforcement Learning</li>\n</ul>\n<ul>\n<li><a href=\"https://prompthero.com/academy\" rel=\"noopener noreferrer\">Crash course in AI art generation by PromptHero</a>: paid ($99) course focused on prompt engineering</li>\n</ul>\n<ul>\n<li><a href=\"https://www.tiktok.com/@ham_made_art/video/7154863972729113899\" rel=\"noopener noreferrer\">Visual intuition for diffusion models and AI art. #stablediffusionart #aiart #aiartwork #aiartcommunity</a></li>\n</ul>\n<ul>\n<li><a href=\"https://jalammar.github.io/illustrated-stable-diffusion/\" rel=\"noopener noreferrer\">The Illustrated Stable Diffusion by Jay Alammar</a>: \"gentle introduction [on] how Stable Diffusion works\"</li>\n</ul>\n<ul>\n<li>[üî•]<a href=\"https://github.com/johnowhitaker/tglcourse\" rel=\"noopener noreferrer\">johnowhitaker/tglcourse (‚≠ê145)</a>: The Generative Landscape - a course on generative modelling (currently unfinished)</li>\n</ul>\n<ul>\n<li><a href=\"https://www.bustbright.com/product/words-are-images-7-week-online-class-starting-october-24th-2022-/331\" rel=\"noopener noreferrer\">Words are Images | BustBright - Machine Learning Art</a>: 7-week Online class starting October 24th, 2022 by <a href=\"https://twitter.com/dvsch/\" rel=\"noopener noreferrer\">Derrick Schultz</a></li>\n</ul>\n<ul>\n<li><a href=\"https://colab.research.google.com/drive/1dlgggNa5Mz8sEAGU0wFCHhGLFooW_pf1?usp=sharing\" rel=\"noopener noreferrer\">Grokking Stable Diffusion.ipynb - Colaboratory - Part 1</a>: notebook by <a href=\"https://twitter.com/johnowhitaker\" rel=\"noopener noreferrer\">@johnowhitaker</a> exploring Stable Diffusion details</li>\n</ul>\n<ul>\n<li><a href=\"https://colab.research.google.com/drive/1RTHDzE-otzmZOuy8w1WEOxmn9pNcEz3u?usp=sharing\" rel=\"noopener noreferrer\">Grokking Stable Diffusion: Textual Inversion.ipynb - Colaboratory - Part 2</a>: sequel to Grokking Stable Diffusion by <a href=\"https://twitter.com/johnowhitaker\" rel=\"noopener noreferrer\">@johnowhitaker</a> that focus on Text Inversion</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/johnowhitaker/aiaiart\" rel=\"noopener noreferrer\">GitHub - johnowhitaker/aiaiart (‚≠ê570)</a>: Course content and resources for the AIAIART course</li>\n</ul>\n<ul>\n<li><a href=\"https://twitter.com/labmlai/status/1571080112459878401\" rel=\"noopener noreferrer\">Implementation/tutorial of stable diffusion with side-by-side notes by labml.ai | Twitter</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=_7rMfsA24Ls&amp;list=PLfYUBJiXbdtRUvTUYpLdfHHp9a58nWVXP\" rel=\"noopener noreferrer\">Practical Deep Learning for Coders 2023 - Part II</a>: continuation of the course focusing on the implementation of Stable Diffusion from scratch.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU\" rel=\"noopener noreferrer\">Practical Deep Learning for Coders 2022 - Part I</a>: \"free course designed for people with some coding experience who want to learn how to apply deep learning and machine learning to practical problems\" by Jeremy Howard</li>\n</ul>\n<h3><p>Prompt Engineering</p>\n</h3><ul>\n<li>[üî•üî•üî•] <a href=\"https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/\" rel=\"noopener noreferrer\">ChatGPT Prompt Engineering for Developers - DeepLearning.AI</a>: short course taught by Isa Fulford (OpenAI) and Andrew Ng (DeepLearning.AI) that provide best practices for prompt engineering</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://learnprompting.org/\" rel=\"noopener noreferrer\">Learn Prompting</a>: series of lessons of prompt engineering</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\" rel=\"noopener noreferrer\">Prompt Engineering | Lil'Log</a>: prompt engineering learning notes by Lilian Weng</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://www.promptingguide.ai/\" rel=\"noopener noreferrer\">Prompt Engineering Guide</a>: a project by DAIR.AI that intends to educate researchers and practitioners about prompt engineering</li>\n</ul>\n<ul>\n<li><a href=\"https://fedhoneypot.notion.site/25fdbdb69e9e44c6877d79e18336fe05?v=1d2bf4143680451986fd2836a04afbf4\" rel=\"noopener noreferrer\">the Book</a>: collection of prompts and hints of prompt engineering</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/dair-ai/Prompt-Engineering-Guide\" rel=\"noopener noreferrer\">dair-ai/Prompt-Engineering-Guide (‚≠ê59k)</a>: Guide and resources for prompt engineering</li>\n</ul>\n<h3><p>Papers Collection</p>\n</h3><ul>\n<li><a href=\"https://github.com/dair-ai/ML-Papers-Explained\" rel=\"noopener noreferrer\">dair-ai/ML-Papers-Explained (‚≠ê8k)</a>: Explanation to key concepts in ML</li>\n</ul>\n<ul>\n<li><a href=\"https://docs.google.com/document/d/1bEQM1W-1fzSVWNbS4ne5PopB2b7j8zD4Jc3nm4rbK-U/edit\" rel=\"noopener noreferrer\">AI Reading List - Google Docs</a>: reading list organized by <a href=\"https://twitter.com/JackSoslow\" rel=\"noopener noreferrer\">Jack Soslow (@JackSoslow)</a></li>\n</ul>\n<ul>\n<li><a href=\"https://aman.ai/papers/\" rel=\"noopener noreferrer\">Aman's AI Journal ‚Ä¢ Papers List</a>: set of seminal AI/ML papers curated by Aman Chadha</li>\n</ul>\n<ul>\n<li><a href=\"https://casualgan.notion.site/casualgan/Casual-GAN-Papers-Reading-Club-327c158518e44d5296a5def74486c7e8\" rel=\"noopener noreferrer\">Casual GAN Papers Reading Club</a>: Community knowledge base for Casual GAN Papers</li>\n</ul>\n<ul>\n<li><a href=\"https://www.casualganpapers.com/\" rel=\"noopener noreferrer\">Casual GAN Papers</a>: Easy to read summaries of popular AI papers</li>\n</ul>\n<ul>\n<li><a href=\"https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/\" rel=\"noopener noreferrer\">The Illustrated VQGAN</a>: illustrated explanation on how VQGAN works</li>\n</ul>\n<ul>\n<li><a href=\"https://openai.com/blog/clip/\" rel=\"noopener noreferrer\">CLIP: Connecting Text and Images</a>: OpenAI's explanation on how CLIP works</li>\n</ul>\n<ul>\n<li><a href=\"https://alexasteinbruck.medium.com/vqgan-clip-how-does-it-work-210a5dca5e52\" rel=\"noopener noreferrer\">VQGAN+CLIP ‚Äî How does it work?. The synthetic imagery (‚ÄúGAN Art‚Äù) scene‚Ä¶ | by Alexa Steinbr√ºck | Medium</a></li>\n</ul>\n<ul>\n<li><a href=\"https://paperswithcode.com/methods\" rel=\"noopener noreferrer\">The Methods Corpus | Papers With Code</a></li>\n</ul>\n<ul>\n<li><a href=\"https://ieeexplore.ieee.org/abstract/document/9043519\" rel=\"noopener noreferrer\">https://ieeexplore.ieee.org/abstract/document/9043519</a>: A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks</li>\n</ul>\n<ul>\n<li><a href=\"https://www.cin.ufpe.br/~tg/2020-1/TG_CC/tg_cco2.pdf\" rel=\"noopener noreferrer\">Utilizando redes advers√°rias generativas (GANs) como agente de apoio √† inspira√ß√£o para artistas</a>: Trabalho de Gradua√ß√£o de Cl√°udio Carvalho no Centro de Inform√°tica - UFPE</li>\n</ul>\n<ul>\n<li><a href=\"https://poloclub.github.io/ganlab/\" rel=\"noopener noreferrer\">GAN Lab</a>: Play with Generative Adversarial Networks in Your Browser!</li>\n</ul>\n<ul>\n<li><a href=\"https://www.semanticscholar.org/paper/Music2Video%3A-Automatic-Generation-of-Music-Video-of-Jang-Shin/38e37c3a7dc22bb3356552e93e6685b99ca04264\" rel=\"noopener noreferrer\">[PDF] Music2Video: Automatic Generation of Music Video with fusion of audio and text | Semantic Scholar</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.semanticscholar.org/paper/Active-Divergence-with-Generative-Deep-Learning-A-Broad-Berns/091c4ea2efaba23cd9024d8a063609c9a313b5cb\" rel=\"noopener noreferrer\">[PDF] Active Divergence with Generative Deep Learning - A Survey and Taxonomy | Semantic Scholar</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.semanticscholar.org/paper/Automating-Generative-Deep-Learning-for-Artistic-Berns-Broad/f3479740d4ec7f91b6d7a01167e9c875a72d386e\" rel=\"noopener noreferrer\">[PDF] Automating Generative Deep Learning for Artistic Purposes: Challenges and Opportunities | Semantic Scholar</a></li>\n</ul>\n<h3><p>Online Tools and Applications</p>\n</h3><ul>\n<li><a href=\"https://www.usetailor.com\" rel=\"noopener noreferrer\">Tailor</a>: Get a daily podcast and newsletter, created for you by an AI</li>\n</ul>\n<ul>\n<li><a href=\"https://paintbytext.chat/\" rel=\"noopener noreferrer\">Paint by Text</a>: Edit your photos using written instructions, with the help of an AI.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.scenario.gg/\" rel=\"noopener noreferrer\">Scenario AI</a>: AI-generated game assets</li>\n</ul>\n<ul>\n<li><a href=\"https://animalai.co/\" rel=\"noopener noreferrer\">AnimalAI</a>: custom AI-generated animal portraits (profits are directed to various wildlife conservation organizations)</li>\n</ul>\n<ul>\n<li><a href=\"https://www.starryai.com/\" rel=\"noopener noreferrer\">starryai</a>: AI Art Generator App - AI Art Maker</li>\n</ul>\n<ul>\n<li><a href=\"https://www.prosepainter.com/\" rel=\"noopener noreferrer\">ProsePainter</a>: an interactive tool to \"paint with words.\" It incorporates guidable text-to-image generation into a traditional digital painting interface</li>\n</ul>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=mK4F32xNrdw&amp;t=429s\" rel=\"noopener noreferrer\">ProsePainter: Image + Sketching Interface + CLIP! - YouTube</a></li>\n</ul>\n<ul>\n<li><a href=\"https://cocreator.ai/\" rel=\"noopener noreferrer\">Cocreator AI</a>: creative computer agent (in wait list)</li>\n</ul>\n<ul>\n<li><a href=\"http://runwayml.com/\" rel=\"noopener noreferrer\">Runway ML</a>: AI video creation suite</li>\n</ul>\n<ul>\n<li><a href=\"https://hotpot.ai/\" rel=\"noopener noreferrer\">Hotpot.ai - Hotpot.ai</a>: set of AI Tools to post-process images</li>\n</ul>\n<ul>\n<li><a href=\"https://www.justinpinkney.com/toonify-yourself/\" rel=\"noopener noreferrer\">Toonify yourself by Justin Pinkney</a>: turn a human face into a cartoon</li>\n</ul>\n<ul>\n<li><a href=\"https://deepart.io/\" rel=\"noopener noreferrer\">deepart.io</a>: a online tool for applying style transfer</li>\n</ul>\n<ul>\n<li><a href=\"https://www.artbreeder.com/\" rel=\"noopener noreferrer\">Artbreeder</a>: web-based tool to generate images by breeding existing images</li>\n</ul>\n<ul>\n<li><a href=\"https://www.ostagram.me/\" rel=\"noopener noreferrer\">Ostagram.ru</a>: image style transfer plataform</li>\n</ul>\n<ul>\n<li><a href=\"https://cleanup.pictures/\" rel=\"noopener noreferrer\">cleanup.pictures</a>: remove objects, people, text and defects from any picture for free</li>\n</ul>\n<ul>\n<li><a href=\"https://www.remove.bg/\" rel=\"noopener noreferrer\">remove.bg</a>: remove background from images</li>\n</ul>\n<ul>\n<li><a href=\"https://quickdraw.withgoogle.com/\" rel=\"noopener noreferrer\">Quick, Draw!</a>: can a neural network learn to recognize doodling? A game to help NL by adding users drawing</li>\n</ul>\n<ul>\n<li><a href=\"https://nekton.ai/\" rel=\"noopener noreferrer\">Nekton.ai</a>: automate your workflows with AI</li>\n</ul>\n<h3><p>Large Language Models (LLMs)</p>\n</h3><ul>\n<li><a href=\"https://github.com/cpacker/MemGPT\" rel=\"noopener noreferrer\">cpacker/MemGPT (‚≠ê17k)</a>: teaching LLMs memory management for unbounded context <a href=\"https://memgpt.ai/\" rel=\"noopener noreferrer\">[demo page]</a> <a href=\"https://arxiv.org/abs/2310.08560\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2307.10169\" rel=\"noopener noreferrer\">[2307.10169] Challenges and Applications of Large Language Models</a>: a systematic set of open problems and application successes of LLM area</li>\n</ul>\n<ul>\n<li><a href=\"https://cookbook.openai.com/articles/related_resources\" rel=\"noopener noreferrer\">Related resources from around the web | OpenAI Cookbook</a>: tools and papers for improving outputs from GPT</li>\n</ul>\n<h3><p>Prompt Engineering / Prompt Engineering for Text-to-text</p>\n</h3><ul>\n<li>[üî•] <a href=\"https://arxiv.org/abs/2307.11760\" rel=\"noopener noreferrer\">[2307.11760] Large Language Models Understand and Can be Enhanced by Emotional Stimuli</a></li>\n</ul>\n<ul>\n<li>[üî•] <a href=\"https://arxiv.org/abs/2305.13252\" rel=\"noopener noreferrer\">[2305.13252] \"According to ...\" Prompting Language Models Improves Quoting from Pre-Training Data</a></li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/timqian/openprompt.co\" rel=\"noopener noreferrer\">timqian/openprompt.co (‚≠ê1.2k)</a>: Create. Use. Share. ChatGPT prompts</li>\n</ul>\n<ul>\n<li><a href=\"https://medium.datadriveninvestor.com/60-chatgpt-prompts-for-data-science-tried-tested-and-rated-4994c7e6adb2\" rel=\"noopener noreferrer\">60 ChatGPT Prompts for Data Science (Tried, Tested, and Rated)</a>: post by Travis Tang from DataDrivenInvestor</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/f/awesome-chatgpt-prompts\" rel=\"noopener noreferrer\">f/awesome-chatgpt-prompts (‚≠ê130k)</a>: this repo includes ChatGPT prompt curation to use ChatGPT better</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/brexhq/prompt-engineering\" rel=\"noopener noreferrer\">brexhq/prompt-engineering (‚≠ê9.2k)</a>: \"Tips and tricks for working with Large Language Models like OpenAI's GPT-4\"</li>\n</ul>\n<ul>\n<li><a href=\"https://zapier.com/blog/gpt-3-prompt/\" rel=\"noopener noreferrer\">How to write an effective GPT-3 prompt | Zapier</a>: a list of 6 GPT-3 tips for getting the desired output</li>\n</ul>\n<ul>\n<li><a href=\"https://fka.gumroad.com/l/art-of-chatgpt-prompting\" rel=\"noopener noreferrer\">The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts</a>: e-book by Fatih Kadir Akƒ±n (<a href=\"http://twitter.com/fkadev\" rel=\"noopener noreferrer\">@fkadev</a>)</li>\n</ul>\n<h3><p>Autonomous LLM Agents / Multi-agents</p>\n</h3><ul>\n<li><a href=\"https://arxiv.org/abs/2307.05300\" rel=\"noopener noreferrer\">[2307.05300] Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration</a></li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/OpenBMB/ChatDev\" rel=\"noopener noreferrer\">OpenBMB/ChatDev (‚≠ê27k)</a>: create customized software using natural language idea (through llm-powered multi-agent collaboration)</li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2308.07201\" rel=\"noopener noreferrer\">[2308.07201] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate</a></li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2308.10848\" rel=\"noopener noreferrer\">[2308.10848] AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a></li>\n</ul>\n<h3><p>Prompt Engineering / Prompt Engineering for Text-to-image</p>\n</h3><ul>\n<li><a href=\"https://app.usp.ai/static/Stable%20Diffusion%202.1%20Prompt%20Book%20by%20USP.ai.pdf\" rel=\"noopener noreferrer\">USP AI Prompt Book</a>: Stable Diffusion v2.1 Prompt Book</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/daspartho/prompt-extend\" rel=\"noopener noreferrer\">daspartho/prompt-extend (‚≠ê176)</a>: extending stable diffusion prompts with suitable style cues using text generation</li>\n</ul>\n<ul>\n<li><a href=\"https://www.promptbox.ai/\" rel=\"noopener noreferrer\">Prompt Box</a>: \"organize and save your AI prompts\"</li>\n</ul>\n<ul>\n<li><a href=\"https://docs.google.com/spreadsheets/d/1e2MZ1K6WMTUuxlPAQ_2A0rz-H55NBykb66TY7DuerVg/edit#gid=2088669480\" rel=\"noopener noreferrer\">Midjourney artist reference - Google Sheets</a></li>\n</ul>\n<ul>\n<li><a href=\"https://stability.ai/sdv2-prompt-book\" rel=\"noopener noreferrer\">Stable Diffusion Prompt Book ‚Äî Stability.Ai</a>: prompt book for Stable Diffusion v2.0 and v2.1 released by Stability.AI</li>\n</ul>\n<ul>\n<li><a href=\"https://prompthero.com/stable-diffusion-prompt-guide\" rel=\"noopener noreferrer\">The Ultimate Stable Diffusion Prompt Guide by PromptHero</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/spaces/pharma/CLIP-Interrogator\" rel=\"noopener noreferrer\">CLIP Interrogator - a Hugging Face Space by pharma</a>: image-to-text tool to figure out what a good prompt might be to create new images like an existing one</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://docs.google.com/presentation/d/1V8d6TIlKqB1j5xPFH7cCmgKOV_fMs4Cb4dwgjD5GIsg/edit#slide=id.g1834b964b0f_3_4\" rel=\"noopener noreferrer\">Prompt book for data lovers II - Google Slides</a>: An open source exploration on text-to-image and data visualization</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/some9000/StylePile\" rel=\"noopener noreferrer\">some9000/StylePile (‚≠ê580)</a>: A helper script for AUTOMATIC1111/stable-diffusion-webui. Basically a mix and match to quickly get different results without wasting a lot of time writing prompts.</li>\n</ul>\n<ul>\n<li><a href=\"https://artiststostudy.pages.dev/\" rel=\"noopener noreferrer\">Artists To Study | All images generated with Google Colab TPUs + CompVis/stable-diffusion-v1-4 + Huggingface Diffusers</a>: a systematic study of artists' styles made by <a href=\"https://twitter.com/camenduru\" rel=\"noopener noreferrer\">@camenduru</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.reddit.com/r/PromptDesign/\" rel=\"noopener noreferrer\">PromptDesign | Reddit</a>: Reddit community for \"the art of communicating with natural language models\"</li>\n</ul>\n<ul>\n<li><a href=\"https://www.inovex.de/de/blog/prompt-engineering-guide/\" rel=\"noopener noreferrer\">Prompt Engineering and Zero-Shot/Few-Shot Learning [Guide] - inovex GmbH</a>: prompt engineering for text generation</li>\n</ul>\n<ul>\n<li><a href=\"https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb#scrollTo=rbDEMDGJrJEo\" rel=\"noopener noreferrer\">clip-interrogator.ipynb - Colaboratory</a>: a tool for image-to-prompt</li>\n</ul>\n<ul>\n<li><a href=\"https://www.reddit.com/r/StableDiffusion/comments/xcrm4d/useful_prompt_engineering_tools_and_resources/\" rel=\"noopener noreferrer\">Useful Prompt Engineering tools and resources | Reddit</a></li>\n</ul>\n<ul>\n<li><a href=\"https://prompthero.com/\" rel=\"noopener noreferrer\">PromptHero</a>: Search the best prompts for Stable Diffusion, DALL-E and Midjourney</li>\n</ul>\n<ul>\n<li><a href=\"https://promptomania.com/\" rel=\"noopener noreferrer\">promptoMANIA</a>: AI art community with prompt generator</li>\n</ul>\n<ul>\n<li><a href=\"https://lexica.art/\" rel=\"noopener noreferrer\">Lexica</a>: search over 10M+ Stable Diffusion images and prompts</li>\n</ul>\n<ul>\n<li><a href=\"https://rentry.org/artists_sd-v1-4\" rel=\"noopener noreferrer\">list of artists for SD v1.4 A-C / D-I / J-N / O-Z</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/succinctly/text2image-prompt-generator\" rel=\"noopener noreferrer\">succinctly/text2image-prompt-generator ¬∑ Hugging Face</a>: a GPT-2 model fine-tuned on the succinctly/midjourney-prompts dataset, which contains 250k text prompts that users issued to the Midjourney text-to-image service over a month period</li>\n</ul>\n<ul>\n<li><a href=\"https://theprompter.substack.com/\" rel=\"noopener noreferrer\">The Prompter | vicc | Substack</a>: a newsletter about news, tips and thoughts around prompt engineering</li>\n</ul>\n<ul>\n<li><a href=\"https://twitter.com/HeyNikhila/status/1570005481896255490\" rel=\"noopener noreferrer\">(19) Nikhil Agrawal üìå on Twitter</a>: 11 AI Images Prompt websites to level up the image quality</li>\n</ul>\n<ul>\n<li><a href=\"https://phraser.tech/\" rel=\"noopener noreferrer\">Phraser</a>: a tool that support prompt creation</li>\n</ul>\n<ul>\n<li><a href=\"https://promptbase.com/\" rel=\"noopener noreferrer\">PromptBase | Prompt Marketplace</a>: PromptBase is a marketplace for DALL¬∑E, Midjourney &amp; GPT-3 prompts, where people can sell prompts and make money from their prompt crafting skills.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.theverge.com/2022/9/2/23326868/dalle-midjourney-ai-promptbase-prompt-market-sales-artist-interview\" rel=\"noopener noreferrer\">Professional AI whisperers have launched a marketplace for DALL-E prompts - The Verge</a></li>\n</ul>\n<ul>\n<li><a href=\"https://tools.saxifrage.xyz/prompt\" rel=\"noopener noreferrer\">Visual Prompt Builder</a>: simple deck of illustrated card to combine modifiers for prompt building</li>\n</ul>\n<ul>\n<li><a href=\"https://docs.google.com/spreadsheets/d/1-snKDn38-KypoYCk9XLPg799bHcNFSBAVu2HVvFEAkA/edit#gid=0\" rel=\"noopener noreferrer\">Prompt Engineering Template - Google Sheets</a>: spreadsheet with lists of modifiers for prompt building and a lot of interesting links for reference</li>\n</ul>\n<ul>\n<li><a href=\"https://www.saxifrage.xyz/post/prompt-engineering\" rel=\"noopener noreferrer\">Prompt Engineering: From Words to Art - Saxifrage Blog</a></li>\n</ul>\n<ul>\n<li><a href=\"https://dallery.gallery/prompt-resources-tools-ai-art/\" rel=\"noopener noreferrer\">DALL¬∑Ery GALL¬∑Ery Resources</a>: DALL¬∑E 2 and AI art prompt resources &amp; tools to inspire beautiful images</li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2204.13988\" rel=\"noopener noreferrer\">[2204.13988] A Taxonomy of Prompt Modifiers for Text-To-Image Generation</a></li>\n</ul>\n<ul>\n<li><a href=\"https://aesthetics.fandom.com/wiki/List_of_Aesthetics\" rel=\"noopener noreferrer\">List of Aesthetics | Aesthetics Wiki | Fandom</a></li>\n</ul>\n<ul>\n<li><a href=\"https://aiartcreation.fandom.com/wiki/Artist_Directory_(Volcano_Comparison)\" rel=\"noopener noreferrer\">Artist Directory (Volcano Comparison) | AI Art Creation Wiki | Fandom</a></li>\n</ul>\n<ul>\n<li><a href=\"https://dallery.gallery/the-dalle-2-prompt-book/\" rel=\"noopener noreferrer\">The DALL¬∑E 2 Prompt Book ‚Äì DALL¬∑Ery GALL¬∑Ery</a></li>\n</ul>\n<ul>\n<li><a href=\"https://dallery.gallery/\" rel=\"noopener noreferrer\">DALL¬∑Ery GALL¬∑Ery</a>: A guide to OpenAI's DALL¬∑E ‚Äì prompts, projects, examples, and tips</li>\n</ul>\n<ul>\n<li><a href=\"https://www.reddit.com/user/haaaaven/comments/w05f56/massive_dalle_2_anime_keywords_modifiers_list/\" rel=\"noopener noreferrer\">(2) MASSIVE üí• DALL-E 2 ANIME ‚ö°Ô∏é KEYWORDS + MODIFIERS LIST ‚òÖ : haaaaven</a>: image prompt modifier collection by haaaaven</li>\n</ul>\n<ul>\n<li><a href=\"https://docs.google.com/spreadsheets/d/1y7nAbmR4FREi6npB1u-Bo3GFdwdOPYJc617rBOxIRHY/edit#gid=0\" rel=\"noopener noreferrer\">DrawBench</a>: a list of prompts the Google Imagen is organizing as a benchmark</li>\n</ul>\n<ul>\n<li><a href=\"https://matthewmcateer.me/blog/clip-prompt-engineering/\" rel=\"noopener noreferrer\">CLIP Prompt Engineering for Generative Art - matthewmcateer.me</a>: list of styles tested with Quick CLIP Guided Diffusion</li>\n</ul>\n<ul>\n<li><a href=\"https://interconnected.org/home/2022/06/02/dalle\" rel=\"noopener noreferrer\">Adobe should make a boring app for prompt engineers (Interconnected)</a></li>\n</ul>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2206.00169\" rel=\"noopener noreferrer\">[2206.00169] Discovering the Hidden Vocabulary of DALLE-2</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.reddit.com/r/StableDiffusion/comments/xgwcab/when_sd_just_doesnt_understand_the_prompt_no/\" rel=\"noopener noreferrer\">When SD just doesn't understand the prompt no matter how hard I try | Reddit</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.reddit.com/r/StableDiffusion/comments/xgplii/its_very_interesting_how_some_prompts_have_very/\" rel=\"noopener noreferrer\">It's very interesting how some prompts have very defined output but other specific ones are not | Reddit</a></li>\n</ul>\n<h3><p>Multimodal Embedding Space / Deforum</p>\n</h3><ul>\n<li><a href=\"https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn5.laion.ai&amp;index=laion5B&amp;useMclip=false\" rel=\"noopener noreferrer\">CLIP retrieval for laion5B</a>: CLIP retrieval using Laion5B. \"It works by converting the text query to a CLIP embedding , then using that embedding to query a knn index of clip image embedddings\".</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/rom1504/clip-retrieval\" rel=\"noopener noreferrer\">rom1504/clip-retrieval (‚≠ê2.6k)</a>: Easily compute CLIP embeddings and build a CLIP retrieval system with them</li>\n</ul>\n<ul>\n<li><a href=\"https://segment-anything.com/\" rel=\"noopener noreferrer\">Segment Anything | Meta AI</a>: \"a new AI model from Meta AI that can \"cut out\" any object, in any image, with a single click\"</li>\n</ul>\n<ul>\n<li><a href=\"https://twitter.com/mervenoyann/status/1720126908384366649\" rel=\"noopener noreferrer\">Microsoft KOSMOS-2</a>: new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world <a href=\"https://huggingface.co/spaces/ydshieh/Kosmos-2\" rel=\"noopener noreferrer\">[HF demo]</a> <a href=\"https://arxiv.org/abs/2306.14824\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/facebookresearch/ImageBind\" rel=\"noopener noreferrer\">facebookresearch/ImageBind (‚≠ê8.7k)</a>: ImageBind One Embedding Space to Bind Them All</li>\n</ul>\n<ul>\n<li><a href=\"https://together.ai/blog/redpajama-data-v2\" rel=\"noopener noreferrer\">RedPajama-Data-v2 by Together AI</a>: an open dataset with 30 trillion tokens for training Large Language Models</li>\n</ul>\n<ul>\n<li><a href=\"https://haveibeentrained.com/\" rel=\"noopener noreferrer\">Have I Been Trained?</a>: tool for searching 5.8 billion images used to train popular AI art models</li>\n</ul>\n<ul>\n<li><a href=\"https://laion-aesthetic.datasette.io/laion-aesthetic-6pls/images\" rel=\"noopener noreferrer\">laion-aesthetic-6pls</a>: exploring 12 million of the 2.3 billion images used to train Stable Diffusion's image generator</li>\n</ul>\n<ul>\n<li><a href=\"https://laion.ai/\" rel=\"noopener noreferrer\">LAION</a>: Large-scale Artificial Intelligence Open Network</li>\n</ul>\n<h3><p>Retrieval-Augmented Generation (RAG) / Prompt Engineering for Text-to-image</p>\n</h3><ul>\n<li><a href=\"https://www.pinecone.io/learn/series/rag/rerankers/\" rel=\"noopener noreferrer\">Rerankers and Two-Stage Retrieval | Pinecone</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.pinecone.io/learn/series/rag/\" rel=\"noopener noreferrer\">Retrieval Augmented Generation | Pinecone</a></li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/dssjon/biblos\" rel=\"noopener noreferrer\">dssjon/biblos: biblos.app (‚≠ê212)</a>: example of RAG architecture using semantic search and summarization for retrieving Bible passages</li>\n</ul>\n<h3><p>Embeddings and Semantic Search / Prompt Engineering for Text-to-image</p>\n</h3><ul>\n<li><a href=\"https://github.com/neuml/txtai\" rel=\"noopener noreferrer\">neuml/txtai (‚≠ê11k)</a>: semantic search and workflows powered by language models</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/facebookresearch/faiss\" rel=\"noopener noreferrer\">facebookresearch/faiss (‚≠ê36k)</a>: A library for efficient similarity search and clustering of dense vectors</li>\n</ul>\n<ul>\n<li><a href=\"https://betterprogramming.pub/how-to-give-your-chatbot-the-power-of-neural-search-with-openai-ebcff5194170\" rel=\"noopener noreferrer\">Optimize Your Chatbot‚Äôs Conversational Intelligence Using GPT-3 | by Amogh Agastya | Better Programming</a>: tutorial presenting semantic search concepts</li>\n</ul>\n<ul>\n<li><a href=\"https://txt.cohere.ai/what-is-semantic-search/\" rel=\"noopener noreferrer\">What is Semantic Search?</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.pinecone.io/learn/\" rel=\"noopener noreferrer\">Learning Center | Pinecone</a>: Pinecone's guides to vector embeddings</li>\n</ul>\n<ul>\n<li><a href=\"https://www.kaggle.com/code/leonidkulyk/lb-0-45836-blip-clip-clip-interrogator\" rel=\"noopener noreferrer\">BLIP+CLIP | CLIP Interrogator | Kaggle</a>: a Kaggle notebook for image description and captioning (imate-to-text)</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/jerryjliu/gpt_index\" rel=\"noopener noreferrer\">jerryjliu/gpt_index: GPT Index (LlamaIndex) (‚≠ê43k)</a>: a project to make it easier to use large external knowledge bases with LLMs</li>\n</ul>\n<ul>\n<li><a href=\"https://llamahub.ai/\" rel=\"noopener noreferrer\">Llama Hub</a>: a repository of data loaders for LlamaIndex (GPT Index) and LangChain</li>\n</ul>\n<ul>\n<li><a href=\"https://www.trychroma.com/\" rel=\"noopener noreferrer\">Chroma</a>: an open-source AI-native database that makes it easy to use embeddings</li>\n</ul>\n<h3><p>Autonomous LLM Agents / Prompt Engineering for Text-to-image</p>\n</h3><ul>\n<li><a href=\"https://github.com/joonspk-research/generative_agents\" rel=\"noopener noreferrer\">joonspk-research/generative_agents - Generative Agents (‚≠ê19k)</a>: code for interactive simulacra of human behavior <a href=\"https://arxiv.org/abs/2304.03442\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<h3><p>LLM Evaluation / Multi-agents</p>\n</h3><ul>\n<li><a href=\"https://www.airtrain.ai/\" rel=\"noopener noreferrer\">LLM Evaluation at Scale ‚Äì Airtrain</a>: no-code batch compute platform for LLM evaluation and tuning workloads</li>\n</ul>\n<ul>\n<li><a href=\"https://cookbook.openai.com/examples/evaluation/how_to_eval_abstractive_summarization\" rel=\"noopener noreferrer\">How to evaluate a summarization task | OpenAI Cookbook</a></li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/openai/evals\" rel=\"noopener noreferrer\">openai/evals (‚≠ê17k)</a>: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.</li>\n</ul>\n<ul>\n<li><a href=\"https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/red-teaming-and-model-evaluations\" rel=\"noopener noreferrer\">Red teaming and model evaluations | Anthropic</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.anthropic.com/index/evaluating-ai-systems\" rel=\"noopener noreferrer\">Challenges in evaluating AI systems | Anthropic</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/\" rel=\"noopener noreferrer\">Evaluating LLMs is a minefield</a>: talk by Princeton professor Arvind Narayanan</li>\n</ul>\n<h3><p>AI Engineering / Multi-agents</p>\n</h3><ul>\n<li><a href=\"https://www.askmarvin.ai/\" rel=\"noopener noreferrer\">Marvin</a>: AI engineering framework for building natural language interfaces</li>\n</ul>\n<ul>\n<li><a href=\"https://jxnl.github.io/instructor/\" rel=\"noopener noreferrer\">Instructor</a>: library for structured LLM extraction in Python</li>\n</ul>\n<h3><p>Image Segmentation / Deforum</p>\n</h3><ul>\n<li><a href=\"https://notes.aimodels.fyi/transforming-2d-images-into-3d-with-the-adampi-ai-model/\" rel=\"noopener noreferrer\">Transforming 2D Images into 3D with the AdaMPI AI Model</a>: guide on how to use the AdaMPI AI model for creating 3D photos from 2D images</li>\n</ul>\n<ul>\n<li><a href=\"https://www.ssemble.com/\" rel=\"noopener noreferrer\">Ssemble</a>: collaborative video editor with a collection of AI plugins</li>\n</ul>\n<ul>\n<li><a href=\"https://twitter.com/NathanLands/status/1659195191591596033\" rel=\"noopener noreferrer\">Nathan Lands on Twitter: \"AI video has started to produce mindblowing results and could eventually disrupt Hollywood / Twitter</a>: Twitter thread with examples of Generative AI tools for video</li>\n</ul>\n<ul>\n<li><a href=\"https://stability.ai/blog/stable-animation-sdk\" rel=\"noopener noreferrer\">Stable Animation SDK</a>: a text-to-animation tool for developers by Stability AI <a href=\"https://platform.stability.ai/docs/features/animation\" rel=\"noopener noreferrer\">[dev platform]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://twelvelabs.io/\" rel=\"noopener noreferrer\">Twelve Labs</a>: multimodal, contextual understanding for video search</li>\n</ul>\n<ul>\n<li><a href=\"https://research.nvidia.com/labs/toronto-ai/VideoLDM/\" rel=\"noopener noreferrer\">Align your Latents</a>: high-resolution video synthesis with latent diffusion models <a href=\"https://arxiv.org/abs/2304.08818\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://research.runwayml.com/gen2\" rel=\"noopener noreferrer\">Gen-2 by Runway</a>: \"a multi-modal AI system that can generate novel videos with text, images, or video clips\" <a href=\"https://arxiv.org/abs/2302.03011\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/CiaraRowles/TemporalNet\" rel=\"noopener noreferrer\">CiaraRowles/TemporalNet ¬∑ Hugging Face</a>: a ControlNet model designed to enhance the temporal consistency of generated outputs <a href=\"https://twitter.com/ciararowles1/status/1639321818581303310\" rel=\"noopener noreferrer\">[tweet]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/spaces/video-p2p-library/Video-P2P-Demo\" rel=\"noopener noreferrer\">Video-P2P UI - a Hugging Face Space by video-p2p-library</a>: video editing with cross-attention control <a href=\"https://twitter.com/_akhaliq/status/1637838648463749120\" rel=\"noopener noreferrer\">[tweet]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/spaces/PAIR/Text2Video-Zero\" rel=\"noopener noreferrer\">Text2Video-Zero - a Hugging Face Space by PAIR</a>: zero-shot text-to-video synthesis diffusion framework <a href=\"https://twitter.com/_akhaliq/status/1639062868850266112\" rel=\"noopener noreferrer\">[tweet]</a> <a href=\"https://arxiv.org/abs/2303.13439\" rel=\"noopener noreferrer\">[arxiv]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis\" rel=\"noopener noreferrer\">ModelScope - a Hugging Face Space by damo-vilab</a>: text-to-video synthesis <a href=\"https://www.modelscope.cn/models/damo/text-to-video-synthesis/summary\" rel=\"noopener noreferrer\">[page]</a></li>\n</ul>\n<ul>\n<li><a href=\"https://www.neuralframes.com/firstframe\" rel=\"noopener noreferrer\">neural frames</a>: tools for animation creation inspired on deforum</li>\n</ul>\n<ul>\n<li>[üî•] <a href=\"https://github.com/dmarx/video-killed-the-radio-star\" rel=\"noopener noreferrer\">dmarx/video-killed-the-radio-star (‚≠ê210)</a>: Notebook and tools for end-to-end automation of music video production with generative AI</li>\n</ul>\n<ul>\n<li>[üî•üî•üî•] <a href=\"https://phenaki.research.google/\" rel=\"noopener noreferrer\">Phenaki ‚Äì Google Research</a>: realistic video generation from open-domain textual descriptions</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/THUDM/CogVideo\" rel=\"noopener noreferrer\">THUDM/CogVideo (‚≠ê12k)</a>: text-to-video generation</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/baowenbo/DAIN\" rel=\"noopener noreferrer\">baowenbo/DAIN (‚≠ê8.3k)</a>: Depth-Aware Video Frame Interpolation (CVPR 2019)</li>\n</ul>\n<ul>\n<li><a href=\"https://grisk.itch.io/dain-app\" rel=\"noopener noreferrer\">Dain-App 1.0 [Nvidia Only] by GRisk</a>: Depth-Aware Video Frame Interpolation (CVPR 2019)</li>\n</ul>\n<h3><p>Speech-to-text (STT) and spoken content analysis / Deforum</p>\n</h3><ul>\n<li><a href=\"https://github.com/facebookresearch/seamless_communication\" rel=\"noopener noreferrer\">facebookresearch/seamless_communication (‚≠ê12k)</a>: Foundational Models for State-of-the-Art Speech and Text Translation</li>\n</ul>\n<ul>\n<li><a href=\"https://www.assemblyai.com/blog/lemur/\" rel=\"noopener noreferrer\">LeMUR</a>: a single API, enabling developers to reason over their spoken data with a few lines of code</li>\n</ul>\n<h3><p>Interesting Twitter Accounts / Deforum</p>\n</h3><ul>\n<li><a href=\"https://twitter.com/nutlope\" rel=\"noopener noreferrer\">Hassan El Mghari (@nutlope) / X</a>: the creator of <a href=\"https://roomgpt.io\" rel=\"noopener noreferrer\">roomgpt</a></li>\n</ul>\n",
      "date_published": "2023-11-03T15:14:13.000Z",
      "date_modified": "2023-11-03T16:42:45.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/gruhn/awesome-naming/",
      "title": "Awesome Naming",
      "_slug": "gruhn/awesome-naming/",
      "_filepath": "/content/gruhn/awesome-naming/README.md",
      "url": "https://www.trackawesomelist.com/gruhn/awesome-naming/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Programming Languages and Programming Language Theory\n\n*   [Choreographic programming](https://en.wikipedia.org/wiki/Choreographic_programming) - A programming paradigm where programs are compositions of interactions among multiple concurrent participants.\n*   [Garbage Collector](https://en.m.wikipedia.org/wiki/Garbage_collection_\\(computer_science\\)) - Part of a program that attempts to find and reclaim garbage pieces of memory not used anymore.\n*   [Syntactic sugar](https://en.wikipedia.org/wiki/Syntactic_sugar) - Syntax that makes the language \"sweeter\" for human use. Usually a shorthand for common operations that can also be expressed in a more verbose form.",
      "content_html": "<h3><p>Programming Languages and Programming Language Theory</p>\n</h3><ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Choreographic_programming\" rel=\"noopener noreferrer\">Choreographic programming</a> - A programming paradigm where programs are compositions of interactions among multiple concurrent participants.</li>\n</ul>\n<ul>\n<li><a href=\"https://en.m.wikipedia.org/wiki/Garbage_collection_(computer_science)\" rel=\"noopener noreferrer\">Garbage Collector</a> - Part of a program that attempts to find and reclaim garbage pieces of memory not used anymore.</li>\n</ul>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Syntactic_sugar\" rel=\"noopener noreferrer\">Syntactic sugar</a> - Syntax that makes the language \"sweeter\" for human use. Usually a shorthand for common operations that can also be expressed in a more verbose form.</li>\n</ul>\n",
      "date_published": "2023-11-03T14:35:03.000Z",
      "date_modified": "2023-11-03T14:35:03.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/academic/awesome-datascience/",
      "title": "Awesome Datascience",
      "_slug": "academic/awesome-datascience/",
      "_filepath": "/content/academic/awesome-datascience/README.md",
      "url": "https://www.trackawesomelist.com/academic/awesome-datascience/",
      "summary": "1 awesome projects updated",
      "content_text": "\n\n### Datasets / Book Deals (Affiliated)\n\n*   [The Humanitarian Data Exchange](https://data.humdata.org/)",
      "content_html": "<h3><p>Datasets / Book Deals (Affiliated)</p>\n</h3><ul>\n<li><a href=\"https://data.humdata.org/\" rel=\"noopener noreferrer\">The Humanitarian Data Exchange</a></li>\n</ul>\n",
      "date_published": "2023-11-03T12:09:02.000Z",
      "date_modified": "2023-11-03T12:09:02.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/avelino/awesome-go/",
      "title": "Awesome Go",
      "_slug": "avelino/awesome-go/",
      "_filepath": "/content/avelino/awesome-go/README.md",
      "url": "https://www.trackawesomelist.com/avelino/awesome-go/",
      "summary": "2 awesome projects updated",
      "content_text": "\n\n### Forms\n\n*   [checker (‚≠ê43)](https://github.com/cinar/checker) - Checker helps validating user input through rules defined in struct tags or directly through functions.\n\n### Server Applications\n\n*   [etcd (‚≠ê50k)](https://github.com/etcd-io/etcd) - Highly-available key value store for shared configuration and service discovery.",
      "content_html": "<h3><p>Forms</p>\n</h3><ul>\n<li><a href=\"https://github.com/cinar/checker\" rel=\"noopener noreferrer\">checker (‚≠ê43)</a> - Checker helps validating user input through rules defined in struct tags or directly through functions.</li>\n</ul>\n<h3><p>Server Applications</p>\n</h3><ul>\n<li><a href=\"https://github.com/etcd-io/etcd\" rel=\"noopener noreferrer\">etcd (‚≠ê50k)</a> - Highly-available key value store for shared configuration and service discovery.</li>\n</ul>\n",
      "date_published": "2023-11-03T11:42:48.000Z",
      "date_modified": "2023-11-03T11:49:40.000Z"
    },
    {
      "id": "https://www.trackawesomelist.com/fffaraz/awesome-cpp/",
      "title": "Awesome Cpp",
      "_slug": "fffaraz/awesome-cpp/",
      "_filepath": "/content/fffaraz/awesome-cpp/README.md",
      "url": "https://www.trackawesomelist.com/fffaraz/awesome-cpp/",
      "summary": "2 awesome projects updated",
      "content_text": "\n\n### Compression\n\n*   [zlib-ng (‚≠ê1.8k)](https://github.com/zlib-ng/zlib-ng) - zlib for the \"next generation\" systems. Drop-In replacement with some serious optimizations. \\[zlib]\n\n### Articles\n\n*   [CppCon 2023 Presentation Materials (‚≠ê317)](https://github.com/CppCon/CppCon2023) - CppCon 2023 Presentation Materials.\n*   [CppCon 2022 Presentation Materials (‚≠ê543)](https://github.com/CppCon/CppCon2022) - CppCon 2022 Presentation Materials.\n*   [CppCon 2021 Presentation Materials (‚≠ê108)](https://github.com/CppCon/CppCon2021) - CppCon 2021 Presentation Materials.\n*   [C++Now 2023 Presentations (‚≠ê87)](https://github.com/boostcon/cppnow_presentations_2023) - Presentation materials presented at C++Now 2023.\n*   [C++Now 2022 Presentations (‚≠ê1)](https://github.com/boostcon/cppnow_presentations_2022) - Presentation materials presented at C++Now 2022.\n*   [C++Now 2021 Presentations (‚≠ê4)](https://github.com/boostcon/cppnow_presentations_2021) - Presentation materials presented at C++Now 2021.",
      "content_html": "<h3><p>Compression</p>\n</h3><ul>\n<li><a href=\"https://github.com/zlib-ng/zlib-ng\" rel=\"noopener noreferrer\">zlib-ng (‚≠ê1.8k)</a> - zlib for the \"next generation\" systems. Drop-In replacement with some serious optimizations. [zlib]</li>\n</ul>\n<h3><p>Articles</p>\n</h3><ul>\n<li><a href=\"https://github.com/CppCon/CppCon2023\" rel=\"noopener noreferrer\">CppCon 2023 Presentation Materials (‚≠ê317)</a> - CppCon 2023 Presentation Materials.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/CppCon/CppCon2022\" rel=\"noopener noreferrer\">CppCon 2022 Presentation Materials (‚≠ê543)</a> - CppCon 2022 Presentation Materials.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/CppCon/CppCon2021\" rel=\"noopener noreferrer\">CppCon 2021 Presentation Materials (‚≠ê108)</a> - CppCon 2021 Presentation Materials.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/boostcon/cppnow_presentations_2023\" rel=\"noopener noreferrer\">C++Now 2023 Presentations (‚≠ê87)</a> - Presentation materials presented at C++Now 2023.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/boostcon/cppnow_presentations_2022\" rel=\"noopener noreferrer\">C++Now 2022 Presentations (‚≠ê1)</a> - Presentation materials presented at C++Now 2022.</li>\n</ul>\n<ul>\n<li><a href=\"https://github.com/boostcon/cppnow_presentations_2021\" rel=\"noopener noreferrer\">C++Now 2021 Presentations (‚≠ê4)</a> - Presentation materials presented at C++Now 2021.</li>\n</ul>\n",
      "date_published": "2023-11-03T02:42:38.000Z",
      "date_modified": "2023-11-03T02:44:03.000Z"
    }
  ]
}
