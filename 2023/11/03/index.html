<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Awesome List Updates on Nov 03, 2023 - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Awesome List Updates on Nov 03, 2023" />
    <meta property="og:description" content="10 awesome lists updated today." />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Awesome List Updates on Nov 03, 2023</h1>
<p>10 awesome lists updated today.</p>
<p><a href="/">üè† Home</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/search/">üîç Search</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/rss.xml">üî• Feed</a><span> ¬∑ </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">üìÆ Subscribe</a><span> ¬∑ </span><a href="https://github.com/sponsors/theowenyoung">‚ù§Ô∏è  Sponsor</a></p>
<h2><a href="https://www.trackawesomelist.com/enaqx/awesome-pentest/">1. Awesome Pentest</a></h2><h3><p>Collaboration Tools / Malware Analysis Books</p>
</h3><ul>
<li><a href="https://hexway.io/hive/" rel="noopener noreferrer">Hexway Hive</a> - Commercial collaboration, data aggregation, and reporting framework for red teams with a limited free self-hostable option.</li>
</ul>
<ul>
<li><a href="https://reconmap.com/" rel="noopener noreferrer">Reconmap</a> - Open-source collaboration platform for InfoSec professionals that streamlines the pentest process.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/unixorn/awesome-zsh-plugins/">2. Awesome Zsh Plugins</a></h2><h3><p>Themes / <a href="https://github.com/alexchmykhalo/superconsole" rel="noopener noreferrer">superconsole</a> - Windows-only</p>
</h3><ul>
<li><a href="https://github.com/wdjcodes/magpie" rel="noopener noreferrer">magpie (‚≠ê0)</a> - Minimalist theme with custom logic to display paths relative to the root of the current <code>git</code>. Includes decorators for time, current directory, username@hostname and <code>git</code> status.</li>
</ul>
<ul>
<li><a href="https://github.com/mellypop/princess" rel="noopener noreferrer">princess (‚≠ê3)</a> - Modeled after <a href="https://github.com/abhiyandhakal/abhiyan.zsh" rel="noopener noreferrer">abhiyan.zsh (‚≠ê7)</a> with perhaps a bit too much pink and arguably too few emojis. Includes decorators for current directory and <code>git</code> status.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/wsvincent/awesome-django/">3. Awesome Django</a></h2><h3><p>Python Packages / Views</p>
</h3><ul>
<li><a href="https://github.com/miguelgrinberg/python-socketio" rel="noopener noreferrer">python-socketio (‚≠ê4.2k)</a> - Python implementation of the Socket.IO_ realtime client and server. <a href="https://python-socketio.readthedocs.io/en/latest/server.html?highlight=django#creating-a-server-instance" rel="noopener noreferrer">(create Socket.io Django server instance)</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/awesome-foss/awesome-sysadmin/">4. Awesome Sysadmin</a></h2><h3><p>Software / Control Panels</p>
</h3><ul>
<li><a href="https://hestiacp.com/" rel="noopener noreferrer">HestiaCP</a> - Web server control panel (fork of VestaCP). (<a href="https://demo.hestiacp.com:8083/login/" rel="noopener noreferrer">Demo</a>, <a href="https://github.com/hestiacp/hestiacp" rel="noopener noreferrer">Source Code (‚≠ê3.9k)</a>) <code>GPL-3.0</code> <code>PHP/Shell/Other</code></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/rothgar/awesome-tmux/">5. Awesome Tmux</a></h2><h3><p>Plugins</p>
</h3><ul>
<li><a href="https://github.com/croxarens/tmux-timetrap" rel="noopener noreferrer">tmux-timetrap (‚≠ê2)</a> Keep your time tracked directly with TMUX (The plugin is just a wrapper for <a href="https://github.com/samg/timetrap" rel="noopener noreferrer">timetrap (‚≠ê1.5k)</a>)</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/filipecalegario/awesome-generative-deep-art/">6. Awesome Generative Deep Art</a></h2><h3><p>Human-AI Interaction</p>
</h3><ul>
<li>[üî•üî•üî•] <a href="https://arxiv.org/abs/2310.07127" rel="noopener noreferrer">[2310.07127] An HCI-Centric Survey and Taxonomy of Human-Generative-AI Interactions</a>: "a survey of 154 papers, providing a novel taxonomy and analysis of Human-GenAI Interactions from both human and Gen-AI perspectives".</li>
</ul>
<ul>
<li><a href="https://www.microsoft.com/en-us/research/publication/guidelines-for-human-ai-interaction/" rel="noopener noreferrer">Guidelines for Human-AI Interaction - Microsoft Research</a>: a set of "18 generally applicable design guidelines for human-AI" interaction</li>
</ul>
<h3><p>Generative AI history, timelines, maps, and definitions</p>
</h3><ul>
<li><a href="https://arxiv.org/abs/2309.07930" rel="noopener noreferrer">[2309.07930] Generative AI</a>: discusses a model-, system-, and application-level view on generative AI.</li>
</ul>
<h3><p>Ethics, Philosophical questions and Discussions about Generative AI</p>
</h3><ul>
<li><a href="https://www.scientificamerican.com/article/new-training-method-helps-ai-generalize-like-people-do/" rel="noopener noreferrer">New Training Method Helps AI Generalize like People Do - Scientific American</a></li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2310.01405" rel="noopener noreferrer">[2310.01405] Representation Engineering: A Top-Down Approach to AI Transparency</a>: "an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience"</li>
</ul>
<ul>
<li><a href="https://www.law.berkeley.edu/library/legal-research/chatgpt/" rel="noopener noreferrer">Generative AI Resources for Berkeley Law Faculty &amp; Staff - Berkeley Law</a></li>
</ul>
<ul>
<li><a href="https://www.aisnakeoil.com/p/licensing-is-neither-feasible-nor" rel="noopener noreferrer">Licensing is neither feasible nor effective for addressing AI risks</a></li>
</ul>
<ul>
<li><a href="https://www.aisnakeoil.com/p/generative-ai-companies-must-publish" rel="noopener noreferrer">Generative AI companies must publish transparency reports</a></li>
</ul>
<ul>
<li><a href="https://www.aisnakeoil.com/p/does-chatgpt-have-a-liberal-bias" rel="noopener noreferrer">Does ChatGPT have a liberal bias?</a></li>
</ul>
<ul>
<li><a href="https://link.springer.com/article/10.1007/s11127-023-01097-2" rel="noopener noreferrer">More human than human: measuring ChatGPT political bias | Public Choice</a></li>
</ul>
<ul>
<li><a href="https://www.gatesnotes.com/The-Age-of-AI-Has-Begun" rel="noopener noreferrer">The Age of AI has begun | Bill Gates</a></li>
</ul>
<h3><p>Critical Views about Generative AI</p>
</h3><ul>
<li><a href="https://docs.google.com/document/d/1PPHwa3KmoeRZwaoxjOS568aF2E-kUngOA2oI45G2Iaw/edit" rel="noopener noreferrer">AI in Education Group Meeting Notes - Google Docs</a></li>
</ul>
<ul>
<li><a href="https://docs.google.com/document/d/1RMVwzjc1o0Mi8Blw_-JUTcXv02b2WRH86vw7mi16W3U/edit#heading=h.1cykjn2vg2wx" rel="noopener noreferrer">Syllabi Policies for AI Generative Tools - Google Docs</a></li>
</ul>
<ul>
<li><a href="https://www.theguardian.com/technology/2023/nov/02/five-takeaways-uk-ai-safety-summit-bletchley-park-rishi-sunak" rel="noopener noreferrer">Five takeaways from UK‚Äôs AI safety summit at Bletchley Park | Artificial intelligence (AI) | The Guardian</a></li>
</ul>
<ul>
<li><a href="https://www.gov.uk/government/publications/frontier-ai-capabilities-and-risks-discussion-paper" rel="noopener noreferrer">Frontier AI: capabilities and risks ‚Äì discussion paper - GOV.UK</a></li>
</ul>
<ul>
<li><a href="https://www.aisafetysummit.gov.uk/policy-updates/#company-policies" rel="noopener noreferrer">AI Safety Summit Policy Updates | AISS 2023</a></li>
</ul>
<h3><p>Courses and Educational Materials</p>
</h3><ul>
<li><a href="https://animatedai.github.io/" rel="noopener noreferrer">Animated AI</a>: animations and instructional videos about neural networks</li>
</ul>
<ul>
<li><a href="https://www.deeplearning.ai/courses/generative-ai-with-llms/" rel="noopener noreferrer">Deep Learning AI - Learn the fundamentals of generative AI for real-world applications</a>: created in partnership with AWS, this course presents the fundamentals of how generative AI works and how to deploy it in real-world applications.</li>
</ul>
<ul>
<li><a href="https://www.cloudskillsboost.google/course_templates/536" rel="noopener noreferrer">Google Cloud Skills Boost - Introduction to Generative AI</a>: an introductory level microlearning course covering Google Tools aimed at explaining what Generative AI is, how it is used, and how it differs from traditional machine learning methods.</li>
</ul>
<ul>
<li><a href="https://www.cloudskillsboost.google/journeys/118" rel="noopener noreferrer">Google Cloud Skills Boost: Generative AI learning path</a>: curated content on Generative AI "from the fundamentals of Large Language Models to how to create and deploy generative AI solutions on Google Cloud"</li>
</ul>
<ul>
<li><a href="https://industrialdesign.ai/" rel="noopener noreferrer">AI for Industrial Design</a>: "students at the National University of Singapore explore AI‚Äôs capability for design in a semester course and share what they learned. Directed by Donn Koh at the Division of Industrial Design, NUS."</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://github.com/dair-ai" rel="noopener noreferrer">DAIR.AI</a>: Democratizing Artificial Intelligence Research, Education, and Technologies</li>
</ul>
<ul>
<li><a href="https://huggingface.co/deep-rl-course/unit0/introduction?fw=pt" rel="noopener noreferrer">Welcome to the ü§ó Deep Reinforcement Learning Course</a>: a Hugging Face Course on Deep Reinforcement Learning</li>
</ul>
<ul>
<li><a href="https://prompthero.com/academy" rel="noopener noreferrer">Crash course in AI art generation by PromptHero</a>: paid ($99) course focused on prompt engineering</li>
</ul>
<ul>
<li><a href="https://www.tiktok.com/@ham_made_art/video/7154863972729113899" rel="noopener noreferrer">Visual intuition for diffusion models and AI art. #stablediffusionart #aiart #aiartwork #aiartcommunity</a></li>
</ul>
<ul>
<li><a href="https://jalammar.github.io/illustrated-stable-diffusion/" rel="noopener noreferrer">The Illustrated Stable Diffusion by Jay Alammar</a>: "gentle introduction [on] how Stable Diffusion works"</li>
</ul>
<ul>
<li>[üî•]<a href="https://github.com/johnowhitaker/tglcourse" rel="noopener noreferrer">johnowhitaker/tglcourse (‚≠ê145)</a>: The Generative Landscape - a course on generative modelling (currently unfinished)</li>
</ul>
<ul>
<li><a href="https://www.bustbright.com/product/words-are-images-7-week-online-class-starting-october-24th-2022-/331" rel="noopener noreferrer">Words are Images | BustBright - Machine Learning Art</a>: 7-week Online class starting October 24th, 2022 by <a href="https://twitter.com/dvsch/" rel="noopener noreferrer">Derrick Schultz</a></li>
</ul>
<ul>
<li><a href="https://colab.research.google.com/drive/1dlgggNa5Mz8sEAGU0wFCHhGLFooW_pf1?usp=sharing" rel="noopener noreferrer">Grokking Stable Diffusion.ipynb - Colaboratory - Part 1</a>: notebook by <a href="https://twitter.com/johnowhitaker" rel="noopener noreferrer">@johnowhitaker</a> exploring Stable Diffusion details</li>
</ul>
<ul>
<li><a href="https://colab.research.google.com/drive/1RTHDzE-otzmZOuy8w1WEOxmn9pNcEz3u?usp=sharing" rel="noopener noreferrer">Grokking Stable Diffusion: Textual Inversion.ipynb - Colaboratory - Part 2</a>: sequel to Grokking Stable Diffusion by <a href="https://twitter.com/johnowhitaker" rel="noopener noreferrer">@johnowhitaker</a> that focus on Text Inversion</li>
</ul>
<ul>
<li><a href="https://github.com/johnowhitaker/aiaiart" rel="noopener noreferrer">GitHub - johnowhitaker/aiaiart (‚≠ê570)</a>: Course content and resources for the AIAIART course</li>
</ul>
<ul>
<li><a href="https://twitter.com/labmlai/status/1571080112459878401" rel="noopener noreferrer">Implementation/tutorial of stable diffusion with side-by-side notes by labml.ai | Twitter</a></li>
</ul>
<ul>
<li><a href="https://www.youtube.com/watch?v=_7rMfsA24Ls&amp;list=PLfYUBJiXbdtRUvTUYpLdfHHp9a58nWVXP" rel="noopener noreferrer">Practical Deep Learning for Coders 2023 - Part II</a>: continuation of the course focusing on the implementation of Stable Diffusion from scratch.</li>
</ul>
<ul>
<li><a href="https://www.youtube.com/playlist?list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU" rel="noopener noreferrer">Practical Deep Learning for Coders 2022 - Part I</a>: "free course designed for people with some coding experience who want to learn how to apply deep learning and machine learning to practical problems" by Jeremy Howard</li>
</ul>
<h3><p>Prompt Engineering</p>
</h3><ul>
<li>[üî•üî•üî•] <a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/" rel="noopener noreferrer">ChatGPT Prompt Engineering for Developers - DeepLearning.AI</a>: short course taught by Isa Fulford (OpenAI) and Andrew Ng (DeepLearning.AI) that provide best practices for prompt engineering</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://learnprompting.org/" rel="noopener noreferrer">Learn Prompting</a>: series of lessons of prompt engineering</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/" rel="noopener noreferrer">Prompt Engineering | Lil'Log</a>: prompt engineering learning notes by Lilian Weng</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://www.promptingguide.ai/" rel="noopener noreferrer">Prompt Engineering Guide</a>: a project by DAIR.AI that intends to educate researchers and practitioners about prompt engineering</li>
</ul>
<ul>
<li><a href="https://fedhoneypot.notion.site/25fdbdb69e9e44c6877d79e18336fe05?v=1d2bf4143680451986fd2836a04afbf4" rel="noopener noreferrer">the Book</a>: collection of prompts and hints of prompt engineering</li>
</ul>
<ul>
<li><a href="https://github.com/dair-ai/Prompt-Engineering-Guide" rel="noopener noreferrer">dair-ai/Prompt-Engineering-Guide (‚≠ê59k)</a>: Guide and resources for prompt engineering</li>
</ul>
<h3><p>Papers Collection</p>
</h3><ul>
<li><a href="https://github.com/dair-ai/ML-Papers-Explained" rel="noopener noreferrer">dair-ai/ML-Papers-Explained (‚≠ê8k)</a>: Explanation to key concepts in ML</li>
</ul>
<ul>
<li><a href="https://docs.google.com/document/d/1bEQM1W-1fzSVWNbS4ne5PopB2b7j8zD4Jc3nm4rbK-U/edit" rel="noopener noreferrer">AI Reading List - Google Docs</a>: reading list organized by <a href="https://twitter.com/JackSoslow" rel="noopener noreferrer">Jack Soslow (@JackSoslow)</a></li>
</ul>
<ul>
<li><a href="https://aman.ai/papers/" rel="noopener noreferrer">Aman's AI Journal ‚Ä¢ Papers List</a>: set of seminal AI/ML papers curated by Aman Chadha</li>
</ul>
<ul>
<li><a href="https://casualgan.notion.site/casualgan/Casual-GAN-Papers-Reading-Club-327c158518e44d5296a5def74486c7e8" rel="noopener noreferrer">Casual GAN Papers Reading Club</a>: Community knowledge base for Casual GAN Papers</li>
</ul>
<ul>
<li><a href="https://www.casualganpapers.com/" rel="noopener noreferrer">Casual GAN Papers</a>: Easy to read summaries of popular AI papers</li>
</ul>
<ul>
<li><a href="https://ljvmiranda921.github.io/notebook/2021/08/08/clip-vqgan/" rel="noopener noreferrer">The Illustrated VQGAN</a>: illustrated explanation on how VQGAN works</li>
</ul>
<ul>
<li><a href="https://openai.com/blog/clip/" rel="noopener noreferrer">CLIP: Connecting Text and Images</a>: OpenAI's explanation on how CLIP works</li>
</ul>
<ul>
<li><a href="https://alexasteinbruck.medium.com/vqgan-clip-how-does-it-work-210a5dca5e52" rel="noopener noreferrer">VQGAN+CLIP ‚Äî How does it work?. The synthetic imagery (‚ÄúGAN Art‚Äù) scene‚Ä¶ | by Alexa Steinbr√ºck | Medium</a></li>
</ul>
<ul>
<li><a href="https://paperswithcode.com/methods" rel="noopener noreferrer">The Methods Corpus | Papers With Code</a></li>
</ul>
<ul>
<li><a href="https://ieeexplore.ieee.org/abstract/document/9043519" rel="noopener noreferrer">https://ieeexplore.ieee.org/abstract/document/9043519</a>: A State-of-the-Art Review on Image Synthesis With Generative Adversarial Networks</li>
</ul>
<ul>
<li><a href="https://www.cin.ufpe.br/~tg/2020-1/TG_CC/tg_cco2.pdf" rel="noopener noreferrer">Utilizando redes advers√°rias generativas (GANs) como agente de apoio √† inspira√ß√£o para artistas</a>: Trabalho de Gradua√ß√£o de Cl√°udio Carvalho no Centro de Inform√°tica - UFPE</li>
</ul>
<ul>
<li><a href="https://poloclub.github.io/ganlab/" rel="noopener noreferrer">GAN Lab</a>: Play with Generative Adversarial Networks in Your Browser!</li>
</ul>
<ul>
<li><a href="https://www.semanticscholar.org/paper/Music2Video%3A-Automatic-Generation-of-Music-Video-of-Jang-Shin/38e37c3a7dc22bb3356552e93e6685b99ca04264" rel="noopener noreferrer">[PDF] Music2Video: Automatic Generation of Music Video with fusion of audio and text | Semantic Scholar</a></li>
</ul>
<ul>
<li><a href="https://www.semanticscholar.org/paper/Active-Divergence-with-Generative-Deep-Learning-A-Broad-Berns/091c4ea2efaba23cd9024d8a063609c9a313b5cb" rel="noopener noreferrer">[PDF] Active Divergence with Generative Deep Learning - A Survey and Taxonomy | Semantic Scholar</a></li>
</ul>
<ul>
<li><a href="https://www.semanticscholar.org/paper/Automating-Generative-Deep-Learning-for-Artistic-Berns-Broad/f3479740d4ec7f91b6d7a01167e9c875a72d386e" rel="noopener noreferrer">[PDF] Automating Generative Deep Learning for Artistic Purposes: Challenges and Opportunities | Semantic Scholar</a></li>
</ul>
<h3><p>Online Tools and Applications</p>
</h3><ul>
<li><a href="https://www.usetailor.com" rel="noopener noreferrer">Tailor</a>: Get a daily podcast and newsletter, created for you by an AI</li>
</ul>
<ul>
<li><a href="https://paintbytext.chat/" rel="noopener noreferrer">Paint by Text</a>: Edit your photos using written instructions, with the help of an AI.</li>
</ul>
<ul>
<li><a href="https://www.scenario.gg/" rel="noopener noreferrer">Scenario AI</a>: AI-generated game assets</li>
</ul>
<ul>
<li><a href="https://animalai.co/" rel="noopener noreferrer">AnimalAI</a>: custom AI-generated animal portraits (profits are directed to various wildlife conservation organizations)</li>
</ul>
<ul>
<li><a href="https://www.starryai.com/" rel="noopener noreferrer">starryai</a>: AI Art Generator App - AI Art Maker</li>
</ul>
<ul>
<li><a href="https://www.prosepainter.com/" rel="noopener noreferrer">ProsePainter</a>: an interactive tool to "paint with words." It incorporates guidable text-to-image generation into a traditional digital painting interface</li>
</ul>
<ul>
<li><a href="https://www.youtube.com/watch?v=mK4F32xNrdw&amp;t=429s" rel="noopener noreferrer">ProsePainter: Image + Sketching Interface + CLIP! - YouTube</a></li>
</ul>
<ul>
<li><a href="https://cocreator.ai/" rel="noopener noreferrer">Cocreator AI</a>: creative computer agent (in wait list)</li>
</ul>
<ul>
<li><a href="http://runwayml.com/" rel="noopener noreferrer">Runway ML</a>: AI video creation suite</li>
</ul>
<ul>
<li><a href="https://hotpot.ai/" rel="noopener noreferrer">Hotpot.ai - Hotpot.ai</a>: set of AI Tools to post-process images</li>
</ul>
<ul>
<li><a href="https://www.justinpinkney.com/toonify-yourself/" rel="noopener noreferrer">Toonify yourself by Justin Pinkney</a>: turn a human face into a cartoon</li>
</ul>
<ul>
<li><a href="https://deepart.io/" rel="noopener noreferrer">deepart.io</a>: a online tool for applying style transfer</li>
</ul>
<ul>
<li><a href="https://www.artbreeder.com/" rel="noopener noreferrer">Artbreeder</a>: web-based tool to generate images by breeding existing images</li>
</ul>
<ul>
<li><a href="https://www.ostagram.me/" rel="noopener noreferrer">Ostagram.ru</a>: image style transfer plataform</li>
</ul>
<ul>
<li><a href="https://cleanup.pictures/" rel="noopener noreferrer">cleanup.pictures</a>: remove objects, people, text and defects from any picture for free</li>
</ul>
<ul>
<li><a href="https://www.remove.bg/" rel="noopener noreferrer">remove.bg</a>: remove background from images</li>
</ul>
<ul>
<li><a href="https://quickdraw.withgoogle.com/" rel="noopener noreferrer">Quick, Draw!</a>: can a neural network learn to recognize doodling? A game to help NL by adding users drawing</li>
</ul>
<ul>
<li><a href="https://nekton.ai/" rel="noopener noreferrer">Nekton.ai</a>: automate your workflows with AI</li>
</ul>
<h3><p>Large Language Models (LLMs)</p>
</h3><ul>
<li><a href="https://github.com/cpacker/MemGPT" rel="noopener noreferrer">cpacker/MemGPT (‚≠ê17k)</a>: teaching LLMs memory management for unbounded context <a href="https://memgpt.ai/" rel="noopener noreferrer">[demo page]</a> <a href="https://arxiv.org/abs/2310.08560" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2307.10169" rel="noopener noreferrer">[2307.10169] Challenges and Applications of Large Language Models</a>: a systematic set of open problems and application successes of LLM area</li>
</ul>
<ul>
<li><a href="https://cookbook.openai.com/articles/related_resources" rel="noopener noreferrer">Related resources from around the web | OpenAI Cookbook</a>: tools and papers for improving outputs from GPT</li>
</ul>
<h3><p>Prompt Engineering / Prompt Engineering for Text-to-text</p>
</h3><ul>
<li>[üî•] <a href="https://arxiv.org/abs/2307.11760" rel="noopener noreferrer">[2307.11760] Large Language Models Understand and Can be Enhanced by Emotional Stimuli</a></li>
</ul>
<ul>
<li>[üî•] <a href="https://arxiv.org/abs/2305.13252" rel="noopener noreferrer">[2305.13252] "According to ..." Prompting Language Models Improves Quoting from Pre-Training Data</a></li>
</ul>
<ul>
<li><a href="https://github.com/timqian/openprompt.co" rel="noopener noreferrer">timqian/openprompt.co (‚≠ê1.2k)</a>: Create. Use. Share. ChatGPT prompts</li>
</ul>
<ul>
<li><a href="https://medium.datadriveninvestor.com/60-chatgpt-prompts-for-data-science-tried-tested-and-rated-4994c7e6adb2" rel="noopener noreferrer">60 ChatGPT Prompts for Data Science (Tried, Tested, and Rated)</a>: post by Travis Tang from DataDrivenInvestor</li>
</ul>
<ul>
<li><a href="https://github.com/f/awesome-chatgpt-prompts" rel="noopener noreferrer">f/awesome-chatgpt-prompts (‚≠ê130k)</a>: this repo includes ChatGPT prompt curation to use ChatGPT better</li>
</ul>
<ul>
<li><a href="https://github.com/brexhq/prompt-engineering" rel="noopener noreferrer">brexhq/prompt-engineering (‚≠ê9.2k)</a>: "Tips and tricks for working with Large Language Models like OpenAI's GPT-4"</li>
</ul>
<ul>
<li><a href="https://zapier.com/blog/gpt-3-prompt/" rel="noopener noreferrer">How to write an effective GPT-3 prompt | Zapier</a>: a list of 6 GPT-3 tips for getting the desired output</li>
</ul>
<ul>
<li><a href="https://fka.gumroad.com/l/art-of-chatgpt-prompting" rel="noopener noreferrer">The Art of ChatGPT Prompting: A Guide to Crafting Clear and Effective Prompts</a>: e-book by Fatih Kadir Akƒ±n (<a href="http://twitter.com/fkadev" rel="noopener noreferrer">@fkadev</a>)</li>
</ul>
<h3><p>Autonomous LLM Agents / Multi-agents</p>
</h3><ul>
<li><a href="https://arxiv.org/abs/2307.05300" rel="noopener noreferrer">[2307.05300] Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration</a></li>
</ul>
<ul>
<li><a href="https://github.com/OpenBMB/ChatDev" rel="noopener noreferrer">OpenBMB/ChatDev (‚≠ê27k)</a>: create customized software using natural language idea (through llm-powered multi-agent collaboration)</li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2308.07201" rel="noopener noreferrer">[2308.07201] ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate</a></li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2308.10848" rel="noopener noreferrer">[2308.10848] AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors</a></li>
</ul>
<h3><p>Prompt Engineering / Prompt Engineering for Text-to-image</p>
</h3><ul>
<li><a href="https://app.usp.ai/static/Stable%20Diffusion%202.1%20Prompt%20Book%20by%20USP.ai.pdf" rel="noopener noreferrer">USP AI Prompt Book</a>: Stable Diffusion v2.1 Prompt Book</li>
</ul>
<ul>
<li><a href="https://github.com/daspartho/prompt-extend" rel="noopener noreferrer">daspartho/prompt-extend (‚≠ê176)</a>: extending stable diffusion prompts with suitable style cues using text generation</li>
</ul>
<ul>
<li><a href="https://www.promptbox.ai/" rel="noopener noreferrer">Prompt Box</a>: "organize and save your AI prompts"</li>
</ul>
<ul>
<li><a href="https://docs.google.com/spreadsheets/d/1e2MZ1K6WMTUuxlPAQ_2A0rz-H55NBykb66TY7DuerVg/edit#gid=2088669480" rel="noopener noreferrer">Midjourney artist reference - Google Sheets</a></li>
</ul>
<ul>
<li><a href="https://stability.ai/sdv2-prompt-book" rel="noopener noreferrer">Stable Diffusion Prompt Book ‚Äî Stability.Ai</a>: prompt book for Stable Diffusion v2.0 and v2.1 released by Stability.AI</li>
</ul>
<ul>
<li><a href="https://prompthero.com/stable-diffusion-prompt-guide" rel="noopener noreferrer">The Ultimate Stable Diffusion Prompt Guide by PromptHero</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/spaces/pharma/CLIP-Interrogator" rel="noopener noreferrer">CLIP Interrogator - a Hugging Face Space by pharma</a>: image-to-text tool to figure out what a good prompt might be to create new images like an existing one</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://docs.google.com/presentation/d/1V8d6TIlKqB1j5xPFH7cCmgKOV_fMs4Cb4dwgjD5GIsg/edit#slide=id.g1834b964b0f_3_4" rel="noopener noreferrer">Prompt book for data lovers II - Google Slides</a>: An open source exploration on text-to-image and data visualization</li>
</ul>
<ul>
<li><a href="https://github.com/some9000/StylePile" rel="noopener noreferrer">some9000/StylePile (‚≠ê580)</a>: A helper script for AUTOMATIC1111/stable-diffusion-webui. Basically a mix and match to quickly get different results without wasting a lot of time writing prompts.</li>
</ul>
<ul>
<li><a href="https://artiststostudy.pages.dev/" rel="noopener noreferrer">Artists To Study | All images generated with Google Colab TPUs + CompVis/stable-diffusion-v1-4 + Huggingface Diffusers</a>: a systematic study of artists' styles made by <a href="https://twitter.com/camenduru" rel="noopener noreferrer">@camenduru</a></li>
</ul>
<ul>
<li><a href="https://www.reddit.com/r/PromptDesign/" rel="noopener noreferrer">PromptDesign | Reddit</a>: Reddit community for "the art of communicating with natural language models"</li>
</ul>
<ul>
<li><a href="https://www.inovex.de/de/blog/prompt-engineering-guide/" rel="noopener noreferrer">Prompt Engineering and Zero-Shot/Few-Shot Learning [Guide] - inovex GmbH</a>: prompt engineering for text generation</li>
</ul>
<ul>
<li><a href="https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb#scrollTo=rbDEMDGJrJEo" rel="noopener noreferrer">clip-interrogator.ipynb - Colaboratory</a>: a tool for image-to-prompt</li>
</ul>
<ul>
<li><a href="https://www.reddit.com/r/StableDiffusion/comments/xcrm4d/useful_prompt_engineering_tools_and_resources/" rel="noopener noreferrer">Useful Prompt Engineering tools and resources | Reddit</a></li>
</ul>
<ul>
<li><a href="https://prompthero.com/" rel="noopener noreferrer">PromptHero</a>: Search the best prompts for Stable Diffusion, DALL-E and Midjourney</li>
</ul>
<ul>
<li><a href="https://promptomania.com/" rel="noopener noreferrer">promptoMANIA</a>: AI art community with prompt generator</li>
</ul>
<ul>
<li><a href="https://lexica.art/" rel="noopener noreferrer">Lexica</a>: search over 10M+ Stable Diffusion images and prompts</li>
</ul>
<ul>
<li><a href="https://rentry.org/artists_sd-v1-4" rel="noopener noreferrer">list of artists for SD v1.4 A-C / D-I / J-N / O-Z</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/succinctly/text2image-prompt-generator" rel="noopener noreferrer">succinctly/text2image-prompt-generator ¬∑ Hugging Face</a>: a GPT-2 model fine-tuned on the succinctly/midjourney-prompts dataset, which contains 250k text prompts that users issued to the Midjourney text-to-image service over a month period</li>
</ul>
<ul>
<li><a href="https://theprompter.substack.com/" rel="noopener noreferrer">The Prompter | vicc | Substack</a>: a newsletter about news, tips and thoughts around prompt engineering</li>
</ul>
<ul>
<li><a href="https://twitter.com/HeyNikhila/status/1570005481896255490" rel="noopener noreferrer">(19) Nikhil Agrawal üìå on Twitter</a>: 11 AI Images Prompt websites to level up the image quality</li>
</ul>
<ul>
<li><a href="https://phraser.tech/" rel="noopener noreferrer">Phraser</a>: a tool that support prompt creation</li>
</ul>
<ul>
<li><a href="https://promptbase.com/" rel="noopener noreferrer">PromptBase | Prompt Marketplace</a>: PromptBase is a marketplace for DALL¬∑E, Midjourney &amp; GPT-3 prompts, where people can sell prompts and make money from their prompt crafting skills.</li>
</ul>
<ul>
<li><a href="https://www.theverge.com/2022/9/2/23326868/dalle-midjourney-ai-promptbase-prompt-market-sales-artist-interview" rel="noopener noreferrer">Professional AI whisperers have launched a marketplace for DALL-E prompts - The Verge</a></li>
</ul>
<ul>
<li><a href="https://tools.saxifrage.xyz/prompt" rel="noopener noreferrer">Visual Prompt Builder</a>: simple deck of illustrated card to combine modifiers for prompt building</li>
</ul>
<ul>
<li><a href="https://docs.google.com/spreadsheets/d/1-snKDn38-KypoYCk9XLPg799bHcNFSBAVu2HVvFEAkA/edit#gid=0" rel="noopener noreferrer">Prompt Engineering Template - Google Sheets</a>: spreadsheet with lists of modifiers for prompt building and a lot of interesting links for reference</li>
</ul>
<ul>
<li><a href="https://www.saxifrage.xyz/post/prompt-engineering" rel="noopener noreferrer">Prompt Engineering: From Words to Art - Saxifrage Blog</a></li>
</ul>
<ul>
<li><a href="https://dallery.gallery/prompt-resources-tools-ai-art/" rel="noopener noreferrer">DALL¬∑Ery GALL¬∑Ery Resources</a>: DALL¬∑E 2 and AI art prompt resources &amp; tools to inspire beautiful images</li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2204.13988" rel="noopener noreferrer">[2204.13988] A Taxonomy of Prompt Modifiers for Text-To-Image Generation</a></li>
</ul>
<ul>
<li><a href="https://aesthetics.fandom.com/wiki/List_of_Aesthetics" rel="noopener noreferrer">List of Aesthetics | Aesthetics Wiki | Fandom</a></li>
</ul>
<ul>
<li><a href="https://aiartcreation.fandom.com/wiki/Artist_Directory_(Volcano_Comparison)" rel="noopener noreferrer">Artist Directory (Volcano Comparison) | AI Art Creation Wiki | Fandom</a></li>
</ul>
<ul>
<li><a href="https://dallery.gallery/the-dalle-2-prompt-book/" rel="noopener noreferrer">The DALL¬∑E 2 Prompt Book ‚Äì DALL¬∑Ery GALL¬∑Ery</a></li>
</ul>
<ul>
<li><a href="https://dallery.gallery/" rel="noopener noreferrer">DALL¬∑Ery GALL¬∑Ery</a>: A guide to OpenAI's DALL¬∑E ‚Äì prompts, projects, examples, and tips</li>
</ul>
<ul>
<li><a href="https://www.reddit.com/user/haaaaven/comments/w05f56/massive_dalle_2_anime_keywords_modifiers_list/" rel="noopener noreferrer">(2) MASSIVE üí• DALL-E 2 ANIME ‚ö°Ô∏é KEYWORDS + MODIFIERS LIST ‚òÖ : haaaaven</a>: image prompt modifier collection by haaaaven</li>
</ul>
<ul>
<li><a href="https://docs.google.com/spreadsheets/d/1y7nAbmR4FREi6npB1u-Bo3GFdwdOPYJc617rBOxIRHY/edit#gid=0" rel="noopener noreferrer">DrawBench</a>: a list of prompts the Google Imagen is organizing as a benchmark</li>
</ul>
<ul>
<li><a href="https://matthewmcateer.me/blog/clip-prompt-engineering/" rel="noopener noreferrer">CLIP Prompt Engineering for Generative Art - matthewmcateer.me</a>: list of styles tested with Quick CLIP Guided Diffusion</li>
</ul>
<ul>
<li><a href="https://interconnected.org/home/2022/06/02/dalle" rel="noopener noreferrer">Adobe should make a boring app for prompt engineers (Interconnected)</a></li>
</ul>
<ul>
<li><a href="https://arxiv.org/abs/2206.00169" rel="noopener noreferrer">[2206.00169] Discovering the Hidden Vocabulary of DALLE-2</a></li>
</ul>
<ul>
<li><a href="https://www.reddit.com/r/StableDiffusion/comments/xgwcab/when_sd_just_doesnt_understand_the_prompt_no/" rel="noopener noreferrer">When SD just doesn't understand the prompt no matter how hard I try | Reddit</a></li>
</ul>
<ul>
<li><a href="https://www.reddit.com/r/StableDiffusion/comments/xgplii/its_very_interesting_how_some_prompts_have_very/" rel="noopener noreferrer">It's very interesting how some prompts have very defined output but other specific ones are not | Reddit</a></li>
</ul>
<h3><p>Multimodal Embedding Space / Deforum</p>
</h3><ul>
<li><a href="https://rom1504.github.io/clip-retrieval/?back=https%3A%2F%2Fknn5.laion.ai&amp;index=laion5B&amp;useMclip=false" rel="noopener noreferrer">CLIP retrieval for laion5B</a>: CLIP retrieval using Laion5B. "It works by converting the text query to a CLIP embedding , then using that embedding to query a knn index of clip image embedddings".</li>
</ul>
<ul>
<li><a href="https://github.com/rom1504/clip-retrieval" rel="noopener noreferrer">rom1504/clip-retrieval (‚≠ê2.6k)</a>: Easily compute CLIP embeddings and build a CLIP retrieval system with them</li>
</ul>
<ul>
<li><a href="https://segment-anything.com/" rel="noopener noreferrer">Segment Anything | Meta AI</a>: "a new AI model from Meta AI that can "cut out" any object, in any image, with a single click"</li>
</ul>
<ul>
<li><a href="https://twitter.com/mervenoyann/status/1720126908384366649" rel="noopener noreferrer">Microsoft KOSMOS-2</a>: new capabilities of perceiving object descriptions (e.g., bounding boxes) and grounding text to the visual world <a href="https://huggingface.co/spaces/ydshieh/Kosmos-2" rel="noopener noreferrer">[HF demo]</a> <a href="https://arxiv.org/abs/2306.14824" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<ul>
<li><a href="https://github.com/facebookresearch/ImageBind" rel="noopener noreferrer">facebookresearch/ImageBind (‚≠ê8.7k)</a>: ImageBind One Embedding Space to Bind Them All</li>
</ul>
<ul>
<li><a href="https://together.ai/blog/redpajama-data-v2" rel="noopener noreferrer">RedPajama-Data-v2 by Together AI</a>: an open dataset with 30 trillion tokens for training Large Language Models</li>
</ul>
<ul>
<li><a href="https://haveibeentrained.com/" rel="noopener noreferrer">Have I Been Trained?</a>: tool for searching 5.8 billion images used to train popular AI art models</li>
</ul>
<ul>
<li><a href="https://laion-aesthetic.datasette.io/laion-aesthetic-6pls/images" rel="noopener noreferrer">laion-aesthetic-6pls</a>: exploring 12 million of the 2.3 billion images used to train Stable Diffusion's image generator</li>
</ul>
<ul>
<li><a href="https://laion.ai/" rel="noopener noreferrer">LAION</a>: Large-scale Artificial Intelligence Open Network</li>
</ul>
<h3><p>Retrieval-Augmented Generation (RAG) / Prompt Engineering for Text-to-image</p>
</h3><ul>
<li><a href="https://www.pinecone.io/learn/series/rag/rerankers/" rel="noopener noreferrer">Rerankers and Two-Stage Retrieval | Pinecone</a></li>
</ul>
<ul>
<li><a href="https://www.pinecone.io/learn/series/rag/" rel="noopener noreferrer">Retrieval Augmented Generation | Pinecone</a></li>
</ul>
<ul>
<li><a href="https://github.com/dssjon/biblos" rel="noopener noreferrer">dssjon/biblos: biblos.app (‚≠ê212)</a>: example of RAG architecture using semantic search and summarization for retrieving Bible passages</li>
</ul>
<h3><p>Embeddings and Semantic Search / Prompt Engineering for Text-to-image</p>
</h3><ul>
<li><a href="https://github.com/neuml/txtai" rel="noopener noreferrer">neuml/txtai (‚≠ê11k)</a>: semantic search and workflows powered by language models</li>
</ul>
<ul>
<li><a href="https://github.com/facebookresearch/faiss" rel="noopener noreferrer">facebookresearch/faiss (‚≠ê36k)</a>: A library for efficient similarity search and clustering of dense vectors</li>
</ul>
<ul>
<li><a href="https://betterprogramming.pub/how-to-give-your-chatbot-the-power-of-neural-search-with-openai-ebcff5194170" rel="noopener noreferrer">Optimize Your Chatbot‚Äôs Conversational Intelligence Using GPT-3 | by Amogh Agastya | Better Programming</a>: tutorial presenting semantic search concepts</li>
</ul>
<ul>
<li><a href="https://txt.cohere.ai/what-is-semantic-search/" rel="noopener noreferrer">What is Semantic Search?</a></li>
</ul>
<ul>
<li><a href="https://www.pinecone.io/learn/" rel="noopener noreferrer">Learning Center | Pinecone</a>: Pinecone's guides to vector embeddings</li>
</ul>
<ul>
<li><a href="https://www.kaggle.com/code/leonidkulyk/lb-0-45836-blip-clip-clip-interrogator" rel="noopener noreferrer">BLIP+CLIP | CLIP Interrogator | Kaggle</a>: a Kaggle notebook for image description and captioning (imate-to-text)</li>
</ul>
<ul>
<li><a href="https://github.com/jerryjliu/gpt_index" rel="noopener noreferrer">jerryjliu/gpt_index: GPT Index (LlamaIndex) (‚≠ê43k)</a>: a project to make it easier to use large external knowledge bases with LLMs</li>
</ul>
<ul>
<li><a href="https://llamahub.ai/" rel="noopener noreferrer">Llama Hub</a>: a repository of data loaders for LlamaIndex (GPT Index) and LangChain</li>
</ul>
<ul>
<li><a href="https://www.trychroma.com/" rel="noopener noreferrer">Chroma</a>: an open-source AI-native database that makes it easy to use embeddings</li>
</ul>
<h3><p>Autonomous LLM Agents / Prompt Engineering for Text-to-image</p>
</h3><ul>
<li><a href="https://github.com/joonspk-research/generative_agents" rel="noopener noreferrer">joonspk-research/generative_agents - Generative Agents (‚≠ê19k)</a>: code for interactive simulacra of human behavior <a href="https://arxiv.org/abs/2304.03442" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<h3><p>LLM Evaluation / Multi-agents</p>
</h3><ul>
<li><a href="https://www.airtrain.ai/" rel="noopener noreferrer">LLM Evaluation at Scale ‚Äì Airtrain</a>: no-code batch compute platform for LLM evaluation and tuning workloads</li>
</ul>
<ul>
<li><a href="https://cookbook.openai.com/examples/evaluation/how_to_eval_abstractive_summarization" rel="noopener noreferrer">How to evaluate a summarization task | OpenAI Cookbook</a></li>
</ul>
<ul>
<li><a href="https://github.com/openai/evals" rel="noopener noreferrer">openai/evals (‚≠ê17k)</a>: Evals is a framework for evaluating LLMs and LLM systems, and an open-source registry of benchmarks.</li>
</ul>
<ul>
<li><a href="https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/red-teaming-and-model-evaluations" rel="noopener noreferrer">Red teaming and model evaluations | Anthropic</a></li>
</ul>
<ul>
<li><a href="https://www.anthropic.com/index/evaluating-ai-systems" rel="noopener noreferrer">Challenges in evaluating AI systems | Anthropic</a></li>
</ul>
<ul>
<li><a href="https://www.cs.princeton.edu/~arvindn/talks/evaluating_llms_minefield/" rel="noopener noreferrer">Evaluating LLMs is a minefield</a>: talk by Princeton professor Arvind Narayanan</li>
</ul>
<h3><p>AI Engineering / Multi-agents</p>
</h3><ul>
<li><a href="https://www.askmarvin.ai/" rel="noopener noreferrer">Marvin</a>: AI engineering framework for building natural language interfaces</li>
</ul>
<ul>
<li><a href="https://jxnl.github.io/instructor/" rel="noopener noreferrer">Instructor</a>: library for structured LLM extraction in Python</li>
</ul>
<h3><p>Image Segmentation / Deforum</p>
</h3><ul>
<li><a href="https://notes.aimodels.fyi/transforming-2d-images-into-3d-with-the-adampi-ai-model/" rel="noopener noreferrer">Transforming 2D Images into 3D with the AdaMPI AI Model</a>: guide on how to use the AdaMPI AI model for creating 3D photos from 2D images</li>
</ul>
<ul>
<li><a href="https://www.ssemble.com/" rel="noopener noreferrer">Ssemble</a>: collaborative video editor with a collection of AI plugins</li>
</ul>
<ul>
<li><a href="https://twitter.com/NathanLands/status/1659195191591596033" rel="noopener noreferrer">Nathan Lands on Twitter: "AI video has started to produce mindblowing results and could eventually disrupt Hollywood / Twitter</a>: Twitter thread with examples of Generative AI tools for video</li>
</ul>
<ul>
<li><a href="https://stability.ai/blog/stable-animation-sdk" rel="noopener noreferrer">Stable Animation SDK</a>: a text-to-animation tool for developers by Stability AI <a href="https://platform.stability.ai/docs/features/animation" rel="noopener noreferrer">[dev platform]</a></li>
</ul>
<ul>
<li><a href="https://twelvelabs.io/" rel="noopener noreferrer">Twelve Labs</a>: multimodal, contextual understanding for video search</li>
</ul>
<ul>
<li><a href="https://research.nvidia.com/labs/toronto-ai/VideoLDM/" rel="noopener noreferrer">Align your Latents</a>: high-resolution video synthesis with latent diffusion models <a href="https://arxiv.org/abs/2304.08818" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<ul>
<li><a href="https://research.runwayml.com/gen2" rel="noopener noreferrer">Gen-2 by Runway</a>: "a multi-modal AI system that can generate novel videos with text, images, or video clips" <a href="https://arxiv.org/abs/2302.03011" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/CiaraRowles/TemporalNet" rel="noopener noreferrer">CiaraRowles/TemporalNet ¬∑ Hugging Face</a>: a ControlNet model designed to enhance the temporal consistency of generated outputs <a href="https://twitter.com/ciararowles1/status/1639321818581303310" rel="noopener noreferrer">[tweet]</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/spaces/video-p2p-library/Video-P2P-Demo" rel="noopener noreferrer">Video-P2P UI - a Hugging Face Space by video-p2p-library</a>: video editing with cross-attention control <a href="https://twitter.com/_akhaliq/status/1637838648463749120" rel="noopener noreferrer">[tweet]</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/spaces/PAIR/Text2Video-Zero" rel="noopener noreferrer">Text2Video-Zero - a Hugging Face Space by PAIR</a>: zero-shot text-to-video synthesis diffusion framework <a href="https://twitter.com/_akhaliq/status/1639062868850266112" rel="noopener noreferrer">[tweet]</a> <a href="https://arxiv.org/abs/2303.13439" rel="noopener noreferrer">[arxiv]</a></li>
</ul>
<ul>
<li><a href="https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis" rel="noopener noreferrer">ModelScope - a Hugging Face Space by damo-vilab</a>: text-to-video synthesis <a href="https://www.modelscope.cn/models/damo/text-to-video-synthesis/summary" rel="noopener noreferrer">[page]</a></li>
</ul>
<ul>
<li><a href="https://www.neuralframes.com/firstframe" rel="noopener noreferrer">neural frames</a>: tools for animation creation inspired on deforum</li>
</ul>
<ul>
<li>[üî•] <a href="https://github.com/dmarx/video-killed-the-radio-star" rel="noopener noreferrer">dmarx/video-killed-the-radio-star (‚≠ê210)</a>: Notebook and tools for end-to-end automation of music video production with generative AI</li>
</ul>
<ul>
<li>[üî•üî•üî•] <a href="https://phenaki.research.google/" rel="noopener noreferrer">Phenaki ‚Äì Google Research</a>: realistic video generation from open-domain textual descriptions</li>
</ul>
<ul>
<li><a href="https://github.com/THUDM/CogVideo" rel="noopener noreferrer">THUDM/CogVideo (‚≠ê12k)</a>: text-to-video generation</li>
</ul>
<ul>
<li><a href="https://github.com/baowenbo/DAIN" rel="noopener noreferrer">baowenbo/DAIN (‚≠ê8.3k)</a>: Depth-Aware Video Frame Interpolation (CVPR 2019)</li>
</ul>
<ul>
<li><a href="https://grisk.itch.io/dain-app" rel="noopener noreferrer">Dain-App 1.0 [Nvidia Only] by GRisk</a>: Depth-Aware Video Frame Interpolation (CVPR 2019)</li>
</ul>
<h3><p>Speech-to-text (STT) and spoken content analysis / Deforum</p>
</h3><ul>
<li><a href="https://github.com/facebookresearch/seamless_communication" rel="noopener noreferrer">facebookresearch/seamless_communication (‚≠ê12k)</a>: Foundational Models for State-of-the-Art Speech and Text Translation</li>
</ul>
<ul>
<li><a href="https://www.assemblyai.com/blog/lemur/" rel="noopener noreferrer">LeMUR</a>: a single API, enabling developers to reason over their spoken data with a few lines of code</li>
</ul>
<h3><p>Interesting Twitter Accounts / Deforum</p>
</h3><ul>
<li><a href="https://twitter.com/nutlope" rel="noopener noreferrer">Hassan El Mghari (@nutlope) / X</a>: the creator of <a href="https://roomgpt.io" rel="noopener noreferrer">roomgpt</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/gruhn/awesome-naming/">7. Awesome Naming</a></h2><h3><p>Programming Languages and Programming Language Theory</p>
</h3><ul>
<li><a href="https://en.wikipedia.org/wiki/Choreographic_programming" rel="noopener noreferrer">Choreographic programming</a> - A programming paradigm where programs are compositions of interactions among multiple concurrent participants.</li>
</ul>
<ul>
<li><a href="https://en.m.wikipedia.org/wiki/Garbage_collection_(computer_science)" rel="noopener noreferrer">Garbage Collector</a> - Part of a program that attempts to find and reclaim garbage pieces of memory not used anymore.</li>
</ul>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Syntactic_sugar" rel="noopener noreferrer">Syntactic sugar</a> - Syntax that makes the language "sweeter" for human use. Usually a shorthand for common operations that can also be expressed in a more verbose form.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/academic/awesome-datascience/">8. Awesome Datascience</a></h2><h3><p>Datasets / Book Deals (Affiliated)</p>
</h3><ul>
<li><a href="https://data.humdata.org/" rel="noopener noreferrer">The Humanitarian Data Exchange</a></li>
</ul>
<h2><a href="https://www.trackawesomelist.com/avelino/awesome-go/">9. Awesome Go</a></h2><h3><p>Forms</p>
</h3><ul>
<li><a href="https://github.com/cinar/checker" rel="noopener noreferrer">checker (‚≠ê43)</a> - Checker helps validating user input through rules defined in struct tags or directly through functions.</li>
</ul>
<h3><p>Server Applications</p>
</h3><ul>
<li><a href="https://github.com/etcd-io/etcd" rel="noopener noreferrer">etcd (‚≠ê50k)</a> - Highly-available key value store for shared configuration and service discovery.</li>
</ul>
<h2><a href="https://www.trackawesomelist.com/fffaraz/awesome-cpp/">10. Awesome Cpp</a></h2><h3><p>Compression</p>
</h3><ul>
<li><a href="https://github.com/zlib-ng/zlib-ng" rel="noopener noreferrer">zlib-ng (‚≠ê1.8k)</a> - zlib for the "next generation" systems. Drop-In replacement with some serious optimizations. [zlib]</li>
</ul>
<h3><p>Articles</p>
</h3><ul>
<li><a href="https://github.com/CppCon/CppCon2023" rel="noopener noreferrer">CppCon 2023 Presentation Materials (‚≠ê317)</a> - CppCon 2023 Presentation Materials.</li>
</ul>
<ul>
<li><a href="https://github.com/CppCon/CppCon2022" rel="noopener noreferrer">CppCon 2022 Presentation Materials (‚≠ê543)</a> - CppCon 2022 Presentation Materials.</li>
</ul>
<ul>
<li><a href="https://github.com/CppCon/CppCon2021" rel="noopener noreferrer">CppCon 2021 Presentation Materials (‚≠ê108)</a> - CppCon 2021 Presentation Materials.</li>
</ul>
<ul>
<li><a href="https://github.com/boostcon/cppnow_presentations_2023" rel="noopener noreferrer">C++Now 2023 Presentations (‚≠ê87)</a> - Presentation materials presented at C++Now 2023.</li>
</ul>
<ul>
<li><a href="https://github.com/boostcon/cppnow_presentations_2022" rel="noopener noreferrer">C++Now 2022 Presentations (‚≠ê1)</a> - Presentation materials presented at C++Now 2022.</li>
</ul>
<ul>
<li><a href="https://github.com/boostcon/cppnow_presentations_2021" rel="noopener noreferrer">C++Now 2021 Presentations (‚≠ê4)</a> - Presentation materials presented at C++Now 2021.</li>
</ul>
<hr><ul><li> Prev: <a href="/2023/11/04/">Nov 04, 2023</a></li><li> Next: <a href="/2023/11/02/">Nov 02, 2023</a></li></ul>
    </main>
  </body>
</html>
