<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <title>Awesome Tensorflow Lite (margaretmz/awesome-tensorflow-lite) Overview - Track Awesome List</title>
    <meta property="og:url" content="https://www.trackawesomelist.com/margaretmz/awesome-tensorflow-lite/readme/" />
    <meta property="og:type" content="summary" />
    <meta property="og:title" content="Awesome Tensorflow Lite Overview" />
    <meta property="og:description" content="An awesome list of TensorFlow Lite models, samples, tutorials, tools and learning resources." />
    <meta property="og:site_name" content="Track Awesome List" />
    <style>
      main {
        max-width: 1024px;
        margin: 0 auto;
        padding: 0 0.5em;
      }
      :root,[data-color-mode=light][data-light-theme=light],[data-color-mode=dark][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=light]{--color-canvas-default-transparent:rgba(255,255,255,0);--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-danger-fg:#cf222e}}[data-color-mode=light][data-light-theme=dark],[data-color-mode=dark][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}@media (prefers-color-scheme:light){[data-color-mode=auto][data-light-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}@media (prefers-color-scheme:dark){[data-color-mode=auto][data-dark-theme=dark]{--color-canvas-default-transparent:rgba(13,17,23,0);--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:rgba(110,118,129,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-danger-fg:#f85149}}.markdown-body{word-wrap:break-word;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5}.markdown-body:before{content:"";display:table}.markdown-body:after{clear:both;content:"";display:table}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:var(--color-danger-fg)}.markdown-body .anchor{float:left;margin-left:-20px;padding-right:4px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body p,.markdown-body blockquote,.markdown-body ul,.markdown-body ol,.markdown-body dl,.markdown-body table,.markdown-body pre,.markdown-body details{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;background-color:var(--color-border-default);border:0;margin:24px 0;padding:0}.markdown-body blockquote{color:var(--color-fg-muted);border-left:.25em solid var(--color-border-default);padding:0 1em}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 tt,.markdown-body h1 code,.markdown-body h2 tt,.markdown-body h2 code,.markdown-body h3 tt,.markdown-body h3 code,.markdown-body h4 tt,.markdown-body h4 code,.markdown-body h5 tt,.markdown-body h5 code,.markdown-body h6 tt,.markdown-body h6 code{font-size:inherit;padding:0 .2em}.markdown-body h1{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:2em}.markdown-body h2{border-bottom:1px solid var(--color-border-muted);padding-bottom:.3em;font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{color:var(--color-fg-muted);font-size:.85em}.markdown-body summary h1,.markdown-body summary h2,.markdown-body summary h3,.markdown-body summary h4,.markdown-body summary h5,.markdown-body summary h6{display:inline-block}.markdown-body summary h1 .anchor,.markdown-body summary h2 .anchor,.markdown-body summary h3 .anchor,.markdown-body summary h4 .anchor,.markdown-body summary h5 .anchor,.markdown-body summary h6 .anchor{margin-left:-40px}.markdown-body summary h1,.markdown-body summary h2{border-bottom:0;padding-bottom:0}.markdown-body ul,.markdown-body ol{padding-left:2em}.markdown-body ul.no-list,.markdown-body ol.no-list{padding:0;list-style-type:none}.markdown-body ol[type="1"]{list-style-type:decimal}.markdown-body ol[type=a]{list-style-type:lower-alpha}.markdown-body ol[type=i]{list-style-type:lower-roman}.markdown-body div>ol:not([type]){list-style-type:decimal}.markdown-body ul ul,.markdown-body ul ol,.markdown-body ol ol,.markdown-body ol ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{margin-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{margin-top:16px;padding:0;font-size:1em;font-style:italic;font-weight:600}.markdown-body dl dd{margin-bottom:16px;padding:0 16px}.markdown-body table{width:100%;width:-webkit-max-content;width:-webkit-max-content;width:max-content;max-width:100%;display:block;overflow:auto}.markdown-body table th{font-weight:600}.markdown-body table th,.markdown-body table td{border:1px solid var(--color-border-default);padding:6px 13px}.markdown-body table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}.markdown-body table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}.markdown-body table img{background-color:rgba(0,0,0,0)}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:var(--color-canvas-default)}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:rgba(0,0,0,0)}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{float:left;width:auto;border:1px solid var(--color-border-default);margin:13px 0 0;padding:7px;display:block;overflow:hidden}.markdown-body span.frame span img{float:left;display:block}.markdown-body span.frame span span{clear:both;color:var(--color-fg-default);padding:5px 0 0;display:block}.markdown-body span.align-center{clear:both;display:block;overflow:hidden}.markdown-body span.align-center>span{text-align:center;margin:13px auto 0;display:block;overflow:hidden}.markdown-body span.align-center span img{text-align:center;margin:0 auto}.markdown-body span.align-right{clear:both;display:block;overflow:hidden}.markdown-body span.align-right>span{text-align:right;margin:13px 0 0;display:block;overflow:hidden}.markdown-body span.align-right span img{text-align:right;margin:0}.markdown-body span.float-left{float:left;margin-right:13px;display:block;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{float:right;margin-left:13px;display:block;overflow:hidden}.markdown-body span.float-right>span{text-align:right;margin:13px auto 0;display:block;overflow:hidden}.markdown-body code,.markdown-body tt{background-color:var(--color-neutral-muted);border-radius:6px;margin:0;padding:.2em .4em;font-size:85%}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{-webkit-text-decoration:inherit;-webkit-text-decoration:inherit;text-decoration:inherit}.markdown-body samp{font-size:85%}.markdown-body pre{word-wrap:normal}.markdown-body pre code{font-size:100%}.markdown-body pre>code{word-break:normal;white-space:pre;background:0 0;border:0;margin:0;padding:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{word-break:normal;margin-bottom:0}.markdown-body .highlight pre,.markdown-body pre{background-color:var(--color-canvas-subtle);border-radius:6px;padding:16px;font-size:85%;line-height:1.45;overflow:auto}.markdown-body pre code,.markdown-body pre tt{max-width:auto;line-height:inherit;word-wrap:normal;background-color:rgba(0,0,0,0);border:0;margin:0;padding:0;display:inline;overflow:visible}.markdown-body .csv-data td,.markdown-body .csv-data th{text-align:left;white-space:nowrap;padding:5px;font-size:12px;line-height:1;overflow:hidden}.markdown-body .csv-data .blob-num{text-align:right;background:var(--color-canvas-default);border:0;padding:10px 8px 9px}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:600}.markdown-body [data-footnote-ref]:before{content:"["}.markdown-body [data-footnote-ref]:after{content:"]"}.markdown-body .footnotes{color:var(--color-fg-muted);border-top:1px solid var(--color-border-default);font-size:12px}.markdown-body .footnotes ol{padding-left:16px}.markdown-body .footnotes li{position:relative}.markdown-body .footnotes li:target:before{pointer-events:none;content:"";border:2px solid var(--color-accent-emphasis);border-radius:6px;position:absolute;top:-8px;bottom:-8px;left:-24px;right:-8px}.markdown-body .footnotes li:target{color:var(--color-fg-default)}.markdown-body .footnotes .data-footnote-backref g-emoji{font-family:monospace}.markdown-body{background-color:var(--color-canvas-default);color:var(--color-fg-default)}.markdown-body a{color:var(--color-accent-fg);text-decoration:none}.markdown-body a:hover{text-decoration:underline}.markdown-body iframe{background-color:#fff;border:0;margin-bottom:16px}.markdown-body svg.octicon{fill:currentColor}.markdown-body .anchor>.octicon{display:inline}.markdown-body .highlight .token.keyword,.gfm-highlight .token.keyword{color:var(--color-prettylights-syntax-keyword)}.markdown-body .highlight .token.tag .token.class-name,.markdown-body .highlight .token.tag .token.script .token.punctuation,.gfm-highlight .token.tag .token.class-name,.gfm-highlight .token.tag .token.script .token.punctuation{color:var(--color-prettylights-syntax-storage-modifier-import)}.markdown-body .highlight .token.operator,.markdown-body .highlight .token.number,.markdown-body .highlight .token.boolean,.markdown-body .highlight .token.tag .token.punctuation,.markdown-body .highlight .token.tag .token.script .token.script-punctuation,.markdown-body .highlight .token.tag .token.attr-name,.gfm-highlight .token.operator,.gfm-highlight .token.number,.gfm-highlight .token.boolean,.gfm-highlight .token.tag .token.punctuation,.gfm-highlight .token.tag .token.script .token.script-punctuation,.gfm-highlight .token.tag .token.attr-name{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.function,.gfm-highlight .token.function{color:var(--color-prettylights-syntax-entity)}.markdown-body .highlight .token.string,.gfm-highlight .token.string{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.comment,.gfm-highlight .token.comment{color:var(--color-prettylights-syntax-comment)}.markdown-body .highlight .token.class-name,.gfm-highlight .token.class-name{color:var(--color-prettylights-syntax-variable)}.markdown-body .highlight .token.regex,.gfm-highlight .token.regex{color:var(--color-prettylights-syntax-string)}.markdown-body .highlight .token.regex .regex-delimiter,.gfm-highlight .token.regex .regex-delimiter{color:var(--color-prettylights-syntax-constant)}.markdown-body .highlight .token.tag .token.tag,.markdown-body .highlight .token.property,.gfm-highlight .token.tag .token.tag,.gfm-highlight .token.property{color:var(--color-prettylights-syntax-entity-tag)}
    </style>
  </head>
  <body>
    <main data-color-mode="light" data-light-theme="light" data-dark-theme="dark" class="markdown-body">
      <h1>Awesome Tensorflow Lite Overview</h1>
<p>An awesome list of TensorFlow Lite models, samples, tutorials, tools and learning resources.</p>
<p><a href="/">üè† Home</a><span> ¬∑ </span><a href="https://www.trackawesomelist.com/margaretmz/awesome-tensorflow-lite/rss.xml">üî• Feed</a><span> ¬∑ </span><a href="https://trackawesomelist.us17.list-manage.com/subscribe?u=d2f0117aa829c83a63ec63c2f&id=36a103854c">üìÆ Subscribe</a><span> ¬∑ </span><a href="https://github.com/sponsors/theowenyoung">‚ù§Ô∏è  Sponsor</a><span> ¬∑ </span><a href="https://github.com/margaretmz/awesome-tensorflow-lite">üò∫ margaretmz/awesome-tensorflow-lite</a><span> ¬∑ </span><span>‚≠ê 1.3K</span><span> ¬∑ </span><span>üè∑Ô∏è Computer Science</span></p>
<p><span>[ </span><a href="/margaretmz/awesome-tensorflow-lite/">Daily</a><span> / </span><a href="/margaretmz/awesome-tensorflow-lite/week/">Weekly</a><span> / </span><span>Overview</span><span> ]</span></p>
<p>
    <img src="https://github.com/margaretmz/awesome-tensorflow-lite/raw/main/images/awesome-tflite.png" alt="awesome tflite" width="500" />
</p>



<h1 id="awesome-tensorflow-lite-awesome-prs-welcome-twitter"><a class="anchor" aria-hidden="true" tabindex="-1" href="#awesome-tensorflow-lite-awesome-prs-welcome-twitter"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Awesome TensorFlow Lite <a href="https://awesome.re" rel="noopener noreferrer"><img src="https://awesome.re/badge.svg" alt="Awesome" /></a> <a href="http://makeapullrequest.com" rel="noopener noreferrer"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square" alt="PRs Welcome" /></a> <a href="https://twitter.com/margaretmz" rel="noopener noreferrer"><img src="https://img.shields.io/badge/Twitter-%40margaretmz-blue" alt="Twitter" /></a></h1><p><a href="https://www.tensorflow.org/lite" rel="noopener noreferrer">TensorFlow Lite</a> is a set of tools that help convert and optimize TensorFlow models to run on mobile and edge devices. It's currently running on more than 4 billion devices! With TensorFlow 2.x, you can train a model with tf.Keras, easily convert a model to .tflite and deploy it; or you can download a pretrained TensorFlow Lite model from the model zoo.</p>
<p>This is an awesome list of TensorFlow Lite models with sample apps, helpful tools and learning resources -</p>
<ul>
<li>Showcase what the community has built with TensorFlow Lite</li>
<li>Put all the samples side-by-side for easy reference</li>
<li>Share knowledge and learning resources</li>
</ul>
<p>Please submit a PR if you would like to contribute and follow the guidelines <a href="https://github.com/margaretmz/awesome-tensorflow-lite/blob/main/README.md/CONTRIBUTING.md" rel="noopener noreferrer">here</a>.</p>


<h2 id="contents"><a class="anchor" aria-hidden="true" tabindex="-1" href="#contents"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Contents</h2><ul>
<li><a href="#past-announcements">Past announcements:</a></li>
<li><a href="#models-with-samples">Models with samples</a><ul>
<li><a href="#computer-vision">Computer vision</a><ul>
<li><a href="#classification">Classification</a></li>
<li><a href="#detection">Detection</a></li>
<li><a href="#segmentation">Segmentation</a></li>
<li><a href="#style-transfer">Style Transfer</a></li>
<li><a href="#generative">Generative</a></li>
<li><a href="#post-estimation">Post estimation</a></li>
<li><a href="#other">Other</a></li>
</ul>
</li>
<li><a href="#text">Text</a></li>
<li><a href="#speech">Speech</a></li>
<li><a href="#recommendation">Recommendation</a></li>
<li><a href="#game">Game</a></li>
</ul>
</li>
<li><a href="#model-zoo">Model zoo</a><ul>
<li><a href="#tensorflow-lite-models">TensorFlow Lite models</a></li>
<li><a href="#tensorflow-models">TensorFlow models</a></li>
</ul>
</li>
<li><a href="#ideas-and-inspiration">Ideas and Inspiration</a></li>
<li><a href="#ml-kit-examples">ML Kit examples</a></li>
<li><a href="#plugins-and-sdks">Plugins and SDKs</a></li>
<li><a href="#helpful-links">Helpful links</a></li>
<li><a href="#learning-resources">Learning resources</a><ul>
<li><a href="#blog-posts">Blog posts</a></li>
<li><a href="#books">Books</a></li>
<li><a href="#videos">Videos</a></li>
<li><a href="#podcasts">Podcasts</a></li>
<li><a href="#moocs">MOOCs</a></li>
</ul>
</li>
</ul>
<h2 id="past-announcements"><a class="anchor" aria-hidden="true" tabindex="-1" href="#past-announcements"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Past announcements:</h2><p>Here are some past feature annoucements of TensorFlow Lite:</p>
<ul>
<li><a href="https://groups.google.com/a/tensorflow.org/d/msg/tflite/Z_h7706dt8Q/sNrjPj4yGgAJ" rel="noopener noreferrer">Announcement of the new converter</a> - <a href="https://medium.com/tensorflow/mlir-a-new-intermediate-representation-and-compiler-framework-beba999ed18d" rel="noopener noreferrer">MLIR</a>-based and enables conversion of new classes of models such as Mask R-CNN and Mobile BERT etc., supports functional control flow and better error handling during conversion. Enabled by default in the nightly builds.</li>
<li><a href="https://github.com/tensorflow/tflite-support/tree/master/tensorflow_lite_support/java" rel="noopener noreferrer">Android Support Library</a> - Makes mobile development easier (<a href="https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/EXPLORE_THE_CODE.md" rel="noopener noreferrer">Android</a> sample code).</li>
<li><a href="https://www.tensorflow.org/lite/guide/model_maker" rel="noopener noreferrer">Model Maker</a> - Create your custom <a href="https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker" rel="noopener noreferrer">image &amp; text</a> classification models easily in a few lines of code. See below the Icon Classifier for a tutorial by the community.</li>
<li><a href="https://blog.tensorflow.org/2019/12/example-on-device-model-personalization.html" rel="noopener noreferrer">On-device training</a> - It is finally here! Currently limited to transfer learning for image classification only but it's a great start. See the official <a href="https://github.com/tensorflow/examples/blob/master/lite/examples/model_personalization/README.md" rel="noopener noreferrer">Android</a> sample code and another one from the community (<a href="https://aqibsaeed.github.io/on-device-activity-recognition" rel="noopener noreferrer">Blog</a> | <a href="https://github.com/aqibsaeed/on-device-activity-recognition" rel="noopener noreferrer">Android</a>).</li>
<li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/hexagon_delegate.md" rel="noopener noreferrer">Hexagon delegate</a> - How to use the Hexagon Delegate to speed up model inference on mobile and edge devices. Also see blog post  <a href="https://blog.tensorflow.org/2019/12/accelerating-tensorflow-lite-on-qualcomm.html" rel="noopener noreferrer">Accelerating TensorFlow Lite on Qualcomm Hexagon DSPs</a>.</li>
<li><a href="https://www.tensorflow.org/lite/convert/metadata" rel="noopener noreferrer">Model Metadata</a> - Provides a standard for model descriptions which also enables <a href="https://www.tensorflow.org/lite/inference_with_metadata/codegen" rel="noopener noreferrer">Code Gen and Android Studio ML Model Binding</a>.</li>
</ul>
<h2 id="models-with-samples"><a class="anchor" aria-hidden="true" tabindex="-1" href="#models-with-samples"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Models with samples</h2><p>Here are the TensorFlow Lite models with app / device implementations, and references.
Note: pretrained TensorFlow Lite models from MediaPipe are included, which you can implement with or without MediaPipe.</p>
<h3 id="computer-vision"><a class="anchor" aria-hidden="true" tabindex="-1" href="#computer-vision"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Computer vision</h3><h4 id="classification"><a class="anchor" aria-hidden="true" tabindex="-1" href="#classification"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Classification</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Classification</td>
<td>MobileNetV1 (<a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/mobilenet_v1_1.0_224_quant_and_labels.zip" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android" rel="noopener noreferrer">Android</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/ios" rel="noopener noreferrer">iOS</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi" rel="noopener noreferrer">Raspberry Pi</a> | <a href="https://www.tensorflow.org/lite/models/image_classification/overview" rel="noopener noreferrer">Overview</a></td>
<td>tensorflow.org</td>
</tr>
<tr>
<td>Classification</td>
<td>MobileNetV2</td>
<td>Recognize Flowers on Android <a href="https://codelabs.developers.google.com/codelabs/recognize-flowers-with-tensorflow-on-android/#0" rel="noopener noreferrer">Codelab</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/codelabs/flower_classification/android" rel="noopener noreferrer">Android</a></td>
<td>TensorFlow team</td>
</tr>
<tr>
<td>Classification</td>
<td>MobileNetV2</td>
<td>Skin Lesion Detection <a href="https://github.com/AakashKumarNain/skin_cancer_detection/tree/master/demo" rel="noopener noreferrer">Android</a></td>
<td>Community</td>
</tr>
<tr>
<td>Classification</td>
<td>MobileNetV2</td>
<td>American Sign Language Detection | <a href="https://colab.research.google.com/drive/1xsunX7Qj_XWBZwcZLyjsKBg4RI0DNo2-?usp=sharing" rel="noopener noreferrer">Colab Notebook</a> | <a href="https://github.com/sayannath/American-Sign-Language-Detection" rel="noopener noreferrer">Android</a></td>
<td>Community</td>
</tr>
<tr>
<td>Classification</td>
<td>CNN + Quantisation Aware Training</td>
<td>Stone Paper Scissor Detection <a href="https://colab.research.google.com/drive/1Wdso2N_76E8Xxniqd4C6T1sV5BuhKN1o?usp=sharing" rel="noopener noreferrer">Colab Notebook</a> | <a href="https://github.com/sayannath/American-Sign-Language-Detection" rel="noopener noreferrer">Flutter</a></td>
<td>Community</td>
</tr>
<tr>
<td>Classification</td>
<td>EfficientNet-Lite0 (<a href="https://github.com/margaretmz/icon-classifier/blob/master/ml-code/icons-50.tflite" rel="noopener noreferrer">download</a>)</td>
<td>Icon Classifier <a href="https://github.com/margaretmz/icon-classifier" rel="noopener noreferrer">Colab &amp; Android</a> | <a href="https://medium.com/swlh/icon-classifier-with-tflite-model-maker-9263c0021f72" rel="noopener noreferrer">tutorial 1</a> | <a href="https://medium.com/@margaretmz/icon-classifier-android-app-1fc0b727f761" rel="noopener noreferrer">tutorial 2</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h4 id="detection"><a class="anchor" aria-hidden="true" tabindex="-1" href="#detection"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Detection</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Object detection</td>
<td>Quantized COCO SSD MobileNet v1 (<a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android" rel="noopener noreferrer">Android</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios" rel="noopener noreferrer">iOS</a> | <a href="https://www.tensorflow.org/lite/models/object_detection/overview#starter_model" rel="noopener noreferrer">Overview</a></td>
<td>tensorflow.org</td>
</tr>
<tr>
<td>Object detection</td>
<td>YOLO</td>
<td><a href="https://blog.francium.tech/real-time-object-detection-on-mobile-with-flutter-tensorflow-lite-and-yolo-android-part-a0042c9b62c6" rel="noopener noreferrer">Flutter</a> | <a href="https://arxiv.org/abs/1506.02640" rel="noopener noreferrer">Paper</a></td>
<td>Community</td>
</tr>
<tr>
<td>Object detection</td>
<td><a href="https://tfhub.dev/neso613/lite-model/yolo-v5-tflite/tflite_model/1" rel="noopener noreferrer">YOLOv5</a></td>
<td><a href="https://github.com/neso613/yolo-v5-tflite-model" rel="noopener noreferrer">Yolov5 Inference </a></td>
<td>Community</td>
</tr>
<tr>
<td>Object detection</td>
<td>MobileNetV2 SSD (<a href="https://github.com/google/mediapipe/tree/master/mediapipe/models/ssdlite_object_detection.tflite" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/google/mediapipe/blob/master/mediapipe/models/object_detection_saved_model/README.md" rel="noopener noreferrer">Reference</a></td>
<td>MediaPipe</td>
</tr>
<tr>
<td>Object detection</td>
<td>MobileDet (<a href="https://arxiv.org/abs/2004.14525" rel="noopener noreferrer">Paper</a>)</td>
<td><a href="https://sayak.dev/mobiledet-optimization/" rel="noopener noreferrer">Blog post (includes the TFLite conversion process)</a></td>
<td>MobileDet is from University of Wisconsin-Madison and Google and the blog post is from the Community</td>
</tr>
<tr>
<td>License Plate detection</td>
<td>SSD MobileNet <a href="https://github.com/ariG23498/Flutter-License/blob/master/assets/detect.tflite" rel="noopener noreferrer">(download)</a></td>
<td><a href="https://github.com/ariG23498/Flutter-License" rel="noopener noreferrer">Flutter</a></td>
<td>Community</td>
</tr>
<tr>
<td>Face detection</td>
<td>BlazeFace (<a href="https://github.com/google/mediapipe/tree/master/mediapipe/models/face_detection_front.tflite" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://sites.google.com/corp/view/perception-cv4arvr/blazeface" rel="noopener noreferrer">Paper</a></td>
<td>MediaPipe</td>
</tr>
<tr>
<td>Face Authentication</td>
<td><a href="https://arxiv.org/pdf/1503.03832.pdf" rel="noopener noreferrer">FaceNet</a></td>
<td><a href="https://github.com/sayannath/Face-Authentication-App" rel="noopener noreferrer">Flutter</a></td>
<td>Community</td>
</tr>
<tr>
<td>Hand detection &amp; tracking</td>
<td>Palm detection &amp; hand landmarks (<a href="https://github.com/google/mediapipe/tree/master/mediapipe/models#hand-detection-and-tracking" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://mediapipe.page.link/handgoogleaiblog" rel="noopener noreferrer">Blog post</a> | <a href="https://mediapipe.page.link/handmc" rel="noopener noreferrer">Model card</a> |  <a href="https://github.com/supremetech/mediapipe-demo-hand-detection" rel="noopener noreferrer">Android</a></td>
<td>MediaPipe &amp; Community</td>
</tr>
</tbody></table>
<h4 id="segmentation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#segmentation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Segmentation</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Segmentation</td>
<td>DeepLab V3 (<a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/deeplabv3_257_mv_gpu.tflite" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/" rel="noopener noreferrer">Android &amp; iOS</a> | <a href="https://www.tensorflow.org/lite/models/segmentation/overview" rel="noopener noreferrer">Overview</a> | Flutter <a href="https://github.com/kshitizrimal/Flutter-TFLite-Image-Segmentation" rel="noopener noreferrer">Image</a> | <a href="https://github.com/kshitizrimal/tflite-realtime-flutter" rel="noopener noreferrer">Realtime</a> | <a href="https://arxiv.org/abs/1706.05587" rel="noopener noreferrer">Paper</a></td>
<td>tf.org &amp; Community</td>
</tr>
<tr>
<td>Segmentation</td>
<td>Different variants of <a href="https://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md" rel="noopener noreferrer">DeepLab V3 models</a></td>
<td>Models on <a href="https://tfhub.dev/s?module-type=image-segmentation&amp;publisher=sayakpaul" rel="noopener noreferrer">TF Hub</a> with Colab Notebooks</td>
<td>Community</td>
</tr>
<tr>
<td>Segmentation</td>
<td><a href="https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2?lite-format=tflite" rel="noopener noreferrer">DeepLab V3 model</a></td>
<td><a href="https://github.com/farmaker47/Update_image_segmentation" rel="noopener noreferrer">Android</a> | <a href="https://farmaker47.medium.com/use-camerax-with-image-segmentation-android-project-d8656f35cea3" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
<tr>
<td>Hair Segmentation</td>
<td><a href="https://github.com/google/mediapipe/tree/master/mediapipe/models/hair_segmentation.tflite" rel="noopener noreferrer">Download</a></td>
<td><a href="https://sites.google.com/corp/view/perception-cv4arvr/hair-segmentation" rel="noopener noreferrer">Paper</a></td>
<td>MediaPipe</td>
</tr>
</tbody></table>
<h4 id="style-transfer"><a class="anchor" aria-hidden="true" tabindex="-1" href="#style-transfer"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Style Transfer</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Style transfer</td>
<td><a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization" rel="noopener noreferrer">Arbitrary image stylization</a></td>
<td><a href="https://www.tensorflow.org/lite/models/style_transfer/overview" rel="noopener noreferrer">Overview</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/style_transfer/android" rel="noopener noreferrer">Android</a> | <a href="https://github.com/PuzzleLeaf/flutter_tflite_style_transfer" rel="noopener noreferrer">Flutter</a></td>
<td>tf.org &amp; Community</td>
</tr>
<tr>
<td>Style transfer</td>
<td>Better-quality style transfer models in .tflite</td>
<td>Models on <a href="https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3/dr/predict/1" rel="noopener noreferrer">TF Hub</a> with Colab Notebooks</td>
<td>Community</td>
</tr>
<tr>
<td>Video Style Transfer</td>
<td>Download: <br /> <a href="https://tfhub.dev/sayakpaul/lite-model/arbitrary-image-stylization-inceptionv3-dynamic-shapes/dr/transfer/1" rel="noopener noreferrer">Dynamic range models</a>)</td>
<td><a href="https://github.com/farmaker47/video_style_transfer" rel="noopener noreferrer">Android</a> | <a href="https://medium.com/@farmaker47/android-implementation-of-video-style-transfer-with-tensorflow-lite-models-9338a6d2a3ea" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
<tr>
<td>Segmentation &amp; Style transfer</td>
<td>DeepLabV3 &amp; Style Transfer <a href="https://github.com/margaretmz/segmentation-style-transfer/tree/master/ml" rel="noopener noreferrer">models</a></td>
<td><a href="https://github.com/margaretmz/segmentation-style-transfer" rel="noopener noreferrer">Project repo</a>  | <a href="https://github.com/margaretmz/segmentation-style-transfer/tree/master/android" rel="noopener noreferrer">Android</a> | <a href="https://medium.com/google-developer-experts/image-background-stylizer-part-1-project-intro-d68c4547e7e3" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h4 id="generative"><a class="anchor" aria-hidden="true" tabindex="-1" href="#generative"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Generative</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>GANs</td>
<td><a href="https://github.com/taki0112/UGATIT" rel="noopener noreferrer">U-GAT-IT</a> (Selfie2Anime)</td>
<td><a href="https://github.com/margaretmz/selfie2anime-with-tflite" rel="noopener noreferrer">Project repo</a> | <a href="https://github.com/margaretmz/selfie2anime-with-tflite/tree/master/android" rel="noopener noreferrer">Android</a> | <a href="https://medium.com/google-developer-experts/selfie2anime-with-tflite-part-1-overview-f97500800ffe" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
<tr>
<td>GANs</td>
<td><a href="https://github.com/SystemErrorWang/White-box-Cartoonization" rel="noopener noreferrer">White-box CartoonGAN</a> (<a href="https://tfhub.dev/sayakpaul/lite-model/cartoongan/dr/1" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/margaretmz/Cartoonizer-with-TFLite" rel="noopener noreferrer">Project repo</a> | <a href="https://github.com/margaretmz/Cartoonizer-with-TFLite/tree/master/android" rel="noopener noreferrer">Android</a> | <a href="https://blog.tensorflow.org/2020/09/how-to-create-cartoonizer-with-tf-lite.html" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
<tr>
<td>GANs - Image Extrapolation</td>
<td>Boundless on <a href="https://tfhub.dev/sayakpaul/lite-model/boundless-quarter/dr/1" rel="noopener noreferrer">TF Hub</a></td>
<td><a href="https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/Boundless_TFLite.ipynb" rel="noopener noreferrer">Colab Notebook</a>  | <a href="https://arxiv.org/pdf/2003.06792v2.pdf" rel="noopener noreferrer">Original Paper</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h4 id="post-estimation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#post-estimation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Post estimation</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Pose estimation</td>
<td>Posenet (<a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/posenet_mobilenet_v1_100_257x257_multi_kpt_stripped.tflite" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/android" rel="noopener noreferrer">Android</a> | <a href="https://github.com/tensorflow/examples/tree/master/lite/examples/posenet/ios" rel="noopener noreferrer">iOS</a> | <a href="https://www.tensorflow.org/lite/models/pose_estimation/overview" rel="noopener noreferrer">Overview</a></td>
<td>tensorflow.org</td>
</tr>
<tr>
<td>Pose Classification based Video Game Control</td>
<td>MoveNet Lightning (<a href="https://github.com/NSTiwari/Video-Game-Control-using-Pose-Classification-and-TensorFlow-Lite/blob/main/movenet_lightning.tflite" rel="noopener noreferrer">download</a>)</td>
<td><a href="https://github.com/NSTiwari/Video-Game-Control-using-Pose-Classification-and-TensorFlow-Lite" rel="noopener noreferrer">Project Repository</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h4 id="other"><a class="anchor" aria-hidden="true" tabindex="-1" href="#other"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Other</h4><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Low-light image enhancement</td>
<td><a href="https://tfhub.dev/sayakpaul/mirnet-fixed/1" rel="noopener noreferrer">Models on TF Hub</a></td>
<td><a href="https://github.com/sayakpaul/MIRNet-TFLite" rel="noopener noreferrer">Project repo</a>  | <a href="https://arxiv.org/pdf/2003.06792v2.pdf" rel="noopener noreferrer">Original Paper</a> | <a href="https://github.com/sayannath/MIRNet-Flutter" rel="noopener noreferrer">Flutter</a></td>
<td></td>
<td>Community</td>
</tr>
<tr>
<td>OCR</td>
<td><a href="https://tfhub.dev/tulasiram58827/lite-model/keras-ocr/dr/2" rel="noopener noreferrer">Models on TF Hub</a></td>
<td><a href="https://github.com/tulasiram58827/ocr_tflite" rel="noopener noreferrer">Project Repository</a></td>
<td>Community</td>
<td></td>
</tr>
</tbody></table>
<h3 id="text"><a class="anchor" aria-hidden="true" tabindex="-1" href="#text"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Text</h3><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>Sample apps</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Question &amp; Answer</td>
<td>DistilBERT</td>
<td><a href="https://github.com/huggingface/tflite-android-transformers/blob/master/bert" rel="noopener noreferrer">Android</a></td>
<td>Hugging Face</td>
</tr>
<tr>
<td>Text Generation</td>
<td>GPT-2 / DistilGPT2</td>
<td><a href="https://github.com/huggingface/tflite-android-transformers/blob/master/gpt2" rel="noopener noreferrer">Android</a></td>
<td>Hugging Face</td>
</tr>
<tr>
<td>Text Classification</td>
<td><a href="https://storage.googleapis.com/download.tensorflow.org/models/tflite/text_classification/text_classification.tflite" rel="noopener noreferrer">Download</a></td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/text_classification/android" rel="noopener noreferrer">Android</a> |<a href="https://github.com/khurram18/TextClassafication" rel="noopener noreferrer">iOS</a> | <a href="https://github.com/am15h/tflite_flutter_plugin/tree/master/example" rel="noopener noreferrer">Flutter</a></td>
<td>tf.org &amp; Community</td>
</tr>
<tr>
<td>Text Detection</td>
<td>CRAFT Text Detector (<a href="https://arxiv.org/pdf/1904.01941" rel="noopener noreferrer">Paper</a>)</td>
<td><a href="https://github.com/tulasiram58827/craft_tflite/blob/main/models/craft_float_800.tflite?raw=true" rel="noopener noreferrer">Download</a> | <a href="https://github.com/tulasiram58827/craft_tflite/" rel="noopener noreferrer">Project Repository</a>  | <a href="https://tulasi.dev/craft-in-tflite" rel="noopener noreferrer">Blog1-Conversion to TFLite</a> | <a href="https://sayak.dev/optimizing-text-detectors/" rel="noopener noreferrer">Blog2-EAST vs CRAFT</a> | <a href="https://tfhub.dev/tulasiram58827/lite-model/craft-text-detector/dr/1" rel="noopener noreferrer">Models on TF Hub</a>   | Android (Coming Soon)</td>
<td>Community</td>
</tr>
<tr>
<td>Text Detection</td>
<td>EAST Text Detector (<a href="https://arxiv.org/abs/1704.03155" rel="noopener noreferrer">Paper</a>)</td>
<td><a href="https://tfhub.dev/sayakpaul/lite-model/east-text-detector/dr/1" rel="noopener noreferrer">Models on TF Hub</a> | <a href="https://colab.research.google.com/github/sayakpaul/Adventures-in-TensorFlow-Lite/blob/master/EAST_TFLite.ipynb" rel="noopener noreferrer">Conversion and Inference Notebook</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h3 id="speech"><a class="anchor" aria-hidden="true" tabindex="-1" href="#speech"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Speech</h3><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Speech Recognition</td>
<td>DeepSpeech</td>
<td><a href="https://github.com/mozilla/DeepSpeech/tree/master/native_client/java" rel="noopener noreferrer">Reference</a></td>
<td>Mozilla</td>
</tr>
<tr>
<td>Speech Recognition</td>
<td>CONFORMER</td>
<td><a href="https://github.com/neso613/ASR_TFLite" rel="noopener noreferrer">Inference</a>  <a href="https://github.com/windmaple/tflite-asr" rel="noopener noreferrer">Android</a></td>
<td>Community</td>
</tr>
<tr>
<td>Speech Synthesis</td>
<td>Tacotron-2, FastSpeech2, MB-Melgan</td>
<td><a href="https://github.com/TensorSpeech/TensorflowTTS/tree/master/examples/android" rel="noopener noreferrer">Android</a></td>
<td>TensorSpeech</td>
</tr>
<tr>
<td>Speech Synthesis(TTS)</td>
<td>Tacotron2, FastSpeech2, MelGAN, MB-MelGAN, HiFi-GAN, Parallel WaveGAN</td>
<td><a href="https://github.com/tulasiram58827/TTS_TFLite/blob/main/End_to_End_TTS.ipynb" rel="noopener noreferrer">Inference Notebook</a>      | <a href="https://github.com/tulasiram58827/TTS_TFLite/" rel="noopener noreferrer">Project Repository</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h3 id="recommendation"><a class="anchor" aria-hidden="true" tabindex="-1" href="#recommendation"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Recommendation</h3><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>On-device Recommendation</td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/recommendation/ml" rel="noopener noreferrer">Dual-Encoder</a></td>
<td><a href="https://github.com/tensorflow/examples/tree/master/lite/examples/recommendation/android" rel="noopener noreferrer">Android</a> | <a href="https://github.com/zhuzilin/on-device_recommendation_tflite" rel="noopener noreferrer">iOS</a> | <a href="https://blog.tensorflow.org/2020/09/introduction-to-tflite-on-device-recommendation.html" rel="noopener noreferrer">Reference</a></td>
<td>tf.org &amp; Community</td>
</tr>
</tbody></table>
<h3 id="game"><a class="anchor" aria-hidden="true" tabindex="-1" href="#game"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Game</h3><table>
<thead>
<tr>
<th>Task</th>
<th>Model</th>
<th>App | Reference</th>
<th>Source</th>
</tr>
</thead>
<tbody><tr>
<td>Game agent</td>
<td>Reinforcement learning</td>
<td><a href="https://github.com/windmaple/planestrike-flutter" rel="noopener noreferrer">Flutter</a> | <a href="https://windmaple.medium.com/" rel="noopener noreferrer">Tutorial</a></td>
<td>Community</td>
</tr>
</tbody></table>
<h2 id="model-zoo"><a class="anchor" aria-hidden="true" tabindex="-1" href="#model-zoo"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Model zoo</h2><h3 id="tensorflow-lite-models"><a class="anchor" aria-hidden="true" tabindex="-1" href="#tensorflow-lite-models"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TensorFlow Lite models</h3><p>These are the TensorFlow Lite models that could be implemented in apps and things:</p>
<ul>
<li><a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md" rel="noopener noreferrer">MobileNet</a> - Pretrained MobileNet v2 and v3 models.</li>
<li>TensorFlow Lite models<ul>
<li><a href="https://www.tensorflow.org/lite/models" rel="noopener noreferrer">TensorFlow Lite models</a> - With official Android and iOS examples.</li>
<li><a href="https://www.tensorflow.org/lite/guide/hosted_models" rel="noopener noreferrer">Pretrained models</a> - Quantized and floating point variants.</li>
<li><a href="https://tfhub.dev/" rel="noopener noreferrer">TensorFlow Hub</a> - Set "Model format = TFLite" to find TensorFlow Lite models.</li>
</ul>
</li>
</ul>
<h3 id="tensorflow-models"><a class="anchor" aria-hidden="true" tabindex="-1" href="#tensorflow-models"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>TensorFlow models</h3><p>These are TensorFlow models that could be converted to .tflite and then implemented in apps and things:</p>
<ul>
<li><a href="https://github.com/tensorflow/models/tree/master/official" rel="noopener noreferrer">TensorFlow models</a> - Official TensorFlow models.</li>
<li><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md" rel="noopener noreferrer">Tensorflow detection model zoo</a> - Pre-trained on COCO, KITTI, AVA v2.1, iNaturalist Species datasets.</li>
</ul>
<h2 id="ideas-and-inspiration"><a class="anchor" aria-hidden="true" tabindex="-1" href="#ideas-and-inspiration"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Ideas and Inspiration</h2><ul>
<li><a href="https://github.com/ml-gde/e2e-tflite-tutorials" rel="noopener noreferrer">E2E TFLite Tutorials</a> - Checkout this repo for sample app ideas and seeking help for your tutorial projects. Once a project gets completed, the links of the TensorFlow Lite model(s), sample code and tutorial will be added to this awesome list.</li>
</ul>
<h2 id="ml-kit-examples"><a class="anchor" aria-hidden="true" tabindex="-1" href="#ml-kit-examples"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>ML Kit examples</h2><p><a href="https://developers.google.com/ml-kit" rel="noopener noreferrer">ML Kit</a> is a mobile SDK that brings Google's ML expertise to mobile developers.</p>
<ul>
<li>2019-10-01 <a href="https://codelabs.developers.google.com/codelabs/mlkit-android-translate/#0" rel="noopener noreferrer">ML Kit Translate demo</a> - A tutorial with material design <a href="https://github.com/googlecodelabs/mlkit-android/tree/master/translate" rel="noopener noreferrer">Android</a> (Kotlin) sample - recognize, identify Language and translate text from live camera with ML Kit for Firebase.</li>
<li>2019-03-13 <a href="https://youtu.be/ymyYUCrJnxU" rel="noopener noreferrer">Computer Vision with ML Kit - Flutter In Focus</a>.</li>
<li>2019-02-09 <a href="https://medium.com/flutter-community/flutter-mlkit-8039ec66b6a" rel="noopener noreferrer">Flutter + MLKit: Business Card Mail Extractor</a>  - A blog post with a <a href="https://github.com/DaemonLoki/Business-Card-Mail-Extractor" rel="noopener noreferrer">Flutter</a> sample code.</li>
<li>2019-02-08 <a href="https://speakerdeck.com/jinqian/from-tensorflow-to-ml-kit-power-your-android-application-with-machine-learning" rel="noopener noreferrer">From TensorFlow to ML Kit: Power your Android application with machine learning</a> - A talk with <a href="https://github.com/xebia-france/magritte" rel="noopener noreferrer">Android</a> (Kotlin) sample code.</li>
<li>2018-08-07 <a href="https://medium.com/over-engineering/building-a-custom-machine-learning-model-on-android-with-tensorflow-lite-26447e53abf2" rel="noopener noreferrer">Building a Custom Machine Learning Model on Android with TensorFlow Lite</a>.</li>
<li>2018-07-20 <a href="https://flatteredwithflutter.com/ml-kit-and-face-detection-in-flutter/" rel="noopener noreferrer">ML Kit and Face Detection in Flutter</a>.</li>
<li>2018-07-27 <a href="https://medium.com/google-developer-experts/exploring-firebase-mlkit-on-android-landmark-detection-part-four-5e86b8deac3a" rel="noopener noreferrer">ML Kit on Android 4: Landmark Detection</a>.</li>
<li>2018-07-28 <a href="https://medium.com/google-developer-experts/exploring-firebase-mlkit-on-android-barcode-scanning-part-three-cc6f5921a108" rel="noopener noreferrer">ML Kit on Android 3: Barcode Scanning</a>.</li>
<li>2018-05-31 <a href="https://medium.com/google-developer-experts/exploring-firebase-mlkit-on-android-face-detection-part-two-de7e307c52e0" rel="noopener noreferrer">ML Kit on Android 2: Face Detection</a>.</li>
<li>2018-05-22 <a href="https://medium.com/google-developer-experts/exploring-firebase-mlkit-on-android-introducing-mlkit-part-one-98fcfedbeee0" rel="noopener noreferrer">ML Kit on Android 1: Intro</a>.</li>
</ul>
<h2 id="plugins-and-sdks"><a class="anchor" aria-hidden="true" tabindex="-1" href="#plugins-and-sdks"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Plugins and SDKs</h2><ul>
<li><a href="https://www.edgeimpulse.com/" rel="noopener noreferrer">Edge Impulse</a> - Created by <a href="https://twitter.com/EdgeImpulse" rel="noopener noreferrer">@EdgeImpulse</a> to help you to train TensorFlow Lite models for embedded devices in the cloud.</li>
<li><a href="https://github.com/google/mediapipe" rel="noopener noreferrer">MediaPipe</a> - A cross platform (mobile, desktop and Edge TPUs) AI pipeline by Google AI. (PM <a href="https://twitter.com/realmgyong" rel="noopener noreferrer">Ming Yong</a>) | <a href="https://mediapipe.readthedocs.io/en/latest/examples.html" rel="noopener noreferrer">MediaPipe examples</a>.</li>
<li><a href="https://coral.ai/" rel="noopener noreferrer">Coral Edge TPU</a> - Edge hardware by Google. <a href="https://coral.ai/examples/" rel="noopener noreferrer">Coral Edge TPU examples</a>.</li>
<li><a href="https://github.com/am15h/tflite_flutter_plugin/" rel="noopener noreferrer">TensorFlow Lite Flutter Plugin</a> - Provides a dart API similar to the TensorFlow Lite Java API for accessing TensorFlow Lite interpreter and performing inference in flutter apps. <a href="https://pub.dev/packages/tflite_flutter" rel="noopener noreferrer">tflite_flutter on pub.dev</a>.</li>
</ul>
<h2 id="helpful-links"><a class="anchor" aria-hidden="true" tabindex="-1" href="#helpful-links"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Helpful links</h2><ul>
<li><a href="https://github.com/lutzroeder/netron" rel="noopener noreferrer">Netron</a> - A tool for visualizing models.</li>
<li><a href="http://ai-benchmark.com/tests.html" rel="noopener noreferrer">AI benchmark</a> - A website for benchmarking computer vision models on smartphones.</li>
<li><a href="https://www.tensorflow.org/lite/performance/measurement" rel="noopener noreferrer">Performance measurement</a> - How to measure model performance on Android and iOS.</li>
<li><a href="https://material.io/collections/machine-learning/patterns-for-machine-learning-powered-features.html" rel="noopener noreferrer">Material design guidelines for ML</a> - How to design machine learning powered features. A good example: <a href="https://github.com/firebase/mlkit-material-android" rel="noopener noreferrer">ML Kit Showcase App</a>.</li>
<li><a href="https://pair.withgoogle.com/" rel="noopener noreferrer">The People + AI Guide book</a> - Learn how to design human-centered AI products.</li>
<li><a href="https://github.com/sayakpaul/Adventures-in-TensorFlow-Lite" rel="noopener noreferrer">Adventures in TensorFlow Lite</a> - A repository showing non-trivial conversion processes and general explorations in TensorFlow Lite.</li>
<li><a href="https://github.com/iglaweb/TFProfiler" rel="noopener noreferrer">TFProfiler</a> - An Android-based app to profile TensorFlow Lite models and measure its performance on smartphone.</li>
<li><a href="https://www.tensorflow.org/lite/microcontrollers" rel="noopener noreferrer">TensorFlow Lite for Microcontrollers</a></li>
<li><a href="https://github.com/dailystudio/tensorflow-lite-examples-android" rel="noopener noreferrer">TensorFlow Lite Examples - Android</a> - A repository refactors and rewrites all the TensorFlow Lite Android examples which are included in the TensorFlow official website.</li>
<li><a href="https://github.com/SunitRoy2703/Tensorflow-lite-kotlin-samples" rel="noopener noreferrer">Tensorflow-lite-kotlin-samples</a> - A collection of Tensorflow Lite Android example Apps in Kotlin, to show different kinds of kotlin implementation of the <a href="https://www.tensorflow.org/lite/examples" rel="noopener noreferrer">example apps</a></li>
</ul>
<h2 id="learning-resources"><a class="anchor" aria-hidden="true" tabindex="-1" href="#learning-resources"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Learning resources</h2><p>Interested but not sure how to get started? Here are some learning resources that will help you whether you are a beginner or a practitioner in the field for a while.</p>
<h3 id="blog-posts"><a class="anchor" aria-hidden="true" tabindex="-1" href="#blog-posts"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blog posts</h3><ul>
<li>2021-11-09 <a href="https://blog.tensorflow.org/2021/11/on-device-training-in-tensorflow-lite.html" rel="noopener noreferrer">On-device training in TensorFlow Lite</a></li>
<li>2021-09-27 <a href="https://blog.tensorflow.org/2021/09/blog.tensorflow.org202109optical-character-recognition.html" rel="noopener noreferrer">Optical character recognition with TensorFlow Lite: A new example app</a></li>
<li>2021-06-16 <a href="https://blog.tensorflow.org/2021/11/on-device-training-in-tensorflow-lite.html" rel="noopener noreferrer">https://blog.tensorflow.org/2021/06/easier-object-detection-on-mobile-with-tf-lite.html</a></li>
<li>2020-12-29 <a href="https://medium.com/analytics-vidhya/yolov3-to-tensorflow-lite-conversion-4602cec5c239" rel="noopener noreferrer">YOLOv3 to TensorFlow Lite Conversion</a> - By Nitin Tiwari.</li>
<li>2020-04-20 <a href="https://blog.tensorflow.org/2020/04/whats-new-in-tensorflow-lite-from-devsummit-2020.html" rel="noopener noreferrer">What is new in TensorFlow Lite</a> - By Khanh LeViet.</li>
<li>2020-04-17 <a href="https://blog.tensorflow.org/2020/04/optimizing-style-transfer-to-run-on-mobile-with-tflite.html" rel="noopener noreferrer">Optimizing style transfer to run on mobile with TFLite</a> - By Khanh LeViet and Luiz Gustavo Martins.</li>
<li>2020-04-14 <a href="https://blog.tensorflow.org/2020/04/how-tensorflow-lite-helps-you-from-prototype-to-product.html" rel="noopener noreferrer">How TensorFlow Lite helps you from prototype to product</a> -  By Khanh LeViet.</li>
<li>2019-11-08 <a href="https://blog.particle.io/2019/11/08/particle-machine-learning-101/" rel="noopener noreferrer">Getting  Started with ML on MCUs with TensorFlow</a> -  By Brandon Satrom.</li>
<li>2019-08-05 <a href="https://blog.tensorflow.org/2019/08/tensorflow-model-optimization-toolkit_5.html" rel="noopener noreferrer">TensorFlow Model Optimization Toolkit ‚Äî float16 quantization halves model size</a> - By the TensorFlow team.</li>
<li>2018-07-13 <a href="https://blog.tensorflow.org/2018/07/training-and-serving-realtime-mobile-object-detector-cloud-tpus.html" rel="noopener noreferrer">Training and serving a real-time mobile object detector in 30 minutes with Cloud TPUs</a> - By Sara Robinson, Aakanksha Chowdhery, and Jonathan Huang.</li>
<li>2018-06-11 - <a href="https://petewarden.com/2018/06/11/why-the-future-of-machine-learning-is-tiny/" rel="noopener noreferrer">Why the Future of Machine Learning is Tiny</a> - By Pete Warden.</li>
<li>2018-03-30 - <a href="https://blog.tensorflow.org/2018/03/using-tensorflow-lite-on-android.html" rel="noopener noreferrer">Using TensorFlow Lite on Android</a>) - By Laurence Moroney.</li>
</ul>
<h3 id="books"><a class="anchor" aria-hidden="true" tabindex="-1" href="#books"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Books</h3><ul>
<li>2021-12-01 <a href="https://learning.oreilly.com/library/view/ai-and-machine/9781098101732/" rel="noopener noreferrer">AI and Machine Learning On-Device Development</a> (early access) - By Laurence Moroney (<a href="https://twitter.com/lmoroney" rel="noopener noreferrer">@lmoroney</a>).</li>
<li>2020-10-01 <a href="https://learning.oreilly.com/library/view/ai-and-machine/9781492078180/" rel="noopener noreferrer">AI and Machine Learning for Coders</a> - By Laurence Moroney (<a href="https://twitter.com/lmoroney" rel="noopener noreferrer">@lmoroney</a>).</li>
<li>2020-04-06 <a href="https://www.packtpub.com/product/mobile-deep-learning-with-tensorflow-lite-ml-kit-and-flutter/9781789611212" rel="noopener noreferrer">Mobile Deep Learning with TensorFlow Lite, ML Kit and Flutter</a>: Build scalable real-world projects to implement end-to-end neural networks on Android and iOS (<a href="https://github.com/PacktPublishing/Mobile-Deep-Learning-Projects" rel="noopener noreferrer">GitHub</a>) - By Anubhav Singh (<a href="https://github.com/xprilion" rel="noopener noreferrer">@xprilion</a>) and Rimjhim Bhadani (<a href="https://github.com/Rimjhim28" rel="noopener noreferrer">@Rimjhim28</a>).</li>
<li>2020-03-01 Raspberry Pi for Computer Vision (<a href="https://www.pyimagesearch.com/raspberry-pi-for-computer-vision" rel="noopener noreferrer">Complete Bundle</a> | <a href="https://www.pyimagesearch.com/2019/04/05/table-of-contents-raspberry-pi-for-computer-vision/" rel="noopener noreferrer">TOC</a>) - By the PyImageSearch Team: Adrian Rosebrock (<a href="https://twitter.com/PyImageSearch" rel="noopener noreferrer">@PyImageSearch</a>), David Hoffman, Asbhishek Thanki, Sayak Paul (<a href="https://twitter.com/RisingSayak" rel="noopener noreferrer">@RisingSayak</a>), and David Mcduffee.</li>
<li>2019-12-01 <a href="http://shop.oreilly.com/product/0636920254508.do" rel="noopener noreferrer">TinyML</a> - By Pete Warden (<a href="https://twitter.com/petewarden" rel="noopener noreferrer">@petewarden</a>) and Daniel Situnayake (<a href="https://twitter.com/dansitu" rel="noopener noreferrer">@dansitu</a>).</li>
<li>2019-10-01 <a href="https://www.practicaldeeplearning.ai/" rel="noopener noreferrer">Practical Deep Learning for Cloud, Mobile, and Edge</a> - By Anirudh Koul (<a href="https://twitter.com/AnirudhKoul" rel="noopener noreferrer">@AnirudhKoul</a>), Siddha Ganju (<a href="https://twitter.com/SiddhaGanju" rel="noopener noreferrer">@SiddhaGanju</a>), and Meher Kasam (<a href="https://twitter.com/MeherKasam" rel="noopener noreferrer">@MeherKasam</a>).</li>
</ul>
<h3 id="videos"><a class="anchor" aria-hidden="true" tabindex="-1" href="#videos"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Videos</h3><ul>
<li>2021-10-06 <a href="https://youtu.be/sZayUoWW6nE" rel="noopener noreferrer">Contributing to TensorFlow Lite with Sunit Roy</a> (Hacktoberfest 2021)</li>
<li>2020-07-25 <a href="https://youtu.be/m_bEh8YifnQ" rel="noopener noreferrer">Android ML by Hoi Lam</a> (GDG Kolkata meetup).</li>
<li>2020-04-01 <a href="https://youtu.be/ALxWJoh_BHw" rel="noopener noreferrer">Easy on-device ML from prototype to production</a> (TF Dev Summit 2020).</li>
<li>2020-03-11 <a href="https://youtu.be/27Zx-4GOQA8" rel="noopener noreferrer">TensorFlow Lite: ML for mobile and IoT devices</a> (TF Dev Summit 2020).</li>
<li>2019-10-31 <a href="https://youtu.be/zjDGAiLqGk8" rel="noopener noreferrer">Keynote - TensorFlow Lite: ML for mobile and IoT devices</a>.</li>
<li>2019-10-31 <a href="https://youtu.be/0SpZy7iouFU" rel="noopener noreferrer">TensorFlow Lite: Solution for running ML on-device</a>.</li>
<li>2019-10-31 <a href="https://youtu.be/3JWRVx1OKQQ" rel="noopener noreferrer">TensorFlow model optimization: Quantization and pruning</a>.</li>
<li>2019-10-29 <a href="https://youtu.be/gHN0jDbJz8E" rel="noopener noreferrer">Inside TensorFlow: TensorFlow Lite</a>.</li>
<li>2018-04-18 <a href="https://youtu.be/JnhW5tQ_7Vo" rel="noopener noreferrer">TensorFlow Lite for Android (Coding TensorFlow)</a>.</li>
</ul>
<h3 id="podcasts"><a class="anchor" aria-hidden="true" tabindex="-1" href="#podcasts"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Podcasts</h3><ul>
<li>2020-08-08 <a href="https://anchor.fm/talkingwithapples/episodes/Talking-Machine-Learning-with-Hoi-Lam-eiaj7v" rel="noopener noreferrer">Talking Machine Learning with Hoi Lam</a>.</li>
</ul>
<h3 id="moocs"><a class="anchor" aria-hidden="true" tabindex="-1" href="#moocs"><svg class="octicon octicon-link" viewbox="0 0 16 16" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>MOOCs</h3><ul>
<li><a href="https://www.udacity.com/course/intro-to-tensorflow-lite--ud190" rel="noopener noreferrer">Introduction to TensorFlow Lite</a> - Udacity course by Daniel Situnayake (@dansitu), Paige Bailey (<a href="https://twitter.com/DynamicWebPaige" rel="noopener noreferrer">@DynamicWebPaige</a>), and Juan Delgado.</li>
<li><a href="https://www.coursera.org/learn/device-based-models-tensorflow" rel="noopener noreferrer">Device-based Models with TensorFlow Lite</a> - Coursera course by Laurence Moroney (<a href="https://twitter.com/lmoroney" rel="noopener noreferrer">@lmoroney</a>).</li>
<li><a href="https://www.edx.org/professional-certificate/harvardx-tiny-machine-learning" rel="noopener noreferrer">The Future of ML is Tiny and Bright</a> - A series of edX courses created by Harvard in collaboration with Google. Instructors - Vijay Janapa Reddi, Laurence Moroney, and Pete Warden.</li>
</ul>


    </main>
  </body>
</html>
